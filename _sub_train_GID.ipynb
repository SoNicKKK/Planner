{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning start time: Jun 28, 10:37 (1467099475)\n"
     ]
    }
   ],
   "source": [
    "FOLDER = 'resources/'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "\n",
    "#%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rc('font', family='Times New Roman')\n",
    "\n",
    "pd.set_option('max_rows', 50)\n",
    "\n",
    "time_format = '%b %d, %H:%M'\n",
    "\n",
    "start_time = time.time()\n",
    "current_time = pd.read_csv(FOLDER + 'current_time.csv').current_time[0]\n",
    "twr          = pd.read_csv(FOLDER + 'team_work_region.csv', converters={'twr':str})\n",
    "links        = pd.read_csv(FOLDER + 'link.csv')\n",
    "stations     = pd.read_csv(FOLDER + 'station.csv', converters={'station':str})\n",
    "train_info   = pd.read_csv(FOLDER + 'train_info.csv', converters={'train': str, 'st_from':str, 'st_to':str, 'oper_location':str,\n",
    "                                                                 'st_from':str, 'st_to':str})\n",
    "train_plan   = pd.read_csv(FOLDER + 'slot_train.csv', converters={'train': str, 'st_from':str, 'st_to':str})\n",
    "loco_info    = pd.read_csv(FOLDER + 'loco_attributes.csv', converters={'train':str, 'loco':str, 'depot':str,\n",
    "                                                                      'st_from':str, 'st_to':str})\n",
    "loco_plan    = pd.read_csv(FOLDER + 'slot_loco.csv', converters={'train':str, 'loco':str, 'st_from':str, 'st_to':str})\n",
    "team_info    = pd.read_csv(FOLDER + 'team_attributes.csv', converters={'team':str,'depot':str, 'oper_location':str, \\\n",
    "                                                                 'st_from':str, 'st_to':str, 'loco':str, 'depot_st':str})\n",
    "team_plan    = pd.read_csv(FOLDER + 'slot_team.csv', converters={'team':str,'loco':str, 'st_from':str, 'st_to':str})\n",
    "loco_series  = pd.read_csv(FOLDER + 'loco_series.csv')\n",
    "\n",
    "team_info.regions = team_info.regions.apply(literal_eval)\n",
    "st_names = stations[['station', 'name', 'esr']].drop_duplicates().set_index('station')\n",
    "print('Planning start time: %s (%d)' % (time.strftime(time_format, time.localtime(current_time)), current_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Мержим таблицы _plan и _info для поездов, локомотивов и бригад\n",
    "# Добавляем во все таблицы названия станций на маршруте и времена отправления/прибытия в читабельном формате\n",
    "\n",
    "def add_info(df):    \n",
    "    if 'st_from' in df.columns:\n",
    "        df['st_from_name'] = df.st_from.map(st_names.name)\n",
    "    if 'st_to' in df.columns:\n",
    "        df['st_to_name'] = df.st_to.map(st_names.name)\n",
    "    if 'time_start' in df.columns:\n",
    "        df['time_start_norm'] = df.time_start.apply(lambda x: time.strftime(time_format, time.localtime(x)))\n",
    "    if 'time_end' in df.columns:\n",
    "        df['time_end_norm'] = df.time_end.apply(lambda x: time.strftime(time_format, time.localtime(x)))\n",
    "    if 'oper_location' in df.columns:\n",
    "        df['oper_location_name'] = df.oper_location.map(st_names.name)    \n",
    "        df.oper_location_name.fillna(0, inplace=True)\n",
    "    if ('oper_location' in df.columns) & ('st_from' in df.columns) & ('st_to' in df.columns):        \n",
    "        df['loc_name'] = df.oper_location_name\n",
    "        df.loc[df.loc_name == 0, 'loc_name'] = df.st_from_name + ' - ' + df.st_to_name\n",
    "    \n",
    "add_info(train_plan)\n",
    "add_info(loco_plan)\n",
    "add_info(team_plan)\n",
    "add_info(loco_info)\n",
    "add_info(team_info)\n",
    "add_info(train_info)\n",
    "train_plan = train_plan.merge(train_info, on='train', suffixes=('', '_info'), how='left')\n",
    "loco_plan = loco_plan.merge(loco_info, on='loco', suffixes=('', '_info'), how='left')\n",
    "team_plan = team_plan.merge(team_info, on='team', suffixes=('', '_info'), how='left')\n",
    "team_plan['team_type'] = team_plan.team.apply(lambda x: 'Реальная' if str(x)[0] == '2' else 'Фейковая')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nice_time(t):\n",
    "    return time.strftime(time_format, time.localtime(t)) if t > 0 else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REPORT_FOLDER = 'report/'\n",
    "PRINT = False\n",
    "report = ''\n",
    "\n",
    "def add_line(line, p=PRINT):    \n",
    "    global report        \n",
    "    if p:                \n",
    "        if type(line) == pd.core.frame.DataFrame:\n",
    "            print(line.to_string(index=False))\n",
    "        elif type(line) == pd.core.series.Series:\n",
    "            print(line.to_string())\n",
    "        else:\n",
    "            print(line)\n",
    "    if type(line) == pd.core.frame.DataFrame:        \n",
    "        report += ('%s<br>' % line.to_html(index=False))\n",
    "    elif type(line) == pd.core.series.Series:\n",
    "        report += ('%s<br>' % line.to_frame().reset_index().to_html(index=False))\n",
    "    else:\n",
    "        report += ('%s<br>' % line)\n",
    "    \n",
    "def add_header(header, h=4, p=PRINT):\n",
    "    global report\n",
    "    report += ('<h%d>%s</h%d>' % (h, header, h))\n",
    "    if p:\n",
    "        print(header)\n",
    "\n",
    "def add_image(filename):\n",
    "    global report\n",
    "    report += ('<img src=\"%s\" alt=\"%s\" height=\"40%%\">' % (filename, filename))\n",
    "\n",
    "def create_report(filename):\n",
    "    global report\n",
    "    report = report.replace('<table border=\"1\" class=\"dataframe\">','<table class=\"table table-striped\">')\n",
    "    html_string = '''\n",
    "        <html>\n",
    "            <head>\n",
    "                <link rel=\"stylesheet\" href=\"skeleton.css\">\n",
    "                <style>body{ margin:20 20; background:whitesmoke; }\n",
    "                table {table-layout : fixed}\n",
    "                </style>\n",
    "            </head>\n",
    "            <body>                \n",
    "                %s\n",
    "            </body>\n",
    "        </html>''' % (report)\n",
    "    f = open(filename,'w', encoding='utf-8-sig')\n",
    "    f.write(html_string)\n",
    "    f.close()\n",
    "    print('Report created: %s' % filename)\n",
    "    \n",
    "def create_zip(filename):\n",
    "    zip_filename = filename[:-5] + '.zip'\n",
    "    zf = zipfile.ZipFile(zip_filename, mode='w')\n",
    "    try:\n",
    "        #print 'Отчет заархивирован в файл'\n",
    "        zf.write(filename)\n",
    "        zf.write('report\\skeleton.css')\n",
    "    finally:\n",
    "        print('Zip-file created: %s' % zip_filename)\n",
    "        zf.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: resources/others/Иркутск-Сорт_(нечет_отправление)_ Период28июн 10_30-29июн 10_30(VSD).xlsx\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if len(sys.argv) > 1:\n",
    "    filename = sys.argv[1]    \n",
    "else:\n",
    "    filename = 'resources/others/Иркутск-Сорт_(нечет_отправление)_ Период28июн 10_30-29июн 10_30(VSD).xlsx'\n",
    "    \n",
    "if ('xls' not in filename) & ('csv' not in filename):\n",
    "    filename = 'resources/others/Иркутск-Сорт_(нечет_отправление)_ Период28июн 10_30-29июн 10_30(VSD).xlsx'\n",
    "    \n",
    "print('Filename:', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Анализ файла %s' % filename, h=2, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(filename, header=2)\n",
    "df = df[['П/п', 'Номер', 'Индекс', 'Время', 'Вес']]\n",
    "df.columns = ['n', 'number', 'ind', 'time', 'weight']\n",
    "max_train_idx = df[df.n.apply(lambda x: '-' in str(x))].index.min()\n",
    "df = df.ix[:max_train_idx - 1]\n",
    "df['ind'] = df.ind.apply(lambda x: x.replace(' ', '-'))\n",
    "df['ind_part'] = df.ind.apply(lambda x: x[:-5])\n",
    "stations['esr4'] = stations.esr.apply(lambda x: (str(x))[:4])\n",
    "df['start_esr'] = df.ind.apply(lambda x: x[:4])\n",
    "df['end_esr'] = df.ind.apply(lambda x: x[-4:])\n",
    "df['start_name'] = df.start_esr.map(stations.drop_duplicates('esr4').set_index('esr4').name)\n",
    "df['end_name'] = df.end_esr.map(stations.drop_duplicates('esr4').set_index('esr4').name)\n",
    "add_header('Все поезда из ГИДа:')\n",
    "add_line(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пробуем просто найти поезда по индексу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['train_id'] = df.ind.map(train_info.set_index('ind434').train)\n",
    "good = df[df.train_id.isnull() == False].ind.count()\n",
    "bad = df[df.train_id.isnull()].ind.count()\n",
    "total = df.ind.count()\n",
    "add_header('Поиск поездов по индексу')\n",
    "add_line('Найдено поездов по индексу: %d из %d' % (good, total))\n",
    "add_line('Не найдено поездов: %d' % bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пробуем найти поезда по части индекса (без хвоста)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_info['ind_part'] = train_info.ind434.apply(lambda x: x[:-5])\n",
    "train_info.groupby('ind_part').train.unique()\n",
    "df['susp_trains'] = df.ind_part.map(train_info.groupby('ind_part').train.unique())\n",
    "df.train_id.fillna(df.susp_trains, inplace=True)\n",
    "good = df[df.train_id.isnull() == False].ind.count()\n",
    "bad = df[df.train_id.isnull()].ind.count()\n",
    "add_line('Найдено поездов по индексу и части индекса: %d из %d' % (good, total))\n",
    "add_line('Не найдено поездов: %d' % bad)\n",
    "add_line('Примеры найденных поездов:')\n",
    "add_line(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Из оставшихся выбираем поезда своего формирования (они будут созданы из ССП)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.train_id.isnull()]\n",
    "irk = df[(df.train_id.isnull()) & (df.start_esr == '9300')].ind.count()\n",
    "bad = df[(df.train_id.isnull()) & (df.start_esr != '9300')].ind.count()\n",
    "add_header('Поиск поездов своего формирования (станция Иркутск)')\n",
    "add_line('Найдено поездов своего формирования: %d' % irk)\n",
    "add_line('Всего найдено поездов: %d из %d' % (total - bad, total))\n",
    "add_line('Не найдено поездов: %d' % bad)\n",
    "add_line('Примеры найденных поездов:')\n",
    "add_line(df[(df.train_id.isnull()) & (df.start_esr == '9300')].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смотрим, какие поезда остались не найденными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Оставшиеся поезда')\n",
    "add_line(df[(df.train_id.isnull()) & (df.start_esr != '9300')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Убираем поезда с близких станций формирования (начинающиеся на 93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Без поездов с близких станций формирования:')\n",
    "not_found = df[(df.train_id.isnull()) & (df.start_esr.apply(lambda x: x[:2] != '93'))]\n",
    "add_line(not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем csv с отсевами, ищем непереданные в планировщик поезда там"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otsev = pd.read_csv('./resources/others/otsev_detail.csv', sep=';',\n",
    "                    dtype={'train_index':str, 'train_id':str, 'loco_id':str, 'team_id':str})\n",
    "otsev['ind434'] = otsev['train_index'].apply(lambda x: str(x)[:4] + '-' + str(x)[6:9] + '-' + str(x)[9:-2])\n",
    "otsev['time'] = otsev.time.apply(lambda x: x[:-3])\n",
    "pd.set_option('display.max_colwidth', 35)\n",
    "add_header('Проблемные поезда в логах отсевов')\n",
    "add_line(otsev[otsev.ind434.isin(not_found.ind)].sort_values('ind434').sort_values(['train_index', 'time'])\\\n",
    "    [['uns', 'train_index', 'loco_id', 'team_id', 'location_name', 'type_name', 'time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Данные по проблемным поездам в логах отсевов (поиск по части индекса)')\n",
    "otsev['ind434_part'] = otsev.ind434.apply(lambda x: x[:-5])\n",
    "a = otsev[(otsev.ind434.isin(not_found.ind) == False) \n",
    "             & (otsev.ind434_part.isin(not_found.ind_part))].sort_values('ind434')\\\n",
    "                [['train_id', 'train_index', 'ind434', 'out', 'otsev_list']].dropna(subset=['out'])\n",
    "add_line(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Непереданные поезда, которых нет и в логах отсевов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['number', 'ind', 'time', 'weight', 'start_name', 'end_name']\n",
    "add_header('Оставшиеся поезда, которых нет и в логах отсевов')\n",
    "add_line(not_found[not_found.ind_part.isin(otsev.ind434_part) == False][cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report created: report/train_GID_20160630_152549.html\n",
      "Zip-file created: report/train_GID_20160630_152549.zip\n"
     ]
    }
   ],
   "source": [
    "filename = REPORT_FOLDER + 'train_GID_' + time.strftime('%Y%m%d_%H%M%S', time.localtime(time.time())) + '.html'\n",
    "create_report(filename)\n",
    "create_zip(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
