{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание файла с модельными входными данными\n",
    "\n",
    "Тестовый полигон представляет из себя фрагмент сети между станциями Тайшет и Таксимо. Войтенко П.Е. была создана таблица с набором поездов, локомотивов и бригад, которые планировались к движению по этому фрагменту на сутки 30.07.2015. Данный скрипт из этой таблицы, а также из не меняющейся нормативно-справочной информации создает файл `jason-FullPlannerPlugin_model.log`, на котором можно запускать планировщик и проверять его работу на этом модельном сценарии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Необходимые файлы](#Необходимые-файлы)\n",
    "1. [Алгоритм работы](#Алгоритм-работы)\n",
    "1. [Формирование данных по поездам](#Формирование-данных-по-поездам)\n",
    "1. [Формирование данных по локомотивам](#Формирование-данных-по-локомотивам)\n",
    "1. [Формирование данных по бригадам](#Формирование-данных-по-бригадам)\n",
    "1. [Формирование данных по станциям](#Формирование-данных-по-станциям)\n",
    "1. [Формирование данных по участкам планирования](#Формирование-данных-по участкам-планирования)\n",
    "1. [Формирование данных по пунктам ТО](#Формирование-данных-по-пунктам-ТО)\n",
    "1. [Формирование данных по участкам обслуживания бригад](#Формирование-данных-по-участкам-обслуживания-бригад)\n",
    "1. [Формирование данных по весовым нормам](#Формирование-данных-по-весовым-нормам)\n",
    "1. [Формирование данных по участкам обкатки бригад](#Формирование-данных-по-участкам-обкатки-бригад)\n",
    "1. [Формирование данных по ниткам](#Формирование-данных-по-ниткам)\n",
    "1. [Добавление заголовков и создание итогового файла](#Добавление-заголовков-и-создание-итогового-файла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необходимые файлы\n",
    "\n",
    "1. Путь к таблице Войтенко П.Е. указывается в переменной `input_filename`.\n",
    "2. Путь к папке, в которой будут храниться промежуточные файлы сценария и итоговый файл с входными данными, указывается в переменной `TEST_FOLDER` (для корректной работы папка `TEST_FOLDER` должна быть уже создана).\n",
    "3. Дополнительные файлы, которые используются при формировании входных данных, должны лежать в папке `TEST_FOLDER`:\n",
    "  * файл `paths_id.csv` с путями между всеми станциями планирования.\n",
    "  * файл `test_stations.xlsx` со списком станций модельного полигона.\n",
    "  * файл `jason-FullPlannerPlugin.log` с реальными данными какого-либо запуска планировщика.\n",
    "3. Сsv-файлы, полученные в результате работы скрипта `read.py`, должны лежать в папке `FOLDER`. Оттуда нужны файлы `link.csv`, `station.csv` и `loco_series.csv`.\n",
    "\n",
    "### Алгоритм работы\n",
    "\n",
    "1. Все данные по поездам (`train_info`, `train_depart`, `train_arrive`, `train_ready`), локомотивам (`loco_attributes`, `fact_loco_next_service`) и бригадам (`team_attributes`, `fact_team_ready`, `fact_team_location`) формируются из данных таблицы Войтенко.\n",
    "2. Данные по станциям (сообщения `station`) берутся из файла `test_stations.xlsx`. В станциях заменяются id тяговых плеч.\n",
    "3. Данные по участкам планирования (сообщения `link`) берутся из реальных данных и обрезаются в соответствии с тестовым полигоном.\n",
    "4. Весовые нормы (`loco_tonnage`) и пункты ТО (`service_station`) берутся из реальных данных и обрезаются в соответствии с данными тестового полигона (остаются данные только по нужным сериям локомотивов).\n",
    "  1. Поскольку на участке Тайшет - Таксимо есть участки подталкивания, на которых весовые ограничения для одного локомотива довольно маленькие, то в тех случаях, когда максимальный вес для всех серий/секций на каком-то участке меньше 4000, он заменяется на 6000.\n",
    "5. Нитки (грузовые и пассажирские - `slot`, `slot_pass`) берутся из реальных данных и сдвигаются по времени с 00:00 29.07.2015 до 23:59 30.07.2015.\n",
    "6. Участки обкатки бригад (`team_work_region`) формируются скриптом. Из данных Войтенко берутся границы участков обкатки для каждой бригады, ищутся все участки планирования между этими границами. Формируются строки team_work_region с нужными id и набором треков.\n",
    "7. Участки обслуживания бригад (`team_region`) полностью копируются из реальных данных.\n",
    "8. Данные по каждой сущности записываются в отдельные csv-файлы, затем они собираются вместе в один выходной файл `jason-FullPlannerPlugin_model.log`.\n",
    "\n",
    "### Как запускать\n",
    "\n",
    "В принципе, все должно работать \"из коробки\", достаточно только убедиться, что нужные файлы лежат по нужным путям. Далее надо запустить последовательно два батника:\n",
    "* **`create_scenario_data.bat`** - подчистит все скрипты с помощью `release.bat`, запустит `read.py`, чтобы создать актуальные csv-файлы, затем запустит данный скрипт для создания имитационного файла и скопирует его в папку `./jar`.\n",
    "* **`run_scenario_trace.bat`** - запустит планировщик из папки `/jar` (в ней, разумеется, должен лежать актуальный файл `JADEPlanner.jar`) с максимальным уровнем логирования (TRACE), затем создаст файл `log_for_analysis.log` (в нем будут входные данные из `jason-FullPlannerPlugin.log` и только что полученные результаты планирования), скопирует его в папку `./input` и запустит скрипт `read.py log_for`, чтобы создать csv уже с новыми данными.\n",
    "\n",
    "После этого полученный расчет можно анализировать обычными тестовыми скриптами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER = 'resources/'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "\n",
    "time_format = '%b %d, %H:%M'\n",
    "\n",
    "#twr          = pd.read_csv(FOLDER + 'team_work_region.csv', converters={'twr':str})\n",
    "links        = pd.read_csv(FOLDER + 'link.csv')\n",
    "stations     = pd.read_csv(FOLDER + 'station.csv', converters={'station':str})\n",
    "loco_series  = pd.read_csv(FOLDER + 'loco_series.csv')\n",
    "\n",
    "st_names = stations[['station', 'name', 'esr']].drop_duplicates().set_index('station')\n",
    "\n",
    "def add_info(df):    \n",
    "    if 'st_from' in df.columns:\n",
    "        df['st_from_name'] = df.st_from.map(st_names.name)\n",
    "    if 'st_to' in df.columns:\n",
    "        df['st_to_name'] = df.st_to.map(st_names.name)\n",
    "    if 'time_start' in df.columns:\n",
    "        df['time_start_norm'] = df.time_start.apply(lambda x: time.strftime(time_format, time.localtime(x)))\n",
    "    if 'time_end' in df.columns:\n",
    "        df['time_end_norm'] = df.time_end.apply(lambda x: time.strftime(time_format, time.localtime(x)))\n",
    "    if 'oper_location' in df.columns:\n",
    "        df['oper_location_name'] = df.oper_location.map(st_names.name)    \n",
    "        df.oper_location_name.fillna(0, inplace=True)\n",
    "    if ('oper_location' in df.columns) & ('st_from' in df.columns) & ('st_to' in df.columns):        \n",
    "        df['loc_name'] = df.oper_location_name\n",
    "        df.loc[df.loc_name == 0, 'loc_name'] = df.st_from_name + ' - ' + df.st_to_name\n",
    "\n",
    "def nice_time(t):\n",
    "    #if not time_format: time_format = '%b %d, %H:%M'\n",
    "    return time.strftime(time_format, time.localtime(t)) if t > 0 else ''\n",
    "\n",
    "def nice_print(s, **kwargs):    \n",
    "    num = kwargs['num'] if 'num' in kwargs.keys() else False\n",
    "    cols = kwargs['cols'] if 'cols' in kwargs.keys() else s.columns\n",
    "    if num:\n",
    "        print(s.reset_index()[cols].to_string())\n",
    "    else:\n",
    "        print(s[cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_FOLDER = './test_scenario/'\n",
    "input_filename = './input/(Новые) 2.11.xlsx'\n",
    "paths = pd.read_csv(TEST_FOLDER + 'paths_id.csv', sep=';')\n",
    "stations = pd.read_csv(TEST_FOLDER + 'full_stations.csv', dtype={'station':str})\n",
    "st_names = stations.drop_duplicates('station').set_index('station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по поездам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>number</th>\n",
       "      <th>ind</th>\n",
       "      <th>weight</th>\n",
       "      <th>length</th>\n",
       "      <th>st_first</th>\n",
       "      <th>st_end</th>\n",
       "      <th>oper_id</th>\n",
       "      <th>oper_time</th>\n",
       "      <th>oper_st</th>\n",
       "      <th>st_from</th>\n",
       "      <th>st_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1002012</td>\n",
       "      <td>2012</td>\n",
       "      <td>8937-201-9244</td>\n",
       "      <td>4000</td>\n",
       "      <td>70</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036796</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-29 17:36:00</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1002014</td>\n",
       "      <td>2014</td>\n",
       "      <td>8937-202-9257</td>\n",
       "      <td>5600</td>\n",
       "      <td>66</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036868</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-29 19:06:00</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1002016</td>\n",
       "      <td>2016</td>\n",
       "      <td>8937-203-9044</td>\n",
       "      <td>4100</td>\n",
       "      <td>71</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036228</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-29 20:06:00</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1002018</td>\n",
       "      <td>2018</td>\n",
       "      <td>8937-204-9271</td>\n",
       "      <td>4000</td>\n",
       "      <td>72</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036932</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-29 21:06:00</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1002020</td>\n",
       "      <td>2020</td>\n",
       "      <td>8937-205-9044</td>\n",
       "      <td>5600</td>\n",
       "      <td>70</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036228</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-29 22:06:00</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  number            ind  weight  length    st_first      st_end  \\\n",
       "7   1002012    2012  8937-201-9244    4000      70  2000036018  2000036796   \n",
       "8   1002014    2014  8937-202-9257    5600      66  2000036018  2000036868   \n",
       "9   1002016    2016  8937-203-9044    4100      71  2000036018  2000036228   \n",
       "10  1002018    2018  8937-204-9271    4000      72  2000036018  2000036932   \n",
       "11  1002020    2020  8937-205-9044    5600      70  2000036018  2000036228   \n",
       "\n",
       "    oper_id           oper_time     oper_st     st_from       st_to  \n",
       "7         2 2015-07-29 17:36:00  2000036538  2000036538  2000036518  \n",
       "8         2 2015-07-29 19:06:00  2000036538  2000036538  2000036518  \n",
       "9         2 2015-07-29 20:06:00  2000036538  2000036538  2000036518  \n",
       "10        2 2015-07-29 21:06:00  2000036538  2000036538  2000036518  \n",
       "11        2 2015-07-29 22:06:00  2000036538  2000036538  2000036518  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(input_filename, header=1)\n",
    "df.dropna(subset=['Номер поезда'], inplace=True)\n",
    "df.drop(['поезд'], axis=1, inplace=True)\n",
    "df.columns = ['train_id', 'number', 'ind', 'weight', 'length', \n",
    "              'st_first', 'st_end', 'oper_id', 'oper_time', 'oper_st', 'st_from', 'st_to', 'comm']\n",
    "df['oper_time'] = df.oper_time.apply(pd.to_datetime)\n",
    "df.drop(['comm'], axis=1, inplace=True)\n",
    "df['st_first'] = df.st_first.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df['st_end'] = df.st_end.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df['oper_st'] = df.oper_st.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df['st_from'] = df.st_from.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df['st_to'] = df.st_to.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2000036538, 2000036518]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Датафрейм с путями преобразуем в словарь. Это не обязательно, просто так чуть проще обращаться к нему для поиска.\n",
    "# Можно ограничиться просто set_index на датафрейм.\n",
    "\n",
    "paths = paths.dropna(how='any')\n",
    "d = paths.set_index(['ST_FROM', 'ST_TO'])[['ROUTE']].to_dict()['ROUTE']\n",
    "[int(float(i)) for i in d[2000036538, 2000036518].split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_info(x, paths):    \n",
    "    st_from = int(x['oper_st'])\n",
    "    st_to = int(x['st_end'])\n",
    "    try:\n",
    "        route = paths[(paths.ST_FROM == st_from) & (paths.ST_TO == st_to)].ROUTE.values[0].split(',')        \n",
    "    except:\n",
    "        print(x, st_from, st_to, paths[(paths.ST_FROM == st_from) & (paths.ST_TO == st_to)].columns)\n",
    "        route = ''\n",
    "    r_str = ','.join(['station(%s)' % r[:-2] for r in route])    \n",
    "    return '+train_info(id(%s),info([number(%s),category(%s),weight(%s),length(%s),routes([route([%s])]),joint(-1)]))' %\\\n",
    "     (x.train_id, int(x.number), 2, int(x.weight), int(x.length), r_str)\n",
    "        \n",
    "a = df.apply(lambda x: get_train_info(x, paths), axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'train_info.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "def get_oper(x):\n",
    "    ts = int(round(x.oper_time.timestamp()))\n",
    "    if x.oper_id == 2:\n",
    "        r = [int(float(i)) for i in d[int(x.st_from), int(x.st_to)].split(',')[:2]]\n",
    "        s = '+train_depart(id(%s),track(station(%s),station(%s)),time(%s))' % (x.train_id, r[0], r[1], ts)       \n",
    "    elif x.oper_id == 5:\n",
    "        s = '+train_ready(id(%s),station(%s),time(%s))' % (x.train_id, x.oper_st, ts)\n",
    "    else:        \n",
    "        r = [int(float(i)) for i in d[int(x.st_from), int(x.st_to)].split(',')[-2:]]\n",
    "        #print(x.train_id, x.st_from, x.st_to, r)\n",
    "        s = '+train_arrive(id(%s),track(station(%s),station(%s)),time(%s))' % (x.train_id, r[0], r[1], ts)\n",
    "    return s        \n",
    "    \n",
    "a = df.apply(lambda x: get_oper(x), axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'train_oper.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по локомотивам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loco_id</th>\n",
       "      <th>number</th>\n",
       "      <th>ser_name</th>\n",
       "      <th>depot_st</th>\n",
       "      <th>sections</th>\n",
       "      <th>regions</th>\n",
       "      <th>tts</th>\n",
       "      <th>dts</th>\n",
       "      <th>tr_dts</th>\n",
       "      <th>oper</th>\n",
       "      <th>oper_time</th>\n",
       "      <th>oper_st</th>\n",
       "      <th>st_from</th>\n",
       "      <th>st_to</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001502</td>\n",
       "      <td>1502</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>3</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>2015-07-29 16:50:00</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001503</td>\n",
       "      <td>1503</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>3</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>2015-07-29 17:20:00</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001505</td>\n",
       "      <td>1505</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>3</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-29 17:36:00</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>1002012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001506</td>\n",
       "      <td>1506</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>3</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-29 19:06:00</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>1002014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001507</td>\n",
       "      <td>1507</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>3</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-29 20:06:00</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>1002016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loco_id  number ser_name    depot_st  sections regions  tts   dts  tr_dts  \\\n",
       "4  2001502    1502    ВЛ80Р  2000036018         3   С0-С1   40  2000       0   \n",
       "5  2001503    1503    ВЛ80Р  2000036018         3   С0-С1   40  2000       0   \n",
       "7  2001505    1505    ВЛ80Р  2000036018         3   С0-С1   40  2000       0   \n",
       "8  2001506    1506    ВЛ80Р  2000036018         3   С0-С1   40  2000       0   \n",
       "9  2001507    1507    ВЛ80Р  2000036018         3   С0-С1   40  2000       0   \n",
       "\n",
       "   oper           oper_time     oper_st     st_from       st_to  train_id  \n",
       "4    64 2015-07-29 16:50:00  2000036518  2000036518  2000036518         0  \n",
       "5    64 2015-07-29 17:20:00  2000036518  2000036518  2000036518         0  \n",
       "7     5 2015-07-29 17:36:00  2000036538  2000036538  2000036518   1002012  \n",
       "8     5 2015-07-29 19:06:00  2000036538  2000036538  2000036518   1002014  \n",
       "9     5 2015-07-29 20:06:00  2000036538  2000036538  2000036518   1002016  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loco = pd.read_excel(input_filename, header=1, sheetname='ЛОК')\n",
    "df_loco.dropna(subset=['Борт НОМЕР'], inplace=True)\n",
    "df_loco.drop(['ЛОК'], axis=1, inplace=True)\n",
    "#print(df_loco.head())\n",
    "df_loco.columns = ['loco_id', 'number', 'ser_name', 'depot_st', 'sections', \n",
    "              'regions', 'tts', 'dts', 'tr_dts', 'oper', 'oper_time', 'oper_st', 'st_from', 'st_to', 'train_id', 'comm', 'sokr']\n",
    "df_loco['oper_time'] = df_loco.oper_time.apply(pd.to_datetime)\n",
    "df_loco.drop(['comm', 'sokr'], axis=1, inplace=True)\n",
    "df_loco['depot_st'] = df_loco.depot_st.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_loco['oper_st'] = df_loco.oper_st.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_loco['st_from'] = df_loco.st_from.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_loco['st_to'] = df_loco.st_to.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_loco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_loco_info(x):\n",
    "    ser_id = loco_series[loco_series.ser_name == x.ser_name].ser_id.values[0]\n",
    "    reg_id = ''.join([i for i in x.regions if i.isnumeric()])\n",
    "    return '+loco_attributes(id(%s),attributes([series(%s),loco_regions([id(%s)]),depot(station(%s)),sections(%s),type(1)]))' %\\\n",
    "    (x.loco_id, ser_id, reg_id, x.depot_st, int(x.sections))\n",
    "        \n",
    "a = df_loco.apply(lambda x: get_loco_info(x), axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'loco_attr.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loco_location(x):\n",
    "    ts = int(round(x.oper_time.timestamp()))\n",
    "    if x.oper == 5:        \n",
    "        state = 1\n",
    "        r = [int(float(i)) for i in d[int(x.st_from), int(x.st_to)].split(',')[:2]]\n",
    "        return '+fact_loco(id(%s),fact_time(%s),location(track(station(%s),station(%s),depart_time(%s),state(%s),train(%s))))' %\\\n",
    "            (x.loco_id, ts, r[0], r[1], ts, state, int(x.train_id))\n",
    "    elif x.oper in [64, 40, 94]:\n",
    "        return '+fact_loco(id(%s),fact_time(%s),location(station(%s)))' %\\\n",
    "            (x.loco_id, ts, x.oper_st)\n",
    "    elif x.oper in [1, 26]:\n",
    "        return '+fact_loco(id(%s),fact_time(%s),location(station(%s),arrive_time(%s),state(%s),train(%s)))' % \\\n",
    "            (x.loco_id, ts, x.oper_st, ts, 1, int(x.train_id))\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "a = df_loco.apply(lambda x: get_loco_location(x), axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'loco_location.csv', index=False, sep=';')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loco_service(x):\n",
    "    ts = int(round(x.oper_time.timestamp()))\n",
    "    return '+fact_loco_next_service(id(%s),fact_time(%s),next_service(dist_to(%s),time_to(%s),type(2001889869)))' %\\\n",
    "    (x.loco_id, ts, int(x.dts), int(x.tts) * 3600)\n",
    "        \n",
    "a = df_loco.apply(lambda x: get_loco_service(x), axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'loco_service.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по бригадам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "В таблице Войтенко приведены коды депо приписок бригад. Депо, в общем случае, отличается от станций планирования, используемых\n",
    "в планировщике. Поэтому надо установить соответствие между ЕСР-кодом депо и ЕСР-кодом соответствующей (ближайшей) станции \n",
    "планирования.\n",
    "'''\n",
    "\n",
    "depot_st_dict = {318803:89370, 319212:90320, 359276:90440, 319201:92000, 319209:92440, 319210:92710, 359271:92570}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>depot_st</th>\n",
       "      <th>ready_st</th>\n",
       "      <th>name</th>\n",
       "      <th>number</th>\n",
       "      <th>ser_name</th>\n",
       "      <th>long</th>\n",
       "      <th>heavy</th>\n",
       "      <th>region</th>\n",
       "      <th>ready_time</th>\n",
       "      <th>...</th>\n",
       "      <th>oper_st</th>\n",
       "      <th>st_from</th>\n",
       "      <th>st_to</th>\n",
       "      <th>train_id</th>\n",
       "      <th>loco_id</th>\n",
       "      <th>depot_ready_time</th>\n",
       "      <th>depot_ready_st</th>\n",
       "      <th>return_ready_time</th>\n",
       "      <th>return_ready_st</th>\n",
       "      <th>rest_start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8800002</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>МЯСНИКОВ И.И.</td>\n",
       "      <td>8803-000 155</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-07-29 07:30:00</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2015-07-29 19:00:00</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>2015-07-29 15:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8800003</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>ГРИЩЕНКО А.В.</td>\n",
       "      <td>8803-000 233</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-07-29 08:30:00</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2015-07-29 20:00:00</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>2015-07-29 16:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8800005</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>ШИНКОРЕНКО А.П.</td>\n",
       "      <td>8803-000 622</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>2015-07-29 14:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>1002012</td>\n",
       "      <td>2001505</td>\n",
       "      <td>2015-07-29 14:00:00</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8800006</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>ЛЕОНОВИЧ П.А.</td>\n",
       "      <td>8803-000 628</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>2015-07-29 15:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>1002014</td>\n",
       "      <td>2001506</td>\n",
       "      <td>2015-07-29 15:30:00</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8800007</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>БЕЗГИНСКИЙ Э.В.</td>\n",
       "      <td>8803-000 735</td>\n",
       "      <td>ВЛ80Р</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>С0-С1</td>\n",
       "      <td>2015-07-29 16:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036538</td>\n",
       "      <td>2000036518</td>\n",
       "      <td>1002016</td>\n",
       "      <td>2001507</td>\n",
       "      <td>2015-07-29 16:30:00</td>\n",
       "      <td>2000036018</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_id    depot_st    ready_st             name        number ser_name  \\\n",
       "1  8800002  2000036018  2000036018    МЯСНИКОВ И.И.  8803-000 155    ВЛ80Р   \n",
       "2  8800003  2000036018  2000036018    ГРИЩЕНКО А.В.  8803-000 233    ВЛ80Р   \n",
       "7  8800005  2000036018  2000036018  ШИНКОРЕНКО А.П.  8803-000 622    ВЛ80Р   \n",
       "8  8800006  2000036018  2000036018    ЛЕОНОВИЧ П.А.  8803-000 628    ВЛ80Р   \n",
       "9  8800007  2000036018  2000036018  БЕЗГИНСКИЙ Э.В.  8803-000 735    ВЛ80Р   \n",
       "\n",
       "   long  heavy region           ready_time         ...              oper_st  \\\n",
       "1     1      1  С0-С1                    0         ...           2000036518   \n",
       "2     1      1  С0-С1                    0         ...           2000036518   \n",
       "7     1      1  С0-С1  2015-07-29 14:00:00         ...           2000036538   \n",
       "8     1      1  С0-С1  2015-07-29 15:30:00         ...           2000036538   \n",
       "9     1      1  С0-С1  2015-07-29 16:30:00         ...           2000036538   \n",
       "\n",
       "      st_from       st_to train_id  loco_id     depot_ready_time  \\\n",
       "1  2000036018  2000036518       -1       -1  2015-07-29 07:30:00   \n",
       "2  2000036018  2000036518       -1       -1  2015-07-29 08:30:00   \n",
       "7  2000036538  2000036518  1002012  2001505  2015-07-29 14:00:00   \n",
       "8  2000036538  2000036518  1002014  2001506  2015-07-29 15:30:00   \n",
       "9  2000036538  2000036518  1002016  2001507  2015-07-29 16:30:00   \n",
       "\n",
       "   depot_ready_st    return_ready_time return_ready_st      rest_start_time  \n",
       "1      2000036018  2015-07-29 19:00:00      2000036518  2015-07-29 15:10:00  \n",
       "2      2000036018  2015-07-29 20:00:00      2000036518  2015-07-29 16:10:00  \n",
       "7      2000036018                   -1              -1                   -1  \n",
       "8      2000036018                   -1              -1                   -1  \n",
       "9      2000036018                   -1              -1                   -1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_team = pd.read_excel(input_filename, header=1, sheetname='ЛБР')\n",
    "df_team.dropna(subset=['Таб.номер'], inplace=True)\n",
    "df_team.drop(['ЛБР'], axis=1, inplace=True)\n",
    "df_team.columns = ['team_id', 'depot_st', 'ready_st', 'name', 'number', \n",
    "                  'ser_name', 'long', 'heavy', 'region', 'ready_time', 'oper_id', 'oper_time', 'oper_st', 'st_from', 'st_to',\n",
    "                  'train_id', 'loco_id', 'depot_ready_time', 'depot_ready_st', 'return_ready_time', 'return_ready_st', \n",
    "                  'rest_start_time']\n",
    "df_team['oper_time'] = df_team.oper_time.apply(pd.to_datetime)\n",
    "df_team['depot_ready_time'] = df_team.depot_ready_time.apply(lambda x: pd.to_datetime(x) if x !=0 else -1)\n",
    "df_team['return_ready_time'] = df_team.return_ready_time.apply(lambda x: pd.to_datetime(x) if x !=0 else -1)\n",
    "df_team['rest_start_time'] = df_team.rest_start_time.apply(lambda x: pd.to_datetime(x) if x !=0 else -1)\n",
    "\n",
    "df_team['oper_st'] = df_team.oper_st.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_team['st_from'] = df_team.st_from.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_team['st_to'] = df_team.st_to.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_team['depot_ready_st'] = df_team.depot_ready_st.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_team['return_ready_st'] = df_team.return_ready_st.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_team['depot_ready_st'].fillna(-1, inplace=True)\n",
    "df_team['return_ready_st'].fillna(-1, inplace=True)\n",
    "\n",
    "df_team.depot_st.replace(depot_st_dict, inplace=True)\n",
    "df_team.ready_st.replace(depot_st_dict, inplace=True)\n",
    "df_team['depot_st'] = df_team.depot_st.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "df_team['ready_st'] = df_team.ready_st.map(stations.drop_duplicates('esr').set_index('esr').station)\n",
    "\n",
    "df_team.train_id.replace(0, -1, inplace=True)\n",
    "df_team.loco_id.replace(0, -1, inplace=True)\n",
    "df_team.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21    1438232760\n",
       "Name: oper_time, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_team[df_team.team_id == 8800019].oper_time.apply(lambda x: int(round(x.timestamp())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_team_info(x):\n",
    "    ser_list = x.ser_name.split('; ')\n",
    "    try:\n",
    "        ser_id = loco_series[loco_series.ser_name.isin(ser_list)].ser_id.unique()\n",
    "    except:\n",
    "        ser_id = -1\n",
    "    series = ','.join(['id(%s)' % s for s in ser_id])\n",
    "    reg_id = ''.join([i for i in x.region if i.isnumeric()])\n",
    "    return '+team_attributes(id(%s),attributes([team_work_regions([id(%s)]),depot(station(%s)),loco_series([%s]),long_train(%s),heavy_train(%s),fake(0),type(1)]))' %\\\n",
    "    (x.team_id, reg_id, x.ready_st, series, int(x.long), int(x.heavy))\n",
    "        \n",
    "a = df_team.apply(lambda x: get_team_info(x), axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'team_attr.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_team_ready(x):\n",
    "    try:\n",
    "        depot_ts = int(round(x.depot_ready_time.timestamp())) if x.depot_ready_time != -1 else -1\n",
    "        return_ts = int(round(x.return_ready_time.timestamp()))  if x.return_ready_time != -1 else -1\n",
    "        rest_start_ts = int(round(x.rest_start_time.timestamp()))  if x.rest_start_time != -1 else -1\n",
    "    except:\n",
    "        depot_ts, return_ts, rest_start_ts = -1, -1, -1\n",
    "        print(x.team_id, x.depot_ready_time, x.return_ready_time, x.rest_start_time)\n",
    "    if (x.return_ready_time == -1):\n",
    "        last_ready = 'depot'\n",
    "    elif (x.depot_ready_time == -1):\n",
    "        last_ready = 'return'\n",
    "    else:\n",
    "        last_ready = 'depot' if depot_ts >= return_ts else 'return'    \n",
    "    return '+fact_team_ready(id(%s),ready_depot(time(%s),station(%s)),ready_return(time(%s),station(%s)),last_ready(%s),rest_start_time(%s))' %\\\n",
    "    (x.team_id, depot_ts, x.depot_ready_st, return_ts, x.return_ready_st, last_ready, rest_start_ts)\n",
    "        \n",
    "a = df_team.apply(lambda x: get_team_ready(x), axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'team_ready.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Словарь, в котором ключами являются состояния бригад (0...9), а значениями - коды последних операций с бригадами, которые\n",
    "# соответствуют этому состоянию. Подробнее можно посмотреть в документе \"Алгортим планирования\", раздел 4.3.2.\n",
    "\n",
    "states = {0:[33], 1:[2, 3], 2:[28, 30], 3:[31, 54], 4:[37], 5:[24, 26, 43], 6:[1, 42], 7:[34], 8:[35, 38], 9:[25, 41]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_team_location(x):\n",
    "    oper_time_ts = int(round(x.oper_time.timestamp()))    \n",
    "    try:\n",
    "        state = [key for key, value in states.items() if x.oper_id in value][0]\n",
    "    except:\n",
    "        state = -1\n",
    "        print(x.oper_id)\n",
    "        \n",
    "    if state in [0, 1]:\n",
    "        r = [int(float(i)) for i in d[int(x.st_from), int(x.st_to)].split(',')[:2]]\n",
    "        s = '+fact_team_location(id(%s),fact_time(%s),location(track(station(%s),station(%s))),oper_time(%s),loco(%s),pass_slot(-1),state(%s))' %\\\n",
    "            (x.team_id, oper_time_ts, r[0], r[1], oper_time_ts, int(x.loco_id), state)\n",
    "    else:\n",
    "        s = '+fact_team_location(id(%s),fact_time(%s),location(station(%s)),oper_time(%s),loco(%s),state(%s))' %\\\n",
    "            (x.team_id, oper_time_ts, x.oper_st, oper_time_ts, int(x.loco_id), state)    \n",
    "    return s\n",
    "        \n",
    "a = df_team.apply(lambda x: get_team_location(x), axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'team_location.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по станциям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_station(x):\n",
    "    s = '+station(id(%s),loco_region(%s),service([]),norm_reserve([norm(weight_type(0),0),norm(weight_type(1),0)]),norm_time(%s))' %\\\n",
    "        (x.station, x.loco_region, x.norm_time)\n",
    "    return s\n",
    "\n",
    "test_stations = pd.read_excel(TEST_FOLDER + 'test_stations.xlsx', converters={'loco_region':str, 'station':str})\n",
    "a = test_stations.apply(get_station, axis=1)\n",
    "a.to_csv(TEST_FOLDER + 'station.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по участкам планирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_links(x):\n",
    "    return '+link(track(station(%s),station(%s)),attributes([duration(%s),distance(%s),push(0),direction(%s),lines(%s),road(%s)]))' \\\n",
    "        % (x.st_from, x.st_to, x.time, x.dist, x['dir'], x.lines, x.road)\n",
    "\n",
    "links = pd.read_csv(FOLDER + 'link.csv', dtype={'st_from':str, 'st_to':str})\n",
    "l = links[(links.st_from.isin(test_stations.station)) & (links.st_to.isin(test_stations.station))]\n",
    "l.apply(get_links, axis=1).to_csv(TEST_FOLDER + 'link.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по пунктам ТО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "На реальном полигоне пункты ТО есть на всех крупных станциях модельного полигона, кроме станции Новый Уоян. Чтобы усложнить \n",
    "задачу планировщику и приблизить ситуацию к реальной, было решено сделать пункты ТО с приоритетом 1 на границах тяговых плеч\n",
    "и один пункт ТО с приоритетом 2 в середине плеча (Вихоревка). \n",
    "При возврате к реальным пунктам ТО надо учесть серии локомотивов, которые работают на модельном полигоне. Их можно посмотреть в \n",
    "экселевской таблице (сейчас там есть только локомотивы серий ВЛ80Р и 3ЭС5К).\n",
    "'''\n",
    "\n",
    "PTOL_MODEL = {'ВЛ80Р':[('ТАЙШЕТ', 1), ('ЛЕНА', 1), ('ВИХОРЕВКА', 2)], \n",
    "              '2ЭС5К':[('ЛЕНА', 1), ('ТАКСИМО', 1)], \n",
    "              '3ЭС5К':[('ЛЕНА', 1), ('ТАКСИМО', 1)]}\n",
    "DEFAULT_SERVICE_TYPE = 2001889869\n",
    "\n",
    "def get_service_station(x):\n",
    "    return '+service_station(id(%s),service_type(%s),series(%s),sections(%s),power_type(%s),priority(%s),duration(%s))' \\\n",
    "        % (x.station, x.stype, x.series, x.sections, x.ptype, x.priority, x.duration)\n",
    "\n",
    "# ss = pd.read_csv(FOLDER + 'service_station.csv', dtype={'station':str})\n",
    "# ss['name'] = ss.station.map(st_names.name)\n",
    "# ss['ser_name'] = ss.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "# ss1 = ss[(ss.station.isin(test_stations.station))].copy()\n",
    "#ss1.apply(get_service_station, axis=1).to_csv(TEST_FOLDER + 'service_station.csv', index=False, sep=';')\n",
    "\n",
    "lines = []\n",
    "for ser in PTOL_MODEL.keys():\n",
    "    ser_id = loco_series[loco_series.ser_name == ser].ser_id.values[0]\n",
    "    ptols = PTOL_MODEL[ser]\n",
    "    for st_name, pr in ptols:\n",
    "        st_id = stations[stations.name == st_name].station.values[0]\n",
    "        for sections in [2, 3]:\n",
    "            line = '+service_station(id(%s),service_type(%s),series(%s),sections(%s),power_type(%s),priority(%s),duration(%s))' \\\n",
    "                    % (st_id, DEFAULT_SERVICE_TYPE, ser_id, sections, 'ac', pr, 3*3600)\n",
    "            lines.append(line)\n",
    "\n",
    "pd.DataFrame(lines).to_csv(TEST_FOLDER + 'service_station.csv', index=False, sep=';', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по участкам обслуживания бригад"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = []\n",
    "with open('./input/jason-FullPlannerPlugin.log', encoding='utf-8') as f:\n",
    "    prefixes = ['+team_region']\n",
    "    for line in f:\n",
    "        if any([x in line for x in prefixes]):\n",
    "            tr.append(line)\n",
    "            \n",
    "with open(TEST_FOLDER + 'from_real_data.csv', 'w') as fw:\n",
    "    for line in tr:\n",
    "        fw.write(line)\n",
    "        \n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по весовым нормам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "def get_loco_tonnage(x):\n",
    "    return '+loco_tonnage(series(%s),sections(%s),track(station(%s),station(%s)),max_train_weight(%s))' \\\n",
    "            % (x.series, x.sections, x.st_from, x.st_to, x.max_weight)\n",
    "\n",
    "loco_tonnage = pd.read_csv(FOLDER + 'loco_tonnage.csv', dtype={'st_from':str, 'st_to':str})\n",
    "add_info(loco_tonnage)\n",
    "loco_tonnage['ser_name'] = loco_tonnage.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "loco_tonnage['link_name'] = list(zip(loco_tonnage.st_from_name, loco_tonnage.st_to_name))\n",
    "lt = loco_tonnage[(loco_tonnage.ser_name.apply(lambda x: any([i in str(x) for i in ['ВЛ80Р', 'ЭС5К']])))\n",
    "            & (loco_tonnage.st_from.isin(test_stations.station)) & (loco_tonnage.st_to.isin(test_stations.station))]\n",
    "\n",
    "# Повышение нормы до 6000 для участков, где максимальная норма по всем сериям - меньше 4000\n",
    "a = lt.groupby('link_name').max_weight.max()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    for link in a[a < 4000].index:\n",
    "        lt.loc[(lt.st_from_name == link[0]) & (lt.st_to_name == link[1]), 'max_weight'] = 6000\n",
    "        \n",
    "lt.apply(get_loco_tonnage, axis=1).to_csv(TEST_FOLDER + 'loco_tonnage.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ser_name  sections st_from_name st_to_name  max_weight\n",
      "7843    ВЛ80Р         2       ТАЙШЕТ      ТОРЕЯ        4200\n",
      "7844    ВЛ80Р         3       ТАЙШЕТ      ТОРЕЯ        6000\n",
      "     ser_name  sections st_from_name st_to_name  max_weight\n",
      "8606    ВЛ80Р         3        ТОРЕЯ      ТУРМА        6000\n",
      "8607    ВЛ80Р         2        ТОРЕЯ      ТУРМА        6000\n",
      "     ser_name  sections st_from_name st_to_name  max_weight\n",
      "9715    ВЛ80Р         3        ТУРМА  ВИХОРЕВКА        6000\n",
      "9716    ВЛ80Р         2        ТУРМА  ВИХОРЕВКА        4200\n",
      "     ser_name  sections st_from_name st_to_name  max_weight\n",
      "8993    ВЛ80Р         3    ВИХОРЕВКА   МОРГУДОН        6000\n",
      "8994    ВЛ80Р         2    ВИХОРЕВКА   МОРГУДОН        4200\n",
      "      ser_name  sections st_from_name   st_to_name  max_weight\n",
      "10467    ВЛ80Р         3     МОРГУДОН  ГАЛАЧИНСКИЙ        6000\n",
      "10468    ВЛ80Р         2     МОРГУДОН  ГАЛАЧИНСКИЙ        4200\n",
      "     ser_name  sections st_from_name        st_to_name  max_weight\n",
      "3266    ВЛ80Р         3  ГАЛАЧИНСКИЙ  ПАДУНСКИЕ ПОРОГИ        6000\n",
      "3267    ВЛ80Р         2  ГАЛАЧИНСКИЙ  ПАДУНСКИЕ ПОРОГИ        4200\n",
      "     ser_name  sections      st_from_name      st_to_name  max_weight\n",
      "4357    ВЛ80Р         3  ПАДУНСКИЕ ПОРОГИ  ГИДРОСТРОИТЕЛЬ        6000\n",
      "4358    ВЛ80Р         2  ПАДУНСКИЕ ПОРОГИ  ГИДРОСТРОИТЕЛЬ        4200\n",
      "      ser_name  sections    st_from_name           st_to_name  max_weight\n",
      "10788    ВЛ80Р         3  ГИДРОСТРОИТЕЛЬ  КОРШУНИХА-АНГАРСКАЯ        6000\n",
      "10789    ВЛ80Р         2  ГИДРОСТРОИТЕЛЬ  КОРШУНИХА-АНГАРСКАЯ        4200\n"
     ]
    }
   ],
   "source": [
    "# Для проверки: можно посмотреть все весовые нормы на определенном участке (задается в первой строчке id станций) и серии.\n",
    "a = [int(float(i)) for i in d[int(2000036518), int(2000036868)].split(',')]\n",
    "for link in [(a[i], a[i+1]) for i in range(len(a)-1)]:\n",
    "    print(lt[(lt.st_from == str(link[0])) \n",
    "             & (lt.st_to == str(link[1]))\n",
    "             & (lt.ser_name == 'ВЛ80Р')][['ser_name', 'sections', 'st_from_name', 'st_to_name', 'max_weight']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по участкам обкатки бригад"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_region_borders(x):\n",
    "    x_num = [i for i in x if i.isnumeric()]\n",
    "    twr_id = ''.join(x_num)\n",
    "    st_from = st_dict[st_numbers[int(x_num[0])]]\n",
    "    st_to = st_dict[st_numbers[int(x_num[1])]]\n",
    "    return pd.Series([twr_id, st_from, st_to])\n",
    "\n",
    "def get_tracks(x):\n",
    "    res = []\n",
    "    for i in range(len(x) - 1):\n",
    "        s = 'track(station(%s),station(%s),attributes([]))' % (x[i], x[i+1])\n",
    "        res.append(s)\n",
    "        \n",
    "    return ','.join(res)\n",
    "\n",
    "def get_team_work_region(x):\n",
    "    return '+team_work_region(id(%s),tracks([%s]),work_time(with_rest(0), without_rest(0)))' \\\n",
    "        % (x.twr_id, x.route + ',' + x.route_rev)\n",
    "\n",
    "import networkx as nx\n",
    "g = nx.DiGraph()\n",
    "g.add_nodes_from(test_stations.station.unique())\n",
    "g.add_weighted_edges_from(list(zip(l.st_from, l.st_to, l.time)))\n",
    "\n",
    "st_numbers = {0:'ЮРТЫ', 1:'ТАЙШЕТ', 2:'ВИХОРЕВКА', 3:'КОРШУНИХА-АНГАРСКАЯ', 4:'ЛЕНА', 5:'СЕВЕРОБАЙКАЛЬСК',\n",
    "              6:'НОВЫЙ УОЯН', 7:'ТАКСИМО'}\n",
    "st_dict = test_stations[['name', 'station']].set_index('name').to_dict()['station']\n",
    "df_team[['twr_id', 'team_reg_start', 'team_reg_end']] = df_team.region.apply(get_region_borders)\n",
    "tr = df_team[['twr_id', 'team_reg_start', 'team_reg_end']].drop_duplicates()\n",
    "tr['route'] = tr.apply(lambda row: nx.dijkstra_path(g, row.team_reg_start, row.team_reg_end), axis=1)\n",
    "tr['route_rev'] = tr.apply(lambda row: nx.dijkstra_path(g, row.team_reg_end, row.team_reg_start), axis=1)\n",
    "tr['route'] = tr.route.apply(get_tracks)\n",
    "tr['route_rev'] = tr.route_rev.apply(get_tracks)\n",
    "tr.apply(get_team_work_region, axis=1).to_csv(TEST_FOLDER + 'team_work_region.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование данных по ниткам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def change_slot_times(df):    \n",
    "    min_dt = dt.datetime.fromtimestamp(slot.time_start.min())\n",
    "    td = dt.datetime(min_dt.year, min_dt.month, min_dt.day) - dt.datetime(2015, 7, 29)\n",
    "    df['nt_start'] = df.time_start - td.days * 86400\n",
    "    df['nt_end'] = df.time_end - td.days * 86400\n",
    "    df['track'] = df.apply(lambda row: 'track(station(%s),station(%s),time_start(%s),time_end(%s))'\n",
    "                              % (row.st_from, row.st_to, row.nt_start, row.nt_end), axis=1)\n",
    "    df['tracks'] = slot.slot.map(slot.groupby('slot').track.unique().apply(lambda x: ','.join(x)))\n",
    "    return df    \n",
    "    \n",
    "slot = pd.read_csv(FOLDER + 'slot.csv')\n",
    "slot = change_slot_times(slot)\n",
    "slot.drop_duplicates('slot').apply(lambda row: '+slot(id(%s),category(0),route([%s]))' % (row.slot, row.tracks), axis=1)\\\n",
    "    .to_csv(TEST_FOLDER + 'slot.csv', sep=';', index=False)\n",
    "\n",
    "slot_pass = pd.read_csv(FOLDER + 'slot_pass.csv')\n",
    "slot_pass = change_slot_times(slot_pass)\n",
    "slot_pass.drop_duplicates('slot').apply(lambda row: '+slot_pass(id(%s),category(0),route([%s]))' \n",
    "                                        % (row.slot, row.tracks), axis=1)\\\n",
    "    .to_csv(TEST_FOLDER + 'slot_pass.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Формирование данных по временам на смену локомотивов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_change = ['ТАЙШЕТ', 'ЛЕНА', 'ТАКСИМО']\n",
    "lines = []\n",
    "for st in loco_change:\n",
    "    st_id = stations[stations.name == st].station.values[0]\n",
    "    next_sts = links[links.st_from == str(st_id)].st_to.unique()\n",
    "    for next_st_id in next_sts:\n",
    "        line = '+process(station(%s),track(station(%s),station(%s)),7200)' %\\\n",
    "                (st_id, st_id, next_st_id)\n",
    "        lines.append(line)\n",
    "        \n",
    "pd.DataFrame(lines).to_csv(TEST_FOLDER + 'process.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление заголовков и создание итогового файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл jason-FullPlannerPlugin_model.log создан\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files = [files for root, directories, files in os.walk('./test_scenario/') ][0]\n",
    "files = [f for f in files if ('.csv' in f) & ('paths_id.csv' != f) & ('full_stations.csv' != f)]\n",
    "full = []\n",
    "for filename in sorted(files):\n",
    "    with open('./test_scenario/' + filename, encoding='utf-8') as f:\n",
    "        try:\n",
    "            for line in f:\n",
    "                full.append(line)\n",
    "        except:\n",
    "            print(f)\n",
    "\n",
    "ct = int(dt.datetime(2015, 7, 29, 18, 0, 0).timestamp())\n",
    "start_line = '+current_time(%s)\\n+config(\"bulk_planning\",0)\\n' % ct\n",
    "end_line = '+current_id(%s,1)' % ct\n",
    "header = []\n",
    "head_st = list(test_stations.drop_duplicates('station')\\\n",
    "               .apply(lambda row: '  %s = %s (%s)' % (row.station, row['name'], row.esr), axis=1).values)\n",
    "head_train = list(df.apply(lambda row: '  %s = %s; %s; {\"АСОУП\"=>[]}' \n",
    "         % (row.train_id, row.ind[:4]+'01'+row.ind[5:8]+row.ind[9:]+'01', int(row.number)), axis=1).values)\n",
    "head_loco = list(df_loco.apply(lambda row: '  %s = %s; {\"АСОУП\"=>\"\"}' % (row.loco_id, int(row.number)), axis=1).values)\n",
    "head_team = list(df_team.apply(lambda row: '  %s = %s; {}' \n",
    "                               % (row.team_id, ''.join([x for x in row.number if x.isnumeric()])), axis=1).values)\n",
    "header = head_st + head_train + head_loco + head_team  \n",
    "\n",
    "OUTPUT_FILENAME = 'jason-FullPlannerPlugin_model.log'\n",
    "\n",
    "with open('./test_scenario/' + OUTPUT_FILENAME, 'w', encoding='utf-8') as fw_res:\n",
    "    for x in header:\n",
    "        fw_res.write(x + '\\n')\n",
    "    fw_res.write(start_line)\n",
    "    for line in full:\n",
    "        fw_res.write(line)\n",
    "    fw_res.write(end_line)    \n",
    "\n",
    "fw_res.close()\n",
    "print('Файл %s создан' % OUTPUT_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
