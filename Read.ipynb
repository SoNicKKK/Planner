{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Парсинг логов планировщика и создание csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Подготовка словарей для хранения данных](#dict)\n",
    "  1. [Поля сущностей](#cols)\n",
    "  2. [Словари для строк из файла, список с данными и датафреймов](#data)\n",
    "2. [Загрузка строк из файла](#read)\n",
    "3. [Разбор строк из файла и заполнение словаря со списками данных](#parse)\n",
    "  1. [Данные по поездам](#train)\n",
    "    1. [Атрибуты и маршруты поездов](#train_info)\n",
    "    2. [Операции с поездами (поездные факты)](#train_oper)\n",
    "  2. [Данные по локомотивам](#loco)\n",
    "    1. [Атрибуты локомотивов и тяговые плечи](#loco_attributes)\n",
    "    2. [Местоположение локомотивов (локомотивные факты)](#fact_loco)\n",
    "    3. [Время и пробег до ТО-2](#fact_loco_next_service)\n",
    "  3. [Данные по бригадам](#team)\n",
    "    1. [Атрибуты бригад](#team_attributes)\n",
    "    2. [Местоположение и состояние бригад](#fact_team_location)\n",
    "    3. [Последние явки и время начала отдыха бригад](#fact_team_ready)\n",
    "  4. [Нормативно-справочная информация](#nsi)\n",
    "    1. [Станции и пункты проведения ТО](#station)\n",
    "    2. [Участки планирования](#)\n",
    "    3. [Участки обращения бригад](#team_region)\n",
    "    4. [Участки обкатки бригад](#team_work_region)\n",
    "    5. [Весовые нормы локомотивов](#loco_tonnage)\n",
    "    6. [Задания на поезда своего формирования из ССП](#task)\n",
    "    7. [Пассажирские нитки вариантного графика](#slot_pass)\n",
    "    8. [Грузовые нитки вариантного графика](#slot)\n",
    "    9. [Вспомогательная информация (индексы поездов, номера локомотивов и бригад, названия и коды станций](#support)\n",
    "    10. [Время начала планирования](#current_time)\n",
    "  5. [Результаты планирования](#results)\n",
    "    1. [Планы по поездам](#slot_train)\n",
    "    2. [Планы по локомотивам](#slot_loco)\n",
    "    3. [Планы по бригадам](#slot_team)\n",
    "4. [Создание датафреймов](#create_df)\n",
    "5. [Объединение информации между датафреймами](#merge_df)\n",
    "  1. [Добавление кодов и названий станций в station](#merge_station)\n",
    "  2. [Добавление индекса и операций с поездами в train_info](#merge_train)\n",
    "  3. [Добавление номера, местоположения и времени до ТО в loco_attributes](#merge_loco)\n",
    "  4. [Добавление номера, местоположения, состояния и информации по явке в team_attributes](#merge_team)\n",
    "6. [Выгрузка результатов в csv-файлы](#save_csv)\n",
    "  1. [Создание вспомогательного файла с названиями серий](#series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from file \"input/jason-FullPlannerPlugin.log\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if len(sys.argv) > 1:\n",
    "    if 'log_for' in sys.argv:\n",
    "        file_name = 'input/log_for_analysis.log'        \n",
    "    else:\n",
    "        file_name = 'input/jason-FullPlannerPlugin.log'\n",
    "else:\n",
    "    file_name = 'input/jason-FullPlannerPlugin.log'\n",
    "#file_name = 'input/log_for_analysis.log'        \n",
    "print('Load data from file \"%s\"' % file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "FOLDER = 'resources/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = size / 200     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dict'></a>\n",
    "## Подготовка словарей для хранения данных [ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cols'></a>\n",
    "### Поля сущностей [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_cols = {  'link'                  :['link', 'st_from', 'st_to', 'time', 'dist', 'dir', 'lines', 'road'],\n",
    "                   'station'               :['station', 'loco_region','norm_time'],\n",
    "                   'station_names'         :['station', 'name', 'esr'],\n",
    "                   'train_index'           :['train', 'index', 'ind434'],\n",
    "                   'team_nums'             :['team', 'number'],\n",
    "                   'loco_nums'             :['loco', 'number'],\n",
    "                   'support'               :[],\n",
    "                   'loco_tonnage'          :['series', 'sections', 'link', 'st_from', 'st_to', 'max_weight'],\n",
    "                   'task'                  :['id', 'time_start', 'time_end', 'st_from', 'st_next', 'st_to', 'number'],\n",
    "                   'train_info'            :['train', 'number', 'weight', 'length', 'start_st', 'end_st', 'joint'],\n",
    "                   'slot_train'            :['train', 'st_from', 'st_to', 'link', 'time_start', 'time_end'],\n",
    "                   'loco_attributes'       :['loco', 'series', 'regions', 'depot', 'sections', 'ltype'],\n",
    "                   'slot_loco'             :['loco', 'st_from', 'st_to', 'link', 'time_start', 'time_end', 'state', 'train'],\n",
    "                   'team_attributes'       :['team', 'regions', 'depot', 'long', 'heavy', 'series', 'fake', 'ttype'],\n",
    "                   'fact_team_ready'       :['team', 'ready_type', 'depot_st', 'depot_time', \n",
    "                                             'return_st', 'return_time', 'rest_time'],\n",
    "                   'slot_team'             :['team', 'st_from', 'st_to', 'link', 'time_start', 'time_end', \n",
    "                                             'slot', 'state', 'loco'], \n",
    "                   'slot'                  :['slot', 'st_from', 'st_to', 'link', 'time_start', 'time_end'],\n",
    "                   'slot_pass'             :['slot', 'st_from', 'st_to', 'link', 'time_start', 'time_end'],\n",
    "                   'routes'                :['train', 'st_from', 'st_to'],\n",
    "                   'service'               :['station', 'serv_type', 'duration'],\n",
    "                   'train_oper'            :['train', 'oper', 'oper_time', 'oper_location', 'st_from', 'st_to'],\n",
    "                   'train_depart'          :['train', 'st_from', 'st_to', 'oper_time'],\n",
    "                   'train_arrive'          :['train', 'oper_location', 'oper_time'],\n",
    "                   'train_ready'           :['train', 'oper_location', 'oper_time'],\n",
    "                   'fact_loco'             :['loco', 'oper', 'oper_time', 'oper_location', \n",
    "                                             'st_from', 'st_to', 'state', 'train'],\n",
    "                   'fact_loco_next_service':['loco', 'dts', 'tts'],\n",
    "                   'fact_team_location'    :['team', 'oper_time', 'oper_location', 'st_from', 'st_to', 'state', 'loco'],\n",
    "                   'loco_info_regs'        :['loco', 'region'],\n",
    "                   'team_work_region'      :['twr', 'link'],\n",
    "                   'team_region'           :['team_region', 'asoup', 'depot', 'st_from', 'st_to', 'time_f', 'time_b', 'time_wr'],\n",
    "                   'service_station'       :['station', 'stype', 'series', 'sections', 'ptype', 'priority', 'duration'],\n",
    "                   'current_time'          :['current_time']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "### Словари для строк из файла, списков с данными и датафреймов [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities_data = {}\n",
    "for key in entities_cols.keys():\n",
    "    entities_data[key] = []\n",
    "    \n",
    "entities_df_source = {}\n",
    "for key in entities_cols.keys():\n",
    "    entities_df_source[key] = []\n",
    "    \n",
    "entities_df = {}\n",
    "for key in entities_cols.keys():\n",
    "    entities_df[key] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read'></a>\n",
    "## Загрузка строк из файла [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simplecount(filename):\n",
    "    lines = 0\n",
    "    for line in open(filename, encoding = 'utf_8_sig'):\n",
    "        lines += 1\n",
    "    return lines\n",
    "\n",
    "n = simplecount(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('current_time', 2), ('fact_loco', 2083), ('fact_loco_next_service', 2083), ('fact_team_location', 4898), ('fact_team_ready', 4898), ('link', 746), ('loco_attributes', 2083), ('loco_info_regs', 0), ('loco_nums', 0), ('loco_tonnage', 11688), ('routes', 0), ('service', 0), ('service_station', 4664), ('slot', 7541), ('slot_loco', 1604), ('slot_pass', 2547), ('slot_team', 4714), ('slot_train', 4443), ('station', 498), ('station_names', 0), ('support', 9232), ('task', 714), ('team_attributes', 4898), ('team_nums', 0), ('team_region', 0), ('team_work_region', 2037), ('train_arrive', 428), ('train_depart', 1236), ('train_index', 0), ('train_info', 1896), ('train_oper', 0), ('train_ready', 338)]\n"
     ]
    }
   ],
   "source": [
    "with open(file_name, encoding = 'utf_8_sig') as f:    \n",
    "    for line in log_progress(f, every = 1000, size=n):\n",
    "        functor = line[1:line.find(\"(\")]\n",
    "        functor_tell = line[5:line.find(\"(\", 5)]\n",
    "        if functor in entities_cols.keys():            \n",
    "            entities_data[functor].append(line)\n",
    "        elif functor_tell in entities_cols.keys():            \n",
    "            entities_data[functor_tell].append(line)\n",
    "        elif '=' in functor:\n",
    "            entities_data['support'].append(line)\n",
    "\n",
    "print(sorted((key, len(entities_data[key])) for key in entities_cols.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parse'></a>\n",
    "## Разбор строк из файла и заполнение словаря со списками данных [ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train'></a>\n",
    "### Данные по поездам [ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train_info'></a>\n",
    "#### Атрибуты и маршруты поездов [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['train_info'] = []\n",
    "entities_df_source['routes'] = []\n",
    "\n",
    "for line in entities_data['train_info']:\n",
    "    a = line.split(',')\n",
    "    if 'joint' in line:\n",
    "        train, number, weight, length, joint = a[0][15:27], a[1][13:-1], a[3][7:-1], a[4][7:-1], a[-1][6:-5]\n",
    "    else:\n",
    "        train, number, weight, length, joint = a[0][15:27], a[1][7:-1], a[3][7:-1], a[4][7:-1], -1\n",
    "    r = line.split('route')\n",
    "    if len(r) > 2:\n",
    "        rr = r[2]\n",
    "        r1 = rr[2:rr.find(']')].split(',')            \n",
    "        route = [x[8:-1] for x in r1]\n",
    "        if len(route) > 0:\n",
    "            start_st, end_st = route[0], route[-1]        \n",
    "            route_shift = np.roll(route, -1)\n",
    "            for i in range(0, len(route) - 1):\n",
    "                entities_df_source['routes'].append([train, route[i], route_shift[i]])\n",
    "    else:\n",
    "        start_st, end_st = -1, -1\n",
    "    entities_df_source['train_info'].append([train, number, weight, length, start_st, end_st, joint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train_oper'></a>\n",
    "#### Операции с поездами (поездные факты) [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['train_oper'] = []\n",
    "\n",
    "for line in entities_data['train_depart']:\n",
    "    a = line.split(',')\n",
    "    train, st_from, st_to, t = a[0][17:-1], a[1][14:-1], a[2][8:-2], a[3][5:-3]\n",
    "    entities_df_source['train_oper'].append([train, 'depart', t, [st_from, st_to], st_from, st_to])\n",
    "\n",
    "for line in entities_data['train_arrive']:\n",
    "    a = line.split(',')\n",
    "    train, st, t = a[0][17:-1], a[2][8:-2], a[3][5:-3]\n",
    "    entities_df_source['train_oper'].append([train, 'arrive', t, st, -1, -1])\n",
    "\n",
    "for line in entities_data['train_ready']:\n",
    "    a = line.split(',')\n",
    "    train, st, t = a[0][16:-1], a[1][8:-1], a[2][5:-3]            \n",
    "    entities_df_source['train_oper'].append([train, 'ready', t, st, -1, -1])\n",
    "    \n",
    "#entities_df_source['train_oper'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loco'></a>\n",
    "### Данные по локомотивам [ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loco_attributes'></a>\n",
    "#### Атрибуты локомотивов и тяговые плечи [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['loco_attributes'] = []\n",
    "entities_df_source['loco_info_regs'] = []\n",
    "\n",
    "for line in entities_data['loco_attributes']:\n",
    "    a = line.split(',')            \n",
    "    loco, series = a[0][20:32], a[1][19:-1]              \n",
    "    regions_str = line[79:line.find('depot')-3].split(',')\n",
    "    regions = []\n",
    "    for reg in regions_str:\n",
    "        regions.append(reg[3:-1])\n",
    "        entities_df_source['loco_info_regs'].append([loco, reg[3:-1]])\n",
    "\n",
    "    rest_line = line[line.find('depot'):].split(',')\n",
    "    depot = rest_line[0][14:-2]            \n",
    "    sections = rest_line[1][9:-1]\n",
    "    if len(rest_line) > 2:\n",
    "        ltype = rest_line[2][5:-5]\n",
    "    else:\n",
    "        ltype = 'none'\n",
    "    entities_df_source['loco_attributes'].append([loco, series, regions, depot, sections, ltype])\n",
    "    \n",
    "#entities_df_source['loco_attributes'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fact_loco'></a>\n",
    "#### Местоположение локомотивов (локомотивные факты) [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['fact_loco'] = []\n",
    "\n",
    "for line in entities_data['fact_loco']:\n",
    "    a = line.split(',')\n",
    "    if 'depart_time' in line:                \n",
    "        loco, oper, oper_t = a[0][14:-1], 'depart', a[4][12:-1]\n",
    "        location, state, train = [a[2][23:-1], a[3][8:-1]], a[5][6], a[6][6:-5]\n",
    "        st_from, st_to = a[2][23:-1], a[3][8:-1]\n",
    "    elif 'arrive_time' in line:                \n",
    "        loco, oper, oper_t = a[0][14:-1], 'arrive', a[3][12:-1]\n",
    "        location, state, train = a[2][17:-1], a[4][6], a[5][6:-4]                \n",
    "        st_from, st_to = -1, -1\n",
    "    else:                \n",
    "        loco, oper, oper_t = a[0][14:-1], 'ready', a[1][10:-1]\n",
    "        location, state, train = a[2][17:-4], -1, -1                      \n",
    "        st_from, st_to = -1, -1\n",
    "    entities_df_source['fact_loco'].append([loco, oper, oper_t, location, st_from, st_to, state, train])      \n",
    "    \n",
    "#entities_df_source['fact_loco'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fact_loco_next_service'></a>\n",
    "#### Время и пробег до ТО-2 [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['fact_loco_next_service'] = []\n",
    "\n",
    "for line in entities_data['fact_loco_next_service']:\n",
    "    a = line.split(',')            \n",
    "    loco, dts, tts = a[0][27:-1], a[2][21:-1], a[3][8:-1]\n",
    "    entities_df_source['fact_loco_next_service'].append([loco, dts, tts])\n",
    "    \n",
    "#entities_df_source['fact_loco_next_service'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='team'></a>\n",
    "### Данные по бригадам [ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='team_attributes'></a>\n",
    "#### Атрибуты бригад [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['team_attributes'] = []\n",
    "a = []\n",
    "for line in entities_data['team_attributes']:                       \n",
    "    k = re.split('(attributes|team_work_regions|depot|loco_series|long_train|heavy_train|fake|type)', line)    \n",
    "    team = k[2][4:-2]\n",
    "    regions_str = k[6][2:-3].split(',')\n",
    "    regions = []\n",
    "    for reg in regions_str:\n",
    "        regions.append(reg[3:-1])                      \n",
    "\n",
    "    depot, long, heavy, fake = k[8][9:-3], k[12][1], k[14][1], k[16][1]\n",
    "    series = list(np.unique([x[3:-1] for x in k[10][2:-3].split(',')]))    \n",
    "    if len(k)>18:\n",
    "        ttype = k[18][1]\n",
    "    else:\n",
    "        ttype = 'none'\n",
    "    entities_df_source['team_attributes'].append([team, regions, depot, long, heavy, series, fake, ttype])\n",
    "    \n",
    "#entities_df_source['team_attributes'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fact_team_location'></a>\n",
    "#### Местоположение и состояние бригад [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['fact_team_location'] = []\n",
    "\n",
    "for line in entities_data['fact_team_location']:\n",
    "    a = line.split(',')\n",
    "    if 'location(station' in line:\n",
    "        team, oper_t = a[0][23:-1], a[3][10:-1]\n",
    "        location, state, loco = a[2][17:-2], a[5][6], a[4][5:-1]\n",
    "        st_from, st_to = -1, -1\n",
    "    else:                            \n",
    "        team, oper_t = a[0][23:-1], a[4][10:-1]\n",
    "        location, state, loco = [a[2][23:-1], a[3][8:-3]], a[7][6], a[5][5:-1]\n",
    "        st_from, st_to = a[2][23:-1], a[3][8:-3]\n",
    "    entities_df_source['fact_team_location'].append([team, oper_t, location, st_from, st_to, state, loco])\n",
    "    \n",
    "#print(entities_df_source['fact_team_location'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fact_team_ready'></a>\n",
    "#### Последние явки и время начала отдыха бригад [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['fact_team_ready'] = []\n",
    "\n",
    "for line in entities_data['fact_team_ready']:    \n",
    "    a = line.split(',')\n",
    "    team = a[0][20:-1]\n",
    "    depot_time, depot_st = a[1][17:-1], a[2][8:-2]            \n",
    "    return_time, return_st = a[3][18:-1], a[4][8:-2]            \n",
    "    ready_type = a[5][11:-1]\n",
    "    rest_time = a[6][16:-3]            \n",
    "    entities_df_source['fact_team_ready'].append([team, ready_type, depot_st, depot_time, return_st, return_time, rest_time])\n",
    "\n",
    "#print(entities_df_source['fact_team_ready'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nsi'></a>\n",
    "### Нормативно-справочная информация [ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='station'></a>\n",
    "#### Станции и пункты проведения ТО [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['station'] = []\n",
    "entities_df_source['service'] = []\n",
    "\n",
    "for line in entities_data['station']:\n",
    "    a = line.split(',')\n",
    "    station, loco_region, norm_time = a[0][12:22], a[1][12:-1], a[-1][10:-3]\n",
    "    entities_df_source['station'].append([station, loco_region, norm_time])\n",
    "    serv = re.split('(loco_region|service|norm_reserve|norm_time)', line)[4].split('type')            \n",
    "    if len(serv) > 1:\n",
    "        for item in serv[1:]:\n",
    "            sp = re.split('(]|,)', item)                    \n",
    "            serv_type = sp[0][4:-1]\n",
    "            dur = sp[2][9:-2]\n",
    "            entities_df_source['service'].append([station, serv_type, dur])\n",
    "            \n",
    "#print(entities_df_source['service'][:3])\n",
    "#print(entities_df_source['station'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link'></a>\n",
    "#### Участки планирования [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['link'] = []\n",
    "\n",
    "for line in entities_data['link']:\n",
    "    st_from, st_to = line[20:30], line[40:50]            \n",
    "    attr = line[65:-4].split(',')\n",
    "    travel_time, dist = attr[0][9:-1], attr[1][9:-1]\n",
    "    dir = attr[3][10:-1]\n",
    "    lines, road = attr[4][6:-1], attr[5][5:-1]\n",
    "    entities_df_source['link'].append([[st_from, st_to], st_from, st_to, travel_time, dist, dir, lines, road])\n",
    "    \n",
    "#print(entities_df_source['link'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='team_region'></a>\n",
    "#### Участки обращения бригад (УОЛБ) [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['team_region'] = []\n",
    "\n",
    "for line in entities_data['team_region']:\n",
    "    a = line.split('track')\n",
    "    if len(a) > 2:\n",
    "        b = a[0].split(',')\n",
    "        tr_id = b[0][16:-1]\n",
    "        asoup_id = b[1][9:-1]\n",
    "        depot = b[2][6:-1]\n",
    "        tracks = a[2:]\n",
    "        wt = a[-1].split(',')\n",
    "        time_f = wt[2][18:-1]\n",
    "        time_b = wt[3][9:-1]\n",
    "        time_wr = wt[4][13:-4]\n",
    "        for track in tracks:\n",
    "            st_from, st_to = track[9:19], track[29:39]                    \n",
    "            entities_df_source['team_region'].append([tr_id, asoup_id, depot, st_from, st_to, time_f, time_b, time_wr])\n",
    "            \n",
    "#print(entities_df_source['team_region'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='team_work_region'></a>\n",
    "#### Участки обкатки бригад [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['team_work_region'] = []\n",
    "\n",
    "for line in entities_data['team_work_region']:\n",
    "    a = line.split('track')\n",
    "    if len(a) > 2:\n",
    "        twr_id = a[0][21:-2]                \n",
    "        tracks = a[2:]\n",
    "        for track in tracks:\n",
    "            st_from, st_to = track[9:19], track[29:39]                    \n",
    "            entities_df_source['team_work_region'].append([twr_id, [st_from, st_to]])              \n",
    "            \n",
    "#print(entities_df_source['team_work_region'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loco_tonnage'></a>\n",
    "#### Весовые нормы локомотивов [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['loco_tonnage'] = []\n",
    "\n",
    "for line in entities_data['loco_tonnage']:    \n",
    "    a = line.split(',')                        \n",
    "    series = a[0][21:-1]\n",
    "    sections = a[1][9:-1]\n",
    "    st_from = a[2][14:-1]\n",
    "    st_to = a[3][8:-2]\n",
    "    link = [st_from, st_to]\n",
    "    max_weight = a[4][17:-3]\n",
    "    entities_df_source['loco_tonnage'].append([series, sections, link, st_from, st_to, max_weight])\n",
    "    \n",
    "#print(entities_df_source['loco_tonnage'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task'></a>\n",
    "#### Задания на поезда своего формирования из ССП [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['task'] = []\n",
    "\n",
    "for line in entities_data['task']:\n",
    "    a = re.split('(id|interval|routes|weight)', line)            \n",
    "    task_id = a[2][1:-2]\n",
    "    time_start = a[4][1:11]\n",
    "    time_end = int(time_start) + int(a[4][12:-2])\n",
    "    num = int(re.split(',|\\)', a[-1])[2])\n",
    "    task_routes = re.split('(route|,route)', a[6][2:-3])            \n",
    "    for item in task_routes[2::2]:\n",
    "        task_route = item[2:-2].split(',')\n",
    "        st_from = task_route[0][8:-1]\n",
    "        if len(task_route) > 1:\n",
    "            st_next = task_route[1][8:-1]\n",
    "            st_to = task_route[-1][8:-1]\n",
    "        else:\n",
    "            st_next, st_to = None, None                \n",
    "        entities_df_source['task'].append([task_id, time_start, time_end, st_from, st_next, st_to, num])\n",
    "        \n",
    "#print(entities_df_source['task'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='slot_pass'></a>\n",
    "#### Пассажирские нитки вариантного графика [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['slot_pass'] = []\n",
    "\n",
    "for line in entities_data['slot_pass']:    \n",
    "    a = line.split('track')            \n",
    "    slot_id = a[0][14:26]\n",
    "    for i in range(1, len(a)):                \n",
    "        st_from, st_to = a[i][9:19], a[i][29:39]\n",
    "        link = [st_from, st_to]\n",
    "        time_start, time_end = a[i][52:62], a[i][73:83]                                \n",
    "        entities_df_source['slot_pass'].append([slot_id, st_from, st_to, link, time_start, time_end]) \n",
    "        \n",
    "#print(entities_df_source['slot_pass'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='slot'></a>\n",
    "#### Грузовые нитки вариантного графика [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['slot'] = []\n",
    "\n",
    "for line in entities_data['slot']:\n",
    "    a = line.split('track')            \n",
    "    slot_id = a[0][9:21]            \n",
    "    for i in range(1, len(a)):                \n",
    "        st_from, st_to = a[i][9:19], a[i][29:39]\n",
    "        link = [st_from, st_to]\n",
    "        time_start, time_end = a[i][52:62], a[i][73:83]                                \n",
    "        entities_df_source['slot'].append([slot_id, st_from, st_to, link, time_start, time_end])\n",
    "        \n",
    "#print(entities_df_source['slot'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='service_station'></a>\n",
    "#### Станции ПТОЛ [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['service_station'] = []\n",
    "\n",
    "for line in entities_data['service_station']:\n",
    "    a = line.split(',')\n",
    "    station = a[0][20:-1]\n",
    "    stype = a[1][13:-1]\n",
    "    series = a[2][7:-1]\n",
    "    sections = a[3][9:-1]\n",
    "    ptype = a[4][11:-1]\n",
    "    priority = a[5][9:-1]\n",
    "    duration = a[6][9:-3]\n",
    "    entities_df_source['service_station'].append([station, stype, series, sections, ptype, priority, duration])\n",
    "    \n",
    "#print(entities_df_source['service_station'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='support'></a>\n",
    "#### Вспомогательная информация (индексы поездов, номера локомотивов, бригад, названия и коды станций [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['support'] = []\n",
    "\n",
    "for line in entities_data['support']:\n",
    "    functor = line[1:line.find(\"(\")]\n",
    "    if '{' not in functor:                        \n",
    "        st = line.split('=')                \n",
    "        st_id = st[0][2:-1]\n",
    "        st_name = st[1][1:-9]\n",
    "        st_esr = st[1][-7:-2]                \n",
    "        entities_df_source['station_names'].append([st_id, st_name, st_esr])\n",
    "    elif len(functor.split(';')[0]) == 20:\n",
    "        a = functor.split(';')[0].split('=')\n",
    "        loco_id = a[0][1:-1]\n",
    "        loco_num = a[1][1:]             \n",
    "        entities_df_source['loco_nums'].append([loco_id, loco_num])\n",
    "    elif len(functor.split(';')[0]) == 26:\n",
    "        a = functor.split(';')[0].split('=')\n",
    "        team_id = a[0][1:-1]\n",
    "        team_num = a[1][1:]\n",
    "        team_num_formatted = team_num[:4] + '-' + team_num[4:]        \n",
    "        entities_df_source['team_nums'].append([team_id, team_num])\n",
    "    elif len(functor.split(';')[0]) > 26:\n",
    "        a = line.split(';')\n",
    "        if len(a[0]) < 45:\n",
    "            num_ind = a[0].split('=')\n",
    "            train_id = num_ind[0][2:-1]\n",
    "            ind = num_ind[1][1:]\n",
    "            ind434=ind[:4] + '-' + ind[6:9] + '-' + ind[9:13]\n",
    "            entities_df_source['train_index'].append([train_id, ind, ind434])\n",
    "            \n",
    "#print(entities_df_source['station_names'][:5])\n",
    "#print(entities_df_source['loco_nums'][:5])\n",
    "#print(entities_df_source['team_nums'][:5])\n",
    "#print(entities_df_source['train_index'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='current_time'></a>\n",
    "#### Время начала планирования [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['current_time'] = []\n",
    "for line in entities_data['current_time']:\n",
    "    if entities_df_source['current_time'] == []:\n",
    "        entities_df_source['current_time'].append(line[14:-2])\n",
    "    \n",
    "#entities_df_source['current_time'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "### Результаты планирования [ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='slot_train'></a>\n",
    "#### Планы по поездам [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['slot_train'] = []\n",
    "\n",
    "for line in entities_data['slot_train']:\n",
    "    a = line.split('track')        \n",
    "    train_id = a[0][a[0].index('id')+3:a[0].index('route')-2]                \n",
    "    for i in range(1, len(a)):                \n",
    "        st_from, st_to = a[i][9:19], a[i][29:39]\n",
    "        link = [st_from, st_to]\n",
    "        time_start, time_end = a[i][52:62], a[i][73:83]                \n",
    "        entities_df_source['slot_train'].append([train_id, st_from, st_to, link, time_start, time_end])  \n",
    "        \n",
    "#print(entities_df_source['slot_train'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='slot_loco'></a>\n",
    "#### Планы по локомотивам [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['slot_loco'] = []\n",
    "\n",
    "for line in entities_data['slot_loco']:\n",
    "    a = line.split('track')                    \n",
    "    loco = a[0][18:30]                \n",
    "    for i in range(1, len(a)):\n",
    "        st_from, st_to = a[i][9:19], a[i][29:39]                \n",
    "        link = [st_from, st_to]\n",
    "        time_start, time_end = a[i][52:62], a[i][73:83]                \n",
    "        state, train = a[i][103], a[i][112:a[i].find(\"))\")]                \n",
    "        entities_df_source['slot_loco'].append([loco, st_from, st_to, link, time_start, time_end, state, train])  \n",
    "        \n",
    "#print(entities_df_source['slot_loco'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='slot_team'></a>\n",
    "#### Планы по бригадам [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities_df_source['slot_team'] = []\n",
    "\n",
    "for line in entities_data['slot_team']:\n",
    "    a = line.split('track')                    \n",
    "    team = a[0][18:30]                \n",
    "    for i in range(1, len(a)):\n",
    "        sep = a[i].split(',')                \n",
    "        st_from, st_to = sep[0][9:-1], sep[1][8:-1]                \n",
    "        link = [st_from, st_to]\n",
    "        time_start, time_end = sep[2][11:-1], sep[3][9:-1]                \n",
    "        slot_id, state, loco = sep[4][8:-1], sep[5][6], sep[6][5:sep[6].find('))')]\n",
    "        entities_df_source['slot_team'].append([team, st_from, st_to, link, time_start, time_end, slot_id, state, loco])      \n",
    "        \n",
    "#print(entities_df_source['slot_team'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create_df'></a>\n",
    "## Создание датафреймов [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in entities_df.keys():\n",
    "    try:\n",
    "        entities_df[key] = pd.DataFrame(entities_df_source[key], columns = entities_cols[key])  \n",
    "    except:\n",
    "        print('Fail to create dataframe for key:', key)\n",
    "\n",
    "#print(sorted(entities_df.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_df'></a>\n",
    "## Объединение информации между датафреймами [ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_station'></a>\n",
    "#### Добавление кодов и названий станций в station [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in entities_cols['station_names']:\n",
    "    if col != 'station':\n",
    "        entities_df['station'][col] = entities_df['station'].station\\\n",
    "                    .map(entities_df['station_names'].drop_duplicates('station').set_index('station')[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_train'></a>\n",
    "#### Добавление индекса и операций с поездами в train_info [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Если по поезду в train_oper несколько операций, то оставляем только последнюю по времени\n",
    "# Если последних операций тоже несколько, то оставляем в таком порядке: сначала depart - потом ready - потом arrive\n",
    "\n",
    "def get_oper_code(x):\n",
    "    if x == 'depart':\n",
    "        return 2\n",
    "    elif x == 'ready':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "entities_df['train_oper']['oper_code'] = entities_df['train_oper'].oper.apply(get_oper_code)\n",
    "entities_df['train_oper'].sort_values(['train', 'oper_time', 'oper_code'])\n",
    "entities_df['train_oper'] = entities_df['train_oper'].sort_values(['train', 'oper_time', 'oper_code'])\\\n",
    "                                                     .drop_duplicates(subset=['train'], keep='last')\\\n",
    "                                                     .drop('oper_code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'ind434' not in entities_df['train_info'].columns:\n",
    "    entities_df['train_info'] = entities_df['train_info'].set_index('train')\\\n",
    "                                .join(entities_df['train_index'].set_index('train')).reset_index()\n",
    "    \n",
    "if 'oper_time' not in entities_df['train_info'].columns:\n",
    "    entities_df['train_info'] = pd.merge(entities_df['train_info'], \\\n",
    "                                         entities_df['train_oper'].drop_duplicates('train'), \n",
    "                                         on='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_loco'></a>\n",
    "#### Добавление номера, местоположения и времени до ТО в loco_attributes [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities_df['loco_attributes']['number'] = entities_df['loco_attributes'].loco\\\n",
    "                                        .map(entities_df['loco_nums'].drop_duplicates('loco').set_index('loco').number)\n",
    "\n",
    "if 'oper_time' not in entities_df['loco_attributes'].columns:\n",
    "    entities_df['loco_attributes'] = pd.merge(pd.merge(entities_df['loco_attributes'],\n",
    "                                                       entities_df['fact_loco'], on='loco'), \n",
    "                                              entities_df['fact_loco_next_service'], \n",
    "                                              on='loco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_team'></a>\n",
    "#### Добавление номера, местоположения, состояния и информации по явке в team_attributes [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities_df['team_attributes']['number'] = entities_df['team_attributes'].team\\\n",
    "                                            .map(entities_df['team_nums'].drop_duplicates('team').set_index('team').number)\n",
    "\n",
    "if 'oper_time' not in entities_df['team_attributes'].columns:\n",
    "    entities_df['team_attributes'] = pd.merge(pd.merge(entities_df['team_attributes'], \n",
    "                                                       entities_df['fact_team_ready'], \n",
    "                                                       on='team'), \n",
    "                                              entities_df['fact_team_location'], \n",
    "                                              on='team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='save_csv'></a>\n",
    "## Выгрузка результатов в csv-файлы [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл resources/train_arrive.csv успешно создан\n",
      "Файл resources/routes.csv успешно создан\n",
      "Файл resources/loco_info_regs.csv успешно создан\n",
      "Файл resources/task.csv успешно создан\n",
      "Файл resources/team_nums.csv успешно создан\n",
      "Файл resources/team_work_region.csv успешно создан\n",
      "Файл resources/loco_nums.csv успешно создан\n",
      "Файл resources/slot_pass.csv успешно создан\n",
      "Файл resources/slot_loco.csv успешно создан\n",
      "Файл resources/support.csv успешно создан\n",
      "Файл resources/fact_team_location.csv успешно создан\n",
      "Файл resources/station.csv успешно создан\n",
      "Файл resources/service_station.csv успешно создан\n",
      "Файл resources/slot.csv успешно создан\n",
      "Файл resources/link.csv успешно создан\n",
      "Файл resources/service.csv успешно создан\n",
      "Файл resources/train_index.csv успешно создан\n",
      "Файл resources/train_info.csv успешно создан\n",
      "Файл resources/slot_team.csv успешно создан\n",
      "Файл resources/fact_loco_next_service.csv успешно создан\n",
      "Файл resources/train_depart.csv успешно создан\n",
      "Файл resources/fact_team_ready.csv успешно создан\n",
      "Файл resources/team_region.csv успешно создан\n",
      "Файл resources/slot_train.csv успешно создан\n",
      "Файл resources/station_names.csv успешно создан\n",
      "Файл resources/team_attributes.csv успешно создан\n",
      "Файл resources/current_time.csv успешно создан\n",
      "Файл resources/loco_attributes.csv успешно создан\n",
      "Файл resources/train_ready.csv успешно создан\n",
      "Файл resources/fact_loco.csv успешно создан\n",
      "Файл resources/train_oper.csv успешно создан\n",
      "Файл resources/loco_tonnage.csv успешно создан\n"
     ]
    }
   ],
   "source": [
    "TEST_FOLDER = 'test/'\n",
    "\n",
    "for key in entities_df.keys():\n",
    "    filename = FOLDER  + key + '.csv'\n",
    "    entities_df[key].to_csv(filename, index=False, encoding='utf-8')\n",
    "    print('Файл %s успешно создан' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='series'></a>\n",
    "#### Создание вспомогательного файла с названиями серий [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ser_id, ser_name, ser_desc = [], [], []\n",
    "cnt = 1\n",
    "with open(FOLDER + 'mandatory/series_names.csv', encoding = 'utf_8_sig') as f:\n",
    "    for line in f:        \n",
    "        if cnt == 1:\n",
    "            ser_id.append(line[:-1])\n",
    "            cnt = 2\n",
    "        elif cnt == 2:            \n",
    "            ser_name.append(line[:-1])\n",
    "            cnt = 3\n",
    "        elif cnt == 3:            \n",
    "            if line[:-1] != '':                \n",
    "                ser_desc.append(line[:-1])\n",
    "            else:                \n",
    "                ser_desc.append('none')\n",
    "            cnt = 1\n",
    "series = pd.DataFrame(columns=['ser_id', 'ser_name', 'ser_desc', 'ser_type'])\n",
    "series.ser_id, series.ser_name, series.ser_desc = ser_id, ser_name, ser_desc \n",
    "el_series = ['ЭС', 'ВЛ', 'Э5']\n",
    "series['ser_type'] = series.ser_name.apply(lambda x: 'Электровоз' if any(ser in x for ser in el_series) else 'Тепловоз')\n",
    "series.to_csv(FOLDER + 'loco_series.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее время выполнения: 119.90 сек.\n",
      "Время запуска: Fri Jul  8 13:33:09 2016\n"
     ]
    }
   ],
   "source": [
    "t = time.time() - start_time\n",
    "print('Общее время выполнения: %.2f сек.' % t)\n",
    "print('Время запуска:', time.ctime())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
