{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Список тестов по запланированным локомотивам:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Вычисление процента подвязки поездов и локомотивов.](#perc)\n",
    "2. [Проверка правильности назначениях тяговых плеч локомотивам во входных данных.](#regions)\n",
    "   1. [Проверка назначения тяговых плеч локомотивам в соответствии с сериями](#correct_reg_ser)\n",
    "   2. [Проверка невыезда локомотива за пределы своих тяговых плеч в процессе планирования](#correct_reg_plan)\n",
    "   3. [Локомотивы на чужих тяговых плечах на начало планирования](#bad_regs_loco_info)\n",
    "3. [Проверка пунктов проведения ТО-2.](#st_to2)\n",
    "4. [Проверка подвязки на соответствие весовым нормам.](#tonnage)\n",
    "5. [Проверка смен локомотива на станциях обязательной смены.](#change)\n",
    "6. [Анализ локомотивов резервом.](#res)\n",
    "   1. [Проверка номеров поездов, соответствующих локомотивам резервом.](#res_nums)\n",
    "   2. [Вычисление количества локомотивов резервом по направлениям.](#res_amount)\n",
    "   3. [Проверка отправления локомотивов резервом до начала планирования.](#res_before)\n",
    "   4. [Анализ отправления локомотивов резервом в четную сторону.](#res_even)\n",
    "7. [Проверка скачков по времени назад](#time_leaps)\n",
    "7. [Создание отчета](#report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Константы и настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = ''\n",
    "FOLDER = 'resources/'\n",
    "REPORT_FOLDER = 'report/'\n",
    "PRINT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для экспорта в HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_line(line, p=PRINT):    \n",
    "    global report        \n",
    "    if p:        \n",
    "        if type(line) == str:\n",
    "            print(line)        \n",
    "        elif type(line) == pd.core.frame.DataFrame:\n",
    "            print(line.to_string(index=False))\n",
    "        elif type(line) == pd.core.series.Series:\n",
    "            print(line.to_string())\n",
    "    if type(line) == pd.core.frame.DataFrame:        \n",
    "        report += ('%s<br>' % line.to_html(index=False))\n",
    "    elif type(line) == pd.core.series.Series:\n",
    "        report += ('%s<br>' % line.to_frame().reset_index().to_html(index=False))\n",
    "    else:                \n",
    "        report += ('%s<br>' % line)\n",
    "    \n",
    "def add_header(header, h=4, p=PRINT):\n",
    "    global report    \n",
    "    report += ('<h%d>%s</h%d>' % (h, header, h))    \n",
    "    if p:\n",
    "        print(header)\n",
    "        \n",
    "def add_image(filename):\n",
    "    global report\n",
    "    report += ('<img src=\"%s\" alt=\"%s\" height=\"40%%\">' % (filename, filename))\n",
    "\n",
    "def create_report(filename):\n",
    "    global report\n",
    "    report = report.replace('<table border=\"1\" class=\"dataframe\">','<table class=\"table table-striped\">')\n",
    "    html_string = '''\n",
    "        <html>\n",
    "            <head>\n",
    "                <link rel=\"stylesheet\" href=\"skeleton.css\">\n",
    "                <style>body{ margin:20 20; background:whitesmoke; }\n",
    "                table {table-layout : fixed}\n",
    "                </style>\n",
    "            </head>\n",
    "            <body>\n",
    "                <h1>Проверки по локомотивам</h1>        \n",
    "                %s\n",
    "            </body>\n",
    "        </html>''' % (report)\n",
    "    f = open(filename,'w', encoding='utf-8-sig')\n",
    "    f.write(html_string)\n",
    "    f.close()\n",
    "    print('Отчет сформирован за %.2f сек. и записан в файл %s' % (time.time() - start_time, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время составления отчета: Jul 08, 17:21\n",
      "Время запуска планировщика: Jul 06, 14:41 (1467805287)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import get_ipython\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rc('font', family='Times New Roman')\n",
    "\n",
    "pd.set_option('max_rows', 50)\n",
    "pd.set_option('display.max_colwidth', 25)\n",
    "\n",
    "time_format = '%b %d, %H:%M'\n",
    "\n",
    "start_time = time.time()\n",
    "current_time   = pd.read_csv(FOLDER + 'current_time.csv').current_time[0]\n",
    "twr            = pd.read_csv(FOLDER + 'team_work_region.csv', converters={'team_work_region':str})\n",
    "links          = pd.read_csv(FOLDER + 'link.csv', converters={'st_from':str, 'st_to':str})\n",
    "stations       = pd.read_csv(FOLDER + 'station.csv', converters={'station':str})\n",
    "train_info     = pd.read_csv(FOLDER + 'train_info.csv', converters={'train': str, 'st_from':str, 'st_to':str})\n",
    "train_plan     = pd.read_csv(FOLDER + 'slot_train.csv', converters={'train': str, 'st_from':str, 'st_to':str})\n",
    "loco_info      = pd.read_csv(FOLDER + 'loco_attributes.csv', converters={'train':str, 'loco':str, \n",
    "                                                                   'st_from':str, 'st_to':str, 'depot':str})\n",
    "loco_plan      = pd.read_csv(FOLDER + 'slot_loco.csv', converters={'train':str, 'loco':str, 'st_from':str, 'st_to':str})\n",
    "team_info      = pd.read_csv(FOLDER + 'team_attributes.csv', converters={'team':str,'depot':str, 'oper_location':str, \\\n",
    "                                                     'st_from':str, 'st_to':str, 'loco':str, 'depot_st':str})\n",
    "\n",
    "team_plan      = pd.read_csv(FOLDER + 'slot_team.csv', converters={'team':str,'loco':str, 'st_from':str, 'st_to':str})\n",
    "loco_series    = pd.read_csv(FOLDER + 'loco_series.csv')\n",
    "loco_info_regs = pd.read_csv(FOLDER + 'loco_info_regs.csv', converters={'loco':str})\n",
    "loco_tonnage   = pd.read_csv(FOLDER + 'loco_tonnage.csv', converters={'st_from':str, 'st_to':str})\n",
    "\n",
    "st_names = stations[['station', 'name', 'esr']].drop_duplicates().set_index('station')\n",
    "team_info.regions = team_info.regions.apply(literal_eval)\n",
    "\n",
    "print('Время составления отчета:', time.strftime(time_format, time.localtime()))\n",
    "print('Время запуска планировщика: %s (%d)' % (time.strftime(time_format, time.localtime(current_time)), current_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Мержим таблицы _plan и _info для поездов, локомотивов и бригад\n",
    "# Добавляем во все таблицы названия станций на маршруте и времена отправления/прибытия в читабельном формате\n",
    "\n",
    "def add_info(df):    \n",
    "    if 'st_from' in df.columns:\n",
    "        df['st_from_name'] = df.st_from.map(st_names.name)\n",
    "    if 'st_to' in df.columns:\n",
    "        df['st_to_name'] = df.st_to.map(st_names.name)\n",
    "    if 'time_start' in df.columns:\n",
    "        df['time_start_norm'] = df.time_start.apply(lambda x: time.strftime(time_format, time.localtime(x)))\n",
    "    if 'time_end' in df.columns:\n",
    "        df['time_end_norm'] = df.time_end.apply(lambda x: time.strftime(time_format, time.localtime(x)))\n",
    "    if 'oper_location' in df.columns:\n",
    "        df['oper_location_name'] = df.oper_location.map(st_names.name)    \n",
    "        df.oper_location_name.fillna(0, inplace=True)\n",
    "    if ('oper_location' in df.columns) & ('st_from' in df.columns) & ('st_to' in df.columns):        \n",
    "        df['loc_name'] = df.oper_location_name\n",
    "        df.loc[df.loc_name == 0, 'loc_name'] = df.st_from_name + ' - ' + df.st_to_name\n",
    "    \n",
    "add_info(train_plan)\n",
    "add_info(loco_plan)\n",
    "add_info(team_plan)\n",
    "add_info(loco_info)\n",
    "add_info(team_info)\n",
    "train_plan = train_plan.merge(train_info, on='train', suffixes=('', '_info'), how='left')\n",
    "loco_plan = loco_plan.merge(loco_info, on='loco', suffixes=('', '_info'), how='left')\n",
    "team_plan = team_plan.merge(team_info, on='team', suffixes=('', '_info'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Добавляем ссылку на бригаду в таблицу локомотивов\n",
    "# Добавляем ссылку на локомотив и бригаду в таблицу поездов\n",
    "\n",
    "loco_plan['loco_time'] = list(zip(loco_plan.loco , loco_plan.time_start))\n",
    "team_plan['loco_time'] = list(zip(team_plan.loco , team_plan.time_start))\n",
    "loco_plan['team'] = loco_plan.loco_time.map(team_plan.drop_duplicates('loco_time').set_index('loco_time').team)\n",
    "\n",
    "loco_plan['train_time'] = list(zip(loco_plan.train, loco_plan.time_start))\n",
    "train_plan['train_time'] = list(zip(train_plan.train, train_plan.time_start))\n",
    "train_plan['loco'] = train_plan.train_time.map(loco_plan.drop_duplicates('train_time').set_index('train_time').loco)\n",
    "train_plan['team'] = train_plan.train_time.map(loco_plan.drop_duplicates('train_time').set_index('train_time').team)\n",
    "\n",
    "add_info(loco_tonnage)\n",
    "loco_tonnage['link'] = list(zip(loco_tonnage.st_from, loco_tonnage.st_to))\n",
    "loco_tonnage['ssl'] = list(zip(loco_tonnage.series, loco_tonnage.sections, loco_tonnage.link))\n",
    "loco_tonnage['ser_name'] = loco_tonnage.series.map(loco_series.set_index('ser_id').ser_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='perc'></a>\n",
    "## Вычисление процента подвязки поездов и локомотивов [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент подвязки поездов и локомотивов на горизонте в  6 часов: 88.51% (поездов без локомотива - 536)\n",
      "Процент подвязки поездов и локомотивов на горизонте в 12 часов: 86.58% (поездов без локомотива - 626)\n",
      "Процент подвязки поездов и локомотивов на горизонте в 24 часов: 83.20% (поездов без локомотива - 784)\n",
      "Процент подвязки поездов и локомотивов на горизонте в 48 часов: 76.08% (поездов без локомотива - 1116)\n"
     ]
    }
   ],
   "source": [
    "def count_assign_percent(horizon):\n",
    "    mask = (train_plan.time_start < current_time + horizon)\n",
    "    bad_trains = train_plan.loc[mask & (train_plan.loco.isnull())]\n",
    "    bad_trains_n = bad_trains.drop_duplicates('train').train.count()\n",
    "    good_percent = 100 * (1 - bad_trains_n / total_trains_n)        \n",
    "    return 'Процент подвязки поездов и локомотивов на горизонте в %2.d часов: %.2f%% (поездов без локомотива - %d)'\\\n",
    "         % (horizon / 3600, good_percent, bad_trains_n)\n",
    "\n",
    "train_plan['train_type'] = train_plan.train.apply(lambda x: int(str(x)[0]))\n",
    "total_trains_n = train_plan[train_plan.train_type.isin([2, 9])].drop_duplicates('train').train.count()\n",
    "add_header('Вычисление процента подвязки поездов и локомотивов', p=False, h=2)\n",
    "add_line(count_assign_percent(6 * 3600))\n",
    "add_line(count_assign_percent(12 * 3600))\n",
    "add_line(count_assign_percent(24 * 3600))\n",
    "add_line(count_assign_percent(48 * 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Направления, на которые не удалось подвязать локомотив под поезд (первые 10 по количеству поездов):\n",
      "st_from_name                        st_to_name \n",
      "КОМСОМОЛЬСК-НА-АМУРЕ-СОРТИРОВОЧНЫЙ  МЫЛКИ          27\n",
      "ТАЙШЕТ                              БАЙРОНОВКА     22\n",
      "ЗАБАЙКАЛЬСК                         ХАРАНОР        15\n",
      "КРАСНОЯРСК-ВОСТОЧНЫЙ                ЗЫКОВО         13\n",
      "МАРИИНСК                            БОГОТОЛ        13\n",
      "БОРЗЯ                               ХАРАНОР        12\n",
      "НОВЫЙ УРГАЛ                         УРГАЛ I        12\n",
      "КАРЫМСКАЯ                           ТАРСКАЯ        11\n",
      "УССУРИЙСК                           БАРАНОВСКИЙ    10\n",
      "КИЯ-ШАЛТЫРЬ                         ДУБИНИНО       10\n"
     ]
    }
   ],
   "source": [
    "a = train_plan[(train_plan.time_start < current_time + 24 * 3600) & (train_plan.loco.isnull())]\\\n",
    "    .drop_duplicates('train')\\\n",
    "    .groupby(['st_from_name', 'st_to_name']).train\\\n",
    "    .count().sort_values(ascending=False)\n",
    "add_header('Направления, на которые не удалось подвязать локомотив под поезд (первые 10 по количеству поездов):')\n",
    "add_line(a.head(10))\n",
    "a.to_csv('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поезда со станции КОМСОМОЛЬСК-НА-АМУРЕ-СОРТИРОВОЧНЫЙ, к которым не были подвязаны локомотивы\n",
      "        train  weight              st_from_name            st_to_name  st_dest_name time_start_norm loco ser_name  sections\n",
      " 220206947962    5523  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 06, 14:41  NaN      NaN       NaN\n",
      " 200231306163    4525  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ  ХАБАРОВСК II   Jul 06, 14:41  NaN      NaN       NaN\n",
      " 200231587188    1726  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ      МАРИИНСК   Jul 06, 14:41  NaN      NaN       NaN\n",
      " 200231401345    1762  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ        ТАЙШЕТ   Jul 06, 14:41  NaN      NaN       NaN\n",
      " 200231214185    4669  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ  ХАБАРОВСК II   Jul 06, 14:52  NaN      NaN       NaN\n",
      " 220206129584    5524  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 06, 19:06  NaN      NaN       NaN\n",
      " 220204461424    5630  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 06, 20:21  NaN      NaN       NaN\n",
      " 220205173075    5549  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 06, 20:21  NaN      NaN       NaN\n",
      " 220206996907    6301  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 06, 22:21  NaN      NaN       NaN\n",
      " 220207163878    4920  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 01:01  NaN      NaN       NaN\n",
      " 220205708380    4857  КОМСОМОЛЬСК-НА-АМУРЕ-...  КОМСОМОЛЬСК-НА-АМУРЕ        ДЗЕМГИ   Jul 07, 01:01  NaN      NaN       NaN\n",
      " 220203721661    4845  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 01:01  NaN      NaN       NaN\n",
      " 200230459827    3934  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 03:37  NaN      NaN       NaN\n",
      " 220205155336    5589  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 05:46  NaN      NaN       NaN\n",
      " 220203556589    5557  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 06:59  NaN      NaN       NaN\n",
      " 200231525680    7674  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 06:59  NaN      NaN       NaN\n",
      " 220205751201    5581  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 07:06  NaN      NaN       NaN\n",
      " 220207661467    6298  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 07:31  NaN      NaN       NaN\n",
      " 220206230057    5608  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 07:57  NaN      NaN       NaN\n",
      " 200230911137    5553  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 07:58  NaN      NaN       NaN\n",
      " 220206225383    6288  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 08:08  NaN      NaN       NaN\n",
      " 220204739851    5560  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 11:18  NaN      NaN       NaN\n",
      " 220203077415    5598  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 13:43  NaN      NaN       NaN\n",
      " 220205265642    6297  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 13:54  NaN      NaN       NaN\n",
      " 200231065408    5552  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 14:26  NaN      NaN       NaN\n",
      " 200230329990    5575  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 14:26  NaN      NaN       NaN\n",
      " 210216027151    5587  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 14:26  NaN      NaN       NaN\n",
      " 220205184956    5555  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН        ВАНИНО   Jul 07, 14:26  NaN      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "(st_name, st2_name) = a.index[0]\n",
    "train_cols = ['train', 'weight', 'st_from_name', 'st_to_name', 'st_dest_name', 'time_start_norm', 'time_end_norm', 'loco', 'team']\n",
    "cols = ['train', 'weight', 'st_from_name', 'st_to_name', 'st_dest_name', 'time_start_norm', 'loco', 'ser_name', 'sections']\n",
    "routes = pd.read_csv(FOLDER + 'routes.csv', converters={'st_from':str, 'st_to':str, 'train':str})\n",
    "add_info(routes)\n",
    "routes['end'] = routes.train != routes.train.shift(-1)\n",
    "train_plan['st_dest_name'] = train_plan.train.map(routes[routes.end].set_index('train').st_to_name)\n",
    "loco_info['ser_name'] = loco_info.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "train_plan['ser_name'] = train_plan.loco.map(loco_info.set_index('loco').ser_name)\n",
    "train_plan['sections'] = train_plan.loco.map(loco_info.set_index('loco').sections)\n",
    "a = train_plan[(train_plan.time_start < current_time + 24 * 3600) \n",
    "               & (train_plan.loco.isnull())\n",
    "               & (train_plan.st_dest_name.isnull() == False)\n",
    "               & (train_plan.st_from_name == st_name)].drop_duplicates('train')\n",
    "add_header('Поезда со станции %s, к которым не были подвязаны локомотивы' % st_name)\n",
    "add_line(a.sort_values('time_start')[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='regions'></a>\n",
    "## Проверка наличия локомотивов только на своих тяговых плечах [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Проверка наличия локомотивов только на своих тяговых плечах', h=2, p=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='correct_reg_ser'></a>\n",
    "### Проверка назначения тяговых плеч локомотивам в соответствии с сериями [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка назначения тяговых плеч локомотивам в соответствии с сериями', h=3, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func(df, stations, st):    \n",
    "    a = links.loc[(links.st_from_name.isin(st))].st_from_name.value_counts()\n",
    "    b = links.loc[(links.st_from_name.isin(st)) & (links.st_to_name.isin(st))].st_from_name.value_counts()\n",
    "    c = a.to_frame().join(b, rsuffix='_reg')\n",
    "    c['delta'] = c.st_from_name - c.st_from_name_reg    \n",
    "    d = c.join(stations[['name', 'norm_time']].drop_duplicates().set_index('name'), how='right')\n",
    "    e = d.loc[((d.delta > 0) | (d.st_from_name == 1))]\n",
    "    return sorted(e.index.values)\n",
    "\n",
    "add_info(links)\n",
    "loco_info['regions_eval'] = loco_info.regions.apply(literal_eval)\n",
    "stations_regs = stations.groupby('station').loco_region.apply(lambda x: x.values)\n",
    "loco_info['ser_name'] = loco_info.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "reg_st = stations.groupby('loco_region')['name'].unique().to_frame()\n",
    "reg_st['short_name'] = reg_st['name'].apply(lambda x: func(links, stations, x))\n",
    "reg_st.columns = ['stations', 'reg_name']\n",
    "reg_borders = pd.read_csv(FOLDER + 'mandatory/loco_reg_borders.csv', encoding='utf-8-sig')\n",
    "bord = reg_borders.station.values\n",
    "reg_st['short_name'] = reg_st.reg_name.apply(lambda x: np.intersect1d(x, bord) if len(np.intersect1d(x, bord)) > 1 else [])\n",
    "big_borders = ['МАРИИНСК', 'БОРЗЯ', 'КАРЫМСКАЯ', 'ХАБАРОВСК II', 'МЕЖДУРЕЧЕНСК', 'ТАКСИМО', 'КОМСОМОЛЬСК-НА-АМУРЕ']\n",
    "reg_st['short_name'] = reg_st.short_name.apply(lambda x: np.intersect1d(x, big_borders) if len(x) > 2 else x)\n",
    "pd.set_option('display.max_colwidth', 60)\n",
    "#print(reg_st[['short_name']].to_string())\n",
    "#reg_st.ix[2002119307].reg_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     region                             reg_name_str                                 ser_name                ser_type  loco\n",
      " 2002119299                     ['БОРЗЯ' 'МАРИИНСК']  [ВЛ80С, ВЛ85, ВЛ80Р, 3ЭС5К, 2ЭС5К, В...            [Электровоз]   637\n",
      " 2002119294             ['КАРЫМСКАЯ' 'ХАБАРОВСК II']                    [3ЭС5К, ВЛ80С, 2ЭС5К]            [Электровоз]   572\n",
      " 2002119320           ['СМОЛЯНИНОВО' 'ХАБАРОВСК II']                    [3ЭС5К, 2ЭС5К, ВЛ80С]            [Электровоз]   222\n",
      " 2002119301               ['МЕЖДУРЕЧЕНСК' 'ТАКСИМО']  [2ЭС5К, ВЛ80ТК, 3ЭС5К, ВЛ80С, ВЛ80Т,...  [Электровоз, Тепловоз]   208\n",
      " 2002119296  ['КОМСОМОЛЬСК-НА-АМУРЕ' 'СОВЕТСКАЯ Г...  [3ТЭ10МК, 2ТЭ10МК, 2ТЭ10М, 2ТЭ10УК, ...              [Тепловоз]   115\n",
      " 2002119317                  ['СКОВОРОДИНО' 'ТЫНДА']  [3ТЭ10МК, 2ТЭ10МК, 2ТЭ25А, 2ТЭ10М, 3...              [Тепловоз]    83\n",
      " 2002119305            ['ИЗВЕСТКОВАЯ' 'НОВЫЙ УРГАЛ']  [3ТЭ10МК, 2ТЭ10МК, 2ТЭ10М, 2ТЭ10УК, ...              [Тепловоз]    77\n",
      " 2002119312      ['НАХОДКА-ВОСТОЧНАЯ' 'СМОЛЯНИНОВО']                           [3ЭС5К, 2ЭС5К]            [Электровоз]    63\n",
      " 2002119303                      ['ТАКСИМО' 'ТЫНДА']  [2ТЭ25А, 3ТЭ10МК, 2ТЭ10МК, 2ТЭ10М, 2...              [Тепловоз]    54\n",
      " 2002119292            ['ГРОДЕКОВО (КИТАЙ)' 'ХАСАН']  [3ТЭ10УК, 3ТЭ10М, 2ТЭ10МК, 2ТЭ10УК, ...              [Тепловоз]    24\n",
      " 2002119288                  ['БОРЗЯ' 'ЗАБАЙКАЛЬСК']  [2ТЭ10М, 3ТЭ10УК, 3ТЭ10МК, 2ТЭ10МК, ...              [Тепловоз]    22\n",
      " 2002119286               ['АЧИНСК I' 'ЛЕСОСИБИРСК']                         [2ТЭ10М, 2ТЭ10У]              [Тепловоз]    20\n",
      " 2002119310         ['НОВОКАЧАЛИНСК' 'НОВОЧУГУЕВКА']  [2ТЭ10УК, 2ТЭ10МК, 2ТЭ10М, 2ТЭ10У, 2...              [Тепловоз]    11\n",
      " 2002119318                    ['НАУШКИ' 'УЛАН-УДЭ']                        [2ТЭ10МК, 2ТЭ10М]              [Тепловоз]     9\n",
      " 2002119308                    ['КАРАБУЛА' 'РЕШОТЫ']                 [2ТЭ10М, 2ТЭ10В, 2ТЭ10У]              [Тепловоз]     6\n",
      " 2002119287             ['БЕЛОГОРСК' 'БЛАГОВЕЩЕНСК']                                 [2ТЭ10М]              [Тепловоз]     1\n"
     ]
    }
   ],
   "source": [
    "def save_to_excel(df, filename=FOLDER + 'reg_ser.xlsx'):    \n",
    "    df.to_excel(filename)\n",
    "    print('Excel file %s created' % filename)\n",
    "\n",
    "loco_info['ser_name'] = loco_info.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "loco_info['ser_desc'] = loco_info.series.map(loco_series.set_index('ser_id').ser_desc)\n",
    "loco_info['ser_type'] = loco_info.series.map(loco_series.set_index('ser_id').ser_type)\n",
    "loco_info_regs['number'] = loco_info.loco.map(loco_info.drop_duplicates('loco').set_index('loco').number)\n",
    "loco_info_regs['reg_name'] = loco_info_regs.region.map(reg_st.short_name)\n",
    "loco_info_regs['ser_name'] = loco_info_regs.loco.map(loco_info.set_index('loco').ser_name)\n",
    "loco_info_regs['ser_type'] = loco_info_regs.loco.map(loco_info.set_index('loco').ser_type)\n",
    "loco_info_regs['reg_name_str'] = loco_info_regs.reg_name.apply(str)\n",
    "loco_info_regs['ltype'] = loco_info_regs.loco.map(loco_info.set_index('loco').ltype)\n",
    "loco_info_regs.sort_values(['ser_name', 'reg_name_str'])[['loco', 'ser_name', 'reg_name']].set_index('loco')\\\n",
    "                .to_excel(FOLDER + 'ans.xlsx')\n",
    "a = loco_info_regs.groupby('reg_name_str').ser_name.unique()\n",
    "loco_info_regs['ser_desc'] = loco_info_regs.ser_name.map(loco_series.drop_duplicates('ser_name').set_index('ser_name').ser_desc)\n",
    "a = loco_info_regs.loc[(loco_info_regs.ltype == 1) & (loco_info_regs.ser_desc.isin(['Грузовое', 'Грузопассажирское']))]\\\n",
    "            .groupby(['region', 'reg_name_str']).ser_name.unique().to_frame()\n",
    "b = loco_info_regs.loc[(loco_info_regs.ltype == 1) & (loco_info_regs.ser_desc.isin(['Грузовое', 'Грузопассажирское']))]\\\n",
    "            .groupby(['region', 'reg_name_str']).ser_type.unique().to_frame()\n",
    "c = a.join(b)\n",
    "d = c.join(loco_info_regs.loc[loco_info_regs.ltype == 1].groupby(['region', 'reg_name_str']).loco.count())\n",
    "#print('Total locos:', loco_info.loco.drop_duplicates().count())\n",
    "#print('Freight locos:', loco_info.loc[loco_info.ser_desc.isin(['Грузовое', 'Грузопассажирское'])].loco.drop_duplicates().count())\n",
    "#print('Locos of type = 1:', loco_info[loco_info.ltype == 1].loco.drop_duplicates().count())\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "add_line(d.reset_index().sort_values('loco', ascending=False))\n",
    "#save_to_excel(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_ser = d.reset_index()[['region', 'ser_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='correct_reg_plan'></a>\n",
    "### Проверка выезда локомотивов за пределы своих тяговых плеч [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка выезда локомотивов за пределы своих тяговых плеч', h=3, p=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавляем тяговое плечо в таблицу линков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations['regions'] = stations.station.map(stations.groupby('station').loco_region.unique())\n",
    "stations_unique = stations.drop_duplicates('station').set_index('station')\n",
    "links['st_from_regs'] = links.st_from.map(stations_unique.regions)\n",
    "links['st_to_regs'] = links.st_to.map(stations_unique.regions)\n",
    "links['regs'] = links.st_from_regs.combine(links.st_to_regs, np.intersect1d)\n",
    "links['link'] = list(zip(links.st_from, links.st_to))\n",
    "regs = reg_st.reset_index()\n",
    "links['reg_name'] = links.regs.apply(lambda x: regs[regs.loco_region.isin(x)].short_name.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавляем текущее тяговое плечо в каждый участок планов по локомотивам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['curr_reg'] = loco_plan.link.map(links.drop_duplicates('link').set_index('link').regs)\n",
    "loco_plan['curr_reg_name'] = loco_plan.link.map(links.drop_duplicates('link').set_index('link').reg_name)\n",
    "loco_plan['regions'] = loco_plan.loco.map(loco_info.set_index('loco').regions_eval)\n",
    "loco_info['reg_names'] = loco_info.regions_eval.apply(lambda x: \\\n",
    "                                                      regs[regs.loco_region.isin([int(i) for i in x])].short_name.values)\n",
    "loco_plan['reg_names'] = loco_plan.loco.map(loco_info.set_index('loco').reg_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисляем, есть у локомотива текущее тяговое плечо в списке разрешенных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['ok_reg'] = loco_plan.curr_reg.combine(loco_plan.regions, np.intersect1d).apply(len) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисляем тяговое плечо на исходном местоположении локомотива"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_current_region(row):\n",
    "    if row.st_from == '-1':        \n",
    "        a = links[links.st_from == row.oper_location].regs.values\n",
    "    else:\n",
    "        a = links[(links.st_from == row.st_from) & (links.st_to == row.st_to)].regs.values\n",
    "    return list(np.concatenate(a) if len(a) > 0 else [])\n",
    "        \n",
    "loco_info['location'] = list(zip(loco_info.oper_location, loco_info.st_from, loco_info.st_to))\n",
    "loco_info['curr_reg'] = loco_info.apply(lambda row: get_current_region(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисляем, находится ли локомотив на своем тяговом плече на начало планирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loco_info['ok_reg'] = loco_info.curr_reg.combine(loco_info.regions_eval, np.intersect1d).apply(len) > 0\n",
    "loco_plan['info_ok_reg'] = loco_plan.loco.map(loco_info.drop_duplicates('loco').set_index('loco').ok_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Составляем список локомотивов, выезжающих за пределы своих ТП в процессе планирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_out_of_regs = loco_plan[(loco_plan.curr_reg_name.isnull() == False) \n",
    "                             & (loco_plan.ok_reg == False) & (loco_plan.info_ok_reg == True)]\n",
    "cols = ['loco', 'ser_name', 'reg_names', 'st_from_name', 'st_to_name', 'train', 'state', 'loc_name']\n",
    "add_line('Всего %d локомотивов, выезжающих за пределы своих тяговых плеч в процессе планирования:' \n",
    "           % loco_out_of_regs.loco.drop_duplicates().count())\n",
    "add_line('- %d следуют резервом;' % (loco_out_of_regs[loco_out_of_regs.state == 0].loco.drop_duplicates().count()))\n",
    "add_line('- %d с поездами.' % (loco_out_of_regs[loco_out_of_regs.state == 1].loco.drop_duplicates().count()))\n",
    "\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "states = sorted(loco_out_of_regs.state.unique())\n",
    "for s in states:\n",
    "    add_header('\\nПримеры локомотивов в состоянии %d за пределами своих тяговых плеч:' % s)\n",
    "    add_line(loco_out_of_regs[loco_out_of_regs.state == s].drop_duplicates('loco')[cols].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bad_regs_loco_info'></a>\n",
    "### Локомотивы на чужих тяговых плечах на начало планирования [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Локомотивы на чужих тяговых плечах на начало планирования', h=3, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['loco', 'ser_name', 'loc_name', 'reg_names']\n",
    "bad_regs_loco_info = loco_info[(loco_info.ltype == 1) & (loco_info.ok_reg == False)]\n",
    "add_header('Всего %d локомотивов на чужих тяговых плечах на начало планирования' % bad_regs_loco_info.loco.count())\n",
    "add_header('\\nРаспределение по сериям (показаны первые 5):')\n",
    "add_line(bad_regs_loco_info[cols].ser_name.value_counts().head())\n",
    "add_header('\\nРаспределение по тяговым плечам локомотивов (показаны первые 5):')\n",
    "add_line(bad_regs_loco_info[cols].reg_names.value_counts().head())\n",
    "add_header('\\nПримеры локомотивов:')\n",
    "add_line(bad_regs_loco_info[cols].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='st_to2'></a>\n",
    "## Проверка пунктов проведения ТО-2 [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка планирования ТО-2', h=2, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to2_type = 2001889869\n",
    "service = pd.read_csv(FOLDER + 'service.csv', converters={'station':str})\n",
    "service['st_name'] = service.station.map(st_names.name)\n",
    "service['dur_h'] = np.round((service.duration / 3600), 2)\n",
    "to2 = service[service.serv_type == to2_type].drop_duplicates()\n",
    "to2_dur_median = to2.dur_h.median()\n",
    "add_header('Пункты проведения ТО-2 во входных данных:')\n",
    "add_line(to2[['st_name', 'dur_h']].sort_values('st_name'))\n",
    "add_line('Медианное время проведения ТО-2: %.2f часа' % to2_dur_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['tt'] = loco_plan.time_end - loco_plan.time_start\n",
    "plan_to = loco_plan[loco_plan.state == 4][['loco', 'st_from_name', 'st_to_name', 'time_start_norm', 'time_end_norm', 'tt']]\n",
    "add_header('Проведение ТО запланировано на %d разных станциях (показаны первые 10):' \n",
    "           % plan_to.st_from_name.drop_duplicates().count())\n",
    "stats_plan_to = plan_to.st_from_name.value_counts().to_frame().join(plan_to.groupby('st_from_name').tt.median())\n",
    "stats_plan_to.columns = ['num', 'time']\n",
    "stats_plan_to['time_h'] = np.round((stats_plan_to.time / 3600), 2)\n",
    "add_line(stats_plan_to[['num', 'time_h']].reset_index().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='tonnage'></a>\n",
    "## Проверка подвязки на соответствие весовым нормам [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Проверка подвязки на соответствие весовым нормам', h=2, p=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Маска времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ниже надо раскомментировать соответствующую строчку для нужного анализа\n",
    "\n",
    "def time_mask(df):\n",
    "    # Маска для анализа поездов, которые запланировал планировщик (отправленных после начала планирования)\n",
    "    return df.time_start >= current_time\n",
    "    # Маска для анализа позедов, отправленных до начала планирования (следующих по факту)\n",
    "    #time_mask = overweight.time_start < current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка соответствия результатов планирования справочнику весовых норм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['ser_name'] = loco_plan.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "loco_tonnage = pd.read_csv(FOLDER + 'loco_tonnage.csv', converters={'st_from':str, 'st_to':str})\n",
    "loco_tonnage['link'] = list(zip(loco_tonnage.st_from, loco_tonnage.st_to))\n",
    "loco_tonnage['ssl'] = list(zip(loco_tonnage.series, loco_tonnage.sections, loco_tonnage.link))\n",
    "loco_plan['link'] = list(zip(loco_plan.st_from, loco_plan.st_to))\n",
    "loco_plan['link_name'] = list(zip(loco_plan.st_from_name, loco_plan.st_to_name))\n",
    "loco_plan['ssl'] = list(zip(loco_plan.series, loco_plan.sections, loco_plan.link))\n",
    "loco_plan['max_weight'] = loco_plan.ssl.map(loco_tonnage.groupby('ssl').max_weight.max().to_frame().max_weight)\n",
    "loco_plan['train_weight'] = loco_plan.train.map(train_info.drop_duplicates('train').set_index('train').weight)\n",
    "loco_plan['overweight'] = loco_plan.train_weight - loco_plan.max_weight\n",
    "cols = ['loco', 'ser_name', 'st_from_name', 'st_to_name', 'time_start_norm', 'max_weight', 'train_weight', 'overweight', 'train']\n",
    "overweight = loco_plan[(loco_plan.overweight > 0)].dropna(subset=['max_weight']).drop_duplicates(subset=['loco', 'train'])\n",
    "overweight_plan = overweight[time_mask(overweight)] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<< TIME_MASK -----------------------\n",
    "overweight_n = len(overweight_plan.index)\n",
    "add_header('Всего %d подвязок локомотивов к поезду с нарушением весовых норм (показаны первые 10):' % overweight_n)\n",
    "pd.set_option('display.max_colwidth', 15)\n",
    "add_line(overweight_plan.sort_values('overweight', ascending=False).head(10)[cols])\n",
    "\n",
    "overweight_no_joint = overweight_plan[overweight_plan.train_weight < 10000]\n",
    "add_header('\\nВсего %d подвязок локомотивов к поездам (за исключением сдвоенных) с нарушением весовых норм (показаны первые 10):' \n",
    "      % len(overweight_no_joint.index))\n",
    "add_line(overweight_no_joint.sort_values('overweight', ascending=False).head(10)[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', context='talk')\n",
    "sns.set_color_codes('dark')\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
    "sns.distplot(overweight_plan.train_weight, hist=False, color='b', \n",
    "             kde_kws={'shade':True, 'label':'Вес поезда'}, ax=ax[0])\n",
    "sns.distplot(overweight_plan.overweight, hist=False, color='g', \n",
    "             kde_kws={'shade':True, 'label':'Превышение весовой нормы'}, ax=ax[0])\n",
    "sns.distplot(overweight_no_joint.train_weight, hist=False, color='b', \n",
    "             kde_kws={'shade':True, 'label':'Вес поезда'}, ax=ax[1])\n",
    "sns.distplot(overweight_no_joint.overweight, hist=False, color='g', \n",
    "             kde_kws={'shade':True, 'label':'Превышение весовой нормы'}, ax=ax[1])\n",
    "title = 'Для всех поездов'\n",
    "title_nj = 'Без сдвоенных поезов'\n",
    "ax[0].set(title=title, xlabel='Вес поезда')\n",
    "ax[1].set(title=title_nj, xlabel='Вес поезда')\n",
    "ax[0].legend(frameon=True)\n",
    "ax[1].legend(frameon=True)\n",
    "plt.suptitle('Распределение весов поездов, для которых наблюдается нарушение весовых норм', fontsize=20)\n",
    "sns.despine()\n",
    "filename = 'weight_error.png'\n",
    "fig.savefig(REPORT_FOLDER + filename, bbox_inches='tight')\n",
    "add_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Распределение нарушений весовых норм по участкам (первые 5):')\n",
    "a = overweight_no_joint.link_name.value_counts()\n",
    "b = overweight_no_joint.groupby('link_name').overweight.median()\n",
    "overweight_links = a.to_frame().join(b)\n",
    "overweight_links.columns = ['number', 'overw_median']\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "add_line(overweight_links.reset_index().head())\n",
    "\n",
    "add_header('\\nРаспределение нарушений весовых норм по сериям локомотивов:')\n",
    "a = overweight_no_joint.ser_name.value_counts()\n",
    "b = overweight_no_joint.groupby('ser_name').overweight.median()\n",
    "overweight_ser = a.to_frame().join(b)\n",
    "overweight_ser.columns = ['number', 'overw_median']\n",
    "add_line(overweight_ser.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='change'></a>\n",
    "## Проверка смены локомотивов на станциях обязательной смены [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка смены локомотивов на станциях обязательной смены', h=2, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hor = 24 * 3600\n",
    "cols = ['train', 'st_from_name', 'st_to_name', 'time_start_norm', 'loco', 'train_start', 'loco_start']\n",
    "train_plan['train_start'] = train_plan.train != train_plan.train.shift(1)\n",
    "train_plan['loco_start'] = (train_plan.loco != train_plan.loco.shift(1)) & (train_plan.loco.isnull() == False)\n",
    "loco_changes = train_plan.loc[(train_plan.train_start == False) & (train_plan.loco_start == True) &\n",
    "              (train_plan.time_start < current_time + hor)]\n",
    "add_header('Станции смены локомотивов (показаны первые 10):')\n",
    "add_line(loco_changes.st_from_name.value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Список станций (первый столбец), на которых локомотивы меняются всегда,\n",
    "# если в машруте поезда есть любая из проверочных станций (второй столбец)\n",
    "st_list = [['КАРЫМСКАЯ',['УРУЛЬГА']], ['БОРЗЯ',['ХАРАНОР','ЗУН-ТОРЕЙ']], ['ТАКСИМО', ['КУАНДА','КАЗАНКАН']], \n",
    "           ['СКОВОРОДИНО', ['ШТУРМ']], ['ИЗВЕСТКОВАЯ', ['КУЛЬДУР']], ['ВОЛОЧАЕВКА II', ['СЕЛЬГОН']], \n",
    "           ['УССУРИЙСК', ['ПРИМОРСКАЯ', 'ГРОДЕКОВО']]]\n",
    "df_list = pd.DataFrame(st_list, columns=['st', 'other_st'])\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "add_header('Станции обязательной смены локомотивов:')\n",
    "add_line(df_list)\n",
    "a = train_plan.groupby('train').st_from_name.unique().to_frame()\n",
    "a.columns = ['route']\n",
    "train_plan['route'] = train_plan.train.map(a.route)\n",
    "# Если проверочная станция находится в маршруте поезда, значит, поезд едет в том направлении, где НАДО менять локомотив\n",
    "train_plan['check_st'] = train_plan.st_from_name.map(df_list.set_index('st').other_st)\n",
    "train_plan['in_route'] = train_plan.route.combine(train_plan.check_st, \\\n",
    "                                                  lambda x, y: not False in [st in x for st in y] if type(y) == list else False)\n",
    "\n",
    "cols = ['train', 'st_from_name', 'st_to_name', 'time_start_norm', 'loco', 'in_route']\n",
    "change_fails = train_plan.loc[(train_plan.time_start < current_time + hor) \n",
    "                              & (train_plan.train_type.isin([2, 9]))\n",
    "                              & (train_plan.train_start == False)\n",
    "                              & (train_plan.loco_start == False)\n",
    "                              & (train_plan.st_from_name.isin(df_list.st))\n",
    "                              & (train_plan.in_route == True)][cols].drop_duplicates().dropna(subset=['loco'])\n",
    "add_header('\\nВсего %d поездов, у которых должна быть смена локомотивов на станциях обязательной смены, но она не запланирована:' \n",
    "      % len(change_fails))\n",
    "add_line(change_fails.sort_values(['st_to_name', 'time_start_norm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res'></a>\n",
    "## Анализ локомотивов резервом [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Анализ локомотивов резервом', h=2, p=False)\n",
    "hor = 24 * 3600\n",
    "add_line('Анализируемый горизонт отправления: %.2f ч.' % (hor / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res_nums'></a>\n",
    "### Проверка диапазона номеров для локомотивов резервом [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_plan.columns\n",
    "train_plan['train_type'] = train_plan.train.apply(lambda x: int(str(x)[0]))\n",
    "train_plan['res_train_num'] = train_plan.train.apply(lambda x: int(str(x)[-4:]))\n",
    "res_train_nums = train_plan[train_plan.train_type == 8].res_train_num.drop_duplicates()\n",
    "add_line('Диапазон номеров поездов для локомотивов резервом: от %d до %d' % (res_train_nums.min(), res_train_nums.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res_amount'></a>\n",
    "### Анализ количества отправлений локомотивов резервом по направлениям [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_mask = loco_plan.time_start < current_time + hor\n",
    "loco_cols = ['loco', 'st_from_name', 'st_to_name', 'time_start', 'time_start_norm', 'time_end_norm',\n",
    "             'state', 'train', 'res_start', 'res_end']\n",
    "loco_plan['res_start'] = loco_plan.train != loco_plan.train.shift(1)\n",
    "loco_plan['res_end'] = loco_plan.train != loco_plan.train.shift(-1)\n",
    "loco_plan.loc[loco_plan.state == 0, loco_cols]\n",
    "loco_res_start = loco_plan.loc[(loco_plan.res_start == True) &\n",
    "                               (loco_plan.state == 0), loco_cols].sort_values(['loco', 'time_start'])\n",
    "loco_res_end = loco_plan.loc[(loco_plan.res_end == True) & (loco_plan.state == 0), loco_cols].sort_values(['loco', 'time_start'])\n",
    "cols = ['loco', 'st_from_name', 'st_to_name', 'st_to_name_end', 'time_start', 'time_start_norm', 'time_end_norm', 'train']\n",
    "loco_res_trips = loco_res_start[['loco', 'st_from_name', 'st_to_name', 'time_start', 'time_start_norm', 'train']].\\\n",
    "                set_index(['loco', 'train']).join(loco_res_end[['loco', 'st_to_name', 'time_end_norm', 'train']].\\\n",
    "                                                  set_index(['loco', 'train']), rsuffix='_end').reset_index()[cols]\n",
    "\n",
    "loco_res_trips_hor = loco_res_trips.loc[loco_res_trips.time_start < current_time + hor]\n",
    "add_line('Всего отправок локомотивов резервом: %d' % loco_res_trips_hor.loco.count())\n",
    "add_line('Всего локомотивов, для которых есть пересылка резервом: %d' % loco_res_trips_hor.loco.drop_duplicates().count())\n",
    "add_header('\\nСтанции, с которых было отправлено больше всего локомотивов резервом (первые 10):')\n",
    "add_line(loco_res_trips_hor.st_from_name.value_counts().head(10))\n",
    "add_header('\\nУчастки планирования, на которых было отправлено больше всего локомотивов резервом (первые 10):')\n",
    "add_line(loco_res_trips_hor.groupby('st_from_name').st_to_name.value_counts().sort_values(ascending=False).head(10))\n",
    "add_header('\\nСамые частые маршруты для локомотивов резервом (первые 10):')\n",
    "add_line(loco_res_trips_hor.groupby('st_from_name').st_to_name_end.value_counts().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res_before'></a>\n",
    "### Локомотивы резервом до начала планирования [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_info(links)\n",
    "add_line('Время начала планирования: %s (%d)' % (time.strftime(time_format, time.localtime(current_time)), current_time))\n",
    "loco_res_trips['link_name'] = list(zip(loco_res_trips.st_from_name, loco_res_trips.st_to_name))\n",
    "links['link_name'] = list(zip(links.st_from_name, links.st_to_name))\n",
    "loco_res_trips['dir'] = loco_res_trips.link_name.map(links.drop_duplicates('link_name').set_index('link_name')['dir'])\n",
    "loco_res_trips_hor = loco_res_trips.loc[loco_res_trips.time_start < current_time + hor]\n",
    "    \n",
    "cols = ['loco', 'st_from_name', 'st_to_name_end', 'time_start', 'time_start_norm', 'dir', 'train']\n",
    "res_before_ct = loco_res_trips.loc[loco_res_trips.time_start < current_time, cols]\n",
    "add_header('Всего %d локомотивов, отправленных резервом до начала планирования (показаны первые 10):' % len(res_before_ct.index))\n",
    "if not res_before_ct.empty:\n",
    "    add_line(res_before_ct.sort_values('time_start').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res_even'></a>\n",
    "### Локомотивы резервом в четном направлении [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['loco', 'st_from_name', 'st_to_name_end', 'time_start', 'time_start_norm', 'dir', 'train']\n",
    "even_res = loco_res_trips.loc[loco_res_trips.dir == 0, cols]\n",
    "even_res_hor = loco_res_trips_hor.loc[loco_res_trips_hor.dir == 0, cols]\n",
    "a = even_res_hor.groupby('st_from_name').st_to_name_end.value_counts().sort_values(ascending=False)\n",
    "add_header('Самые частые маршруты для локомотивов резервом в четном направлении (всего %d, показаны первые 10):' \n",
    "      % even_res_hor.loco.drop_duplicates().count())\n",
    "add_line(a.head(10))\n",
    "\n",
    "st_from = a.to_frame().reset_index().ix[0]['st_from_name']\n",
    "st_to = a.to_frame().reset_index().ix[0]['st_to_name_end']\n",
    "most_even_res = even_res_hor.loc[(even_res_hor.st_from_name == st_from) \n",
    "                                 & (even_res_hor.st_to_name_end == st_to)].sort_values('time_start')\n",
    "add_header('\\nЛокомотивы резервом на самом частном маршруте в четном направлении:')\n",
    "add_line(most_even_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Причины появления четных локомотивов резервом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Мариинск и Карымская не являются станциями прохождения ТО. Поэтому локомотивы пересылаются резервом из Мариинска в Боготол для прохождения ТО или из Читы на Карымскую после прохождения ТО в Чите для подвязки под поезда в Карымской. Необходимо обновить справочник ПТОЛ.\n",
    "2. У локомотивов среди разрешенных тяговых плеч указаны и Мариинск-Борзя, и Карымская-Хабаровск. Поэтому локомотивы едут резервом из Читы в Карымскую, чтобы везти локомотивы на Хабаровск, поскольку Чита совсем недалеко от Карымской. Если бы у локомотивов с плеча Мариинск-Борзя не было проставлено плечо Карымская-Хабаровск, то направления резервом из Читы не было бы. Необходимо загрузить новый справочник тяговых плеч, где такого не будет.\n",
    "3. Поезда своего формирования (ССП) из Карымской следуют только до Читы. Поэтому локомотивы и освобождаются в Чите. Но поскольку в Чите они не нужны, то следуют резервом \"куда-то, где нужны\". В новом справочнике от Войтенко поезда СФ из Карымской следуют до Иркутска, Челутая и Петровского Завода -- это дальше Читы. Поэтому отправлений резервом из Читы станет меньше. Аналогичная проблема: для поездов СФ из Красноярска-Восточного и Тайшета.\n",
    "4. Недостаточное количество поездов в четном направлении на главном ходу -- поэтому локомотивы, которые могли бы ехать в четную сторону с поездами, едут резервом. Будет исправлено с загрузкой новых маршрутов.\n",
    "5. Смена локомотивов происходит на станции Горелый (для маршрутов типа Карымская--Беркакит или Таксимо--Карымская, например). Хотя поезд правильнее заводить на Сковородино и менять локомотив там. Проблема в том, что тогда на маршруте поезда получится петля типа \"Бамовская -- Горелый -- Сковородино -- Горелый -- Штурм\". Текущий алгоритм построения маршрутов не сможет сгенерировать такой маршрут у поезда. Видимо, нужна более продвинутая проверка на приоритетные станции при смене локомотивов и корректировка маршрута поезда. Сложная проблема, надо думать. Пока отложено до 10.05.2016.\n",
    "6. Узел Комсомольска-на-Амуре сложный, надо разбираться. Возможно, надо будет вводить дополнительный участок планирования КнА II - КнА-Сорт. Тоже сложная проблема, тоже пока отложено до 10.05.2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='time_leaps'></a>\n",
    "## Проверка скачков по времени назад [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка скачков по времени назад', h=2, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['next_time_start'] = loco_plan.time_start.shift(-1)\n",
    "loco_plan['next_time_start_norm'] = loco_plan.time_start_norm.shift(-1)\n",
    "loco_plan['loco_end'] = loco_plan.loco != loco_plan.loco.shift(-1)\n",
    "cols = ['loco', 'st_from_name', 'st_to_name', 'time_start_norm', 'time_end_norm', 'next_time_start_norm']\n",
    "leaps = loco_plan[(loco_plan.loco_end == False) & (loco_plan.next_time_start < loco_plan.time_end)]\n",
    "if leaps.empty:\n",
    "    add_header('Не найдено локомотивов со скачками по времени назад в плане')\n",
    "else:\n",
    "    add_header('Всего %d локомотивов со скачками по времени назад в плане. Примеры:' % leaps.loco.count())\n",
    "    add_line(leaps.head(10)[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='report'></a>\n",
    "### Экспорт результатов в HTML [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = REPORT_FOLDER + 'loco_report_' + time.strftime('%Y%m%d_%H%M%S', time.localtime(time.time())) + '.html'\n",
    "create_report(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
