{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Список тестов по запланированным локомотивам:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Вычисление процента подвязки поездов и локомотивов.](#perc)\n",
    "2. [Проверка правильности назначениях тяговых плеч локомотивам во входных данных.](#regions)\n",
    "   1. [Проверка назначения тяговых плеч локомотивам в соответствии с сериями](#correct_reg_ser)\n",
    "   2. [Проверка невыезда локомотива за пределы своих тяговых плеч в процессе планирования](#correct_reg_plan)\n",
    "   3. [Локомотивы на чужих тяговых плечах на начало планирования](#bad_regs_loco_info)\n",
    "3. [Проверка пунктов проведения ТО-2.](#st_to2)\n",
    "4. [Проверка подвязки на соответствие весовым нормам.](#tonnage)\n",
    "5. [Проверка смен локомотива на станциях обязательной смены.](#change)\n",
    "6. [Анализ локомотивов резервом.](#res)\n",
    "   1. [Проверка номеров поездов, соответствующих локомотивам резервом.](#res_nums)\n",
    "   2. [Вычисление количества локомотивов резервом по направлениям.](#res_amount)\n",
    "   3. [Проверка отправления локомотивов резервом до начала планирования.](#res_before)\n",
    "   4. [Анализ отправления локомотивов резервом в четную сторону.](#res_even)\n",
    "7. [Проверка скачков по времени назад](#time_leaps)\n",
    "7. [Создание отчета](#report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Константы и настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = ''\n",
    "FOLDER = 'resources/'\n",
    "REPORT_FOLDER = 'report/'\n",
    "PRINT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для экспорта в HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_line(line, p=PRINT):    \n",
    "    global report        \n",
    "    if p:        \n",
    "        if type(line) == str:\n",
    "            print(line)        \n",
    "        elif type(line) == pd.core.frame.DataFrame:\n",
    "            print(line.to_string(index=False))\n",
    "        elif type(line) == pd.core.series.Series:\n",
    "            print(line.to_string())\n",
    "    if type(line) == pd.core.frame.DataFrame:        \n",
    "        report += ('%s<br>' % line.to_html(index=False))\n",
    "    elif type(line) == pd.core.series.Series:\n",
    "        report += ('%s<br>' % line.to_frame().reset_index().to_html(index=False))\n",
    "    else:                \n",
    "        report += ('%s<br>' % line)\n",
    "    \n",
    "def add_header(header, h=4, p=PRINT):\n",
    "    global report    \n",
    "    report += ('<h%d>%s</h%d>' % (h, header, h))    \n",
    "    if p:\n",
    "        print(header)\n",
    "        \n",
    "def add_image(filename):\n",
    "    global report\n",
    "    report += ('<img src=\"%s\" alt=\"%s\" height=\"40%%\">' % (filename, filename))\n",
    "\n",
    "def create_report(filename):\n",
    "    global report\n",
    "    report = report.replace('<table border=\"1\" class=\"dataframe\">','<table class=\"table table-striped\">')\n",
    "    html_string = '''\n",
    "        <html>\n",
    "            <head>\n",
    "                <link rel=\"stylesheet\" href=\"skeleton.css\">\n",
    "                <style>body{ margin:20 20; background:whitesmoke; }\n",
    "                table {table-layout : fixed}\n",
    "                </style>\n",
    "            </head>\n",
    "            <body>\n",
    "                <h1>Проверки по локомотивам</h1>        \n",
    "                %s\n",
    "            </body>\n",
    "        </html>''' % (report)\n",
    "    f = open(filename,'w', encoding='utf-8-sig')\n",
    "    f.write(html_string)\n",
    "    f.close()\n",
    "    print('Отчет сформирован за %.2f сек. и записан в файл %s' % (time.time() - start_time, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время составления отчета: Jul 19, 18:01\n",
      "Время запуска планировщика: Jul 15, 14:41 (1468582897)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import get_ipython\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rc('font', family='Times New Roman')\n",
    "\n",
    "pd.set_option('max_rows', 50)\n",
    "pd.set_option('display.max_colwidth', 25)\n",
    "\n",
    "time_format = '%b %d, %H:%M'\n",
    "\n",
    "start_time = time.time()\n",
    "current_time   = pd.read_csv(FOLDER + 'current_time.csv').current_time[0]\n",
    "twr            = pd.read_csv(FOLDER + 'team_work_region.csv', converters={'team_work_region':str})\n",
    "links          = pd.read_csv(FOLDER + 'link.csv', converters={'st_from':str, 'st_to':str})\n",
    "stations       = pd.read_csv(FOLDER + 'station.csv', converters={'station':str})\n",
    "train_info     = pd.read_csv(FOLDER + 'train_info.csv', converters={'train': str, 'st_from':str, 'st_to':str})\n",
    "train_plan     = pd.read_csv(FOLDER + 'slot_train.csv', converters={'train': str, 'st_from':str, 'st_to':str})\n",
    "loco_info      = pd.read_csv(FOLDER + 'loco_attributes.csv', converters={'train':str, 'loco':str, \n",
    "                                                                   'st_from':str, 'st_to':str, 'depot':str})\n",
    "loco_plan      = pd.read_csv(FOLDER + 'slot_loco.csv', converters={'train':str, 'loco':str, 'st_from':str, 'st_to':str})\n",
    "team_info      = pd.read_csv(FOLDER + 'team_attributes.csv', converters={'team':str,'depot':str, 'oper_location':str, \\\n",
    "                                                     'st_from':str, 'st_to':str, 'loco':str, 'depot_st':str})\n",
    "\n",
    "team_plan      = pd.read_csv(FOLDER + 'slot_team.csv', converters={'team':str,'loco':str, 'st_from':str, 'st_to':str})\n",
    "loco_series    = pd.read_csv(FOLDER + 'loco_series.csv')\n",
    "loco_info_regs = pd.read_csv(FOLDER + 'loco_info_regs.csv', converters={'loco':str})\n",
    "loco_tonnage   = pd.read_csv(FOLDER + 'loco_tonnage.csv', converters={'st_from':str, 'st_to':str})\n",
    "\n",
    "st_names = stations[['station', 'name', 'esr']].drop_duplicates().set_index('station')\n",
    "team_info.regions = team_info.regions.apply(literal_eval)\n",
    "\n",
    "print('Время составления отчета:', time.strftime(time_format, time.localtime()))\n",
    "print('Время запуска планировщика: %s (%d)' % (time.strftime(time_format, time.localtime(current_time)), current_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Мержим таблицы _plan и _info для поездов, локомотивов и бригад\n",
    "# Добавляем во все таблицы названия станций на маршруте и времена отправления/прибытия в читабельном формате\n",
    "\n",
    "def add_info(df):    \n",
    "    if 'st_from' in df.columns:\n",
    "        df['st_from_name'] = df.st_from.map(st_names.name)\n",
    "    if 'st_to' in df.columns:\n",
    "        df['st_to_name'] = df.st_to.map(st_names.name)\n",
    "    if 'time_start' in df.columns:\n",
    "        df['time_start_norm'] = df.time_start.apply(lambda x: time.strftime(time_format, time.localtime(x)))\n",
    "    if 'time_end' in df.columns:\n",
    "        df['time_end_norm'] = df.time_end.apply(lambda x: time.strftime(time_format, time.localtime(x)))\n",
    "    if 'oper_location' in df.columns:\n",
    "        df['oper_location_name'] = df.oper_location.map(st_names.name)    \n",
    "        df.oper_location_name.fillna(0, inplace=True)\n",
    "    if ('oper_location' in df.columns) & ('st_from' in df.columns) & ('st_to' in df.columns):        \n",
    "        df['loc_name'] = df.oper_location_name\n",
    "        df.loc[df.loc_name == 0, 'loc_name'] = df.st_from_name + ' - ' + df.st_to_name\n",
    "    \n",
    "add_info(train_plan)\n",
    "add_info(loco_plan)\n",
    "add_info(team_plan)\n",
    "add_info(loco_info)\n",
    "add_info(team_info)\n",
    "train_plan = train_plan.merge(train_info, on='train', suffixes=('', '_info'), how='left')\n",
    "loco_plan = loco_plan.merge(loco_info, on='loco', suffixes=('', '_info'), how='left')\n",
    "team_plan = team_plan.merge(team_info, on='team', suffixes=('', '_info'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Добавляем ссылку на бригаду в таблицу локомотивов\n",
    "# Добавляем ссылку на локомотив и бригаду в таблицу поездов\n",
    "\n",
    "loco_plan['loco_time'] = list(zip(loco_plan.loco , loco_plan.time_start))\n",
    "team_plan['loco_time'] = list(zip(team_plan.loco , team_plan.time_start))\n",
    "loco_plan['team'] = loco_plan.loco_time.map(team_plan.drop_duplicates('loco_time').set_index('loco_time').team)\n",
    "\n",
    "loco_plan['train_time'] = list(zip(loco_plan.train, loco_plan.time_start))\n",
    "train_plan['train_time'] = list(zip(train_plan.train, train_plan.time_start))\n",
    "train_plan['loco'] = train_plan.train_time.map(loco_plan.drop_duplicates('train_time').set_index('train_time').loco)\n",
    "train_plan['team'] = train_plan.train_time.map(loco_plan.drop_duplicates('train_time').set_index('train_time').team)\n",
    "\n",
    "add_info(loco_tonnage)\n",
    "loco_tonnage['link'] = list(zip(loco_tonnage.st_from, loco_tonnage.st_to))\n",
    "loco_tonnage['ssl'] = list(zip(loco_tonnage.series, loco_tonnage.sections, loco_tonnage.link))\n",
    "loco_tonnage['ser_name'] = loco_tonnage.series.map(loco_series.set_index('ser_id').ser_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='perc'></a>\n",
    "## Вычисление процента подвязки поездов и локомотивов [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент подвязки поездов и локомотивов на горизонте в  6 часов: 84.21% (поездов без локомотива - 738)\n",
      "Процент подвязки поездов и локомотивов на горизонте в 12 часов: 76.70% (поездов без локомотива - 1089)\n",
      "Процент подвязки поездов и локомотивов на горизонте в 24 часов: 64.61% (поездов без локомотива - 1654)\n",
      "Процент подвязки поездов и локомотивов на горизонте в 48 часов: 50.15% (поездов без локомотива - 2330)\n"
     ]
    }
   ],
   "source": [
    "def count_assign_percent(horizon):\n",
    "    mask = (train_plan.time_start < current_time + horizon)\n",
    "    bad_trains = train_plan.loc[mask & (train_plan.loco.isnull())]\n",
    "    bad_trains_n = bad_trains.drop_duplicates('train').train.count()\n",
    "    good_percent = 100 * (1 - bad_trains_n / total_trains_n)        \n",
    "    return 'Процент подвязки поездов и локомотивов на горизонте в %2.d часов: %.2f%% (поездов без локомотива - %d)'\\\n",
    "         % (horizon / 3600, good_percent, bad_trains_n)\n",
    "\n",
    "train_plan['train_type'] = train_plan.train.apply(lambda x: int(str(x)[0]))\n",
    "total_trains_n = train_plan[train_plan.train_type.isin([2, 9])].drop_duplicates('train').train.count()\n",
    "add_header('Вычисление процента подвязки поездов и локомотивов', p=False, h=2)\n",
    "add_line(count_assign_percent(6 * 3600))\n",
    "add_line(count_assign_percent(12 * 3600))\n",
    "add_line(count_assign_percent(24 * 3600))\n",
    "add_line(count_assign_percent(48 * 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>st_from_name</th>\n",
       "      <th>st_to_name</th>\n",
       "      <th>time_start_norm</th>\n",
       "      <th>loco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>999928799022001</td>\n",
       "      <td>ЗАОЗЕРНАЯ</td>\n",
       "      <td>УЯР</td>\n",
       "      <td>Jul 15, 18:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>999928799022003</td>\n",
       "      <td>ЗАОЗЕРНАЯ</td>\n",
       "      <td>УЯР</td>\n",
       "      <td>Jul 15, 18:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>999928799022005</td>\n",
       "      <td>ЗАОЗЕРНАЯ</td>\n",
       "      <td>УЯР</td>\n",
       "      <td>Jul 15, 18:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>999928799022007</td>\n",
       "      <td>ЗАОЗЕРНАЯ</td>\n",
       "      <td>УЯР</td>\n",
       "      <td>Jul 15, 19:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>999928814032001</td>\n",
       "      <td>МЕГЕТ</td>\n",
       "      <td>СУХОВСКАЯ</td>\n",
       "      <td>Jul 15, 18:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>200022114474</td>\n",
       "      <td>КРАСНОКАМЕНСК</td>\n",
       "      <td>УРУЛЮНГУЙ</td>\n",
       "      <td>Jul 15, 14:39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>999912393022000</td>\n",
       "      <td>ИРКУТСК-СОРТИРОВОЧНЫЙ</td>\n",
       "      <td>ГОНЧАРОВО</td>\n",
       "      <td>Jul 15, 20:15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>999912393022002</td>\n",
       "      <td>ИРКУТСК-СОРТИРОВОЧНЫЙ</td>\n",
       "      <td>ГОНЧАРОВО</td>\n",
       "      <td>Jul 15, 20:25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>999912508032001</td>\n",
       "      <td>ВАНИНО</td>\n",
       "      <td>ТОКИ</td>\n",
       "      <td>Jul 15, 19:55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>200021701871</td>\n",
       "      <td>СЕЛЬГОН</td>\n",
       "      <td>МЫЛКИ</td>\n",
       "      <td>Jul 15, 17:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>200021923764</td>\n",
       "      <td>НЕРЮНГРИ-ПАССАЖИРСКАЯ</td>\n",
       "      <td>НЕРЮНГРИ-ГРУЗОВАЯ</td>\n",
       "      <td>Jul 15, 16:40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>200021923766</td>\n",
       "      <td>ВЫСОКОГОРНАЯ</td>\n",
       "      <td>БЛОКПОСТ 197 КМ</td>\n",
       "      <td>Jul 15, 16:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>200022038309</td>\n",
       "      <td>ИЗВЕСТКОВАЯ</td>\n",
       "      <td>КУЛЬДУР</td>\n",
       "      <td>Jul 15, 13:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>999928805012001</td>\n",
       "      <td>ЧЕРЕМХОВО</td>\n",
       "      <td>ЗАЛАРИ</td>\n",
       "      <td>Jul 15, 18:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>999928813022000</td>\n",
       "      <td>МЕГЕТ</td>\n",
       "      <td>БАТАРЕЙНАЯ</td>\n",
       "      <td>Jul 15, 18:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>999912377032001</td>\n",
       "      <td>КРАСНОЯРСК-ВОСТОЧНЫЙ</td>\n",
       "      <td>КРАСНОЯРСК-СЕВЕРНЫЙ</td>\n",
       "      <td>Jul 15, 18:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>999912377032003</td>\n",
       "      <td>КРАСНОЯРСК-ВОСТОЧНЫЙ</td>\n",
       "      <td>КРАСНОЯРСК-СЕВЕРНЫЙ</td>\n",
       "      <td>Jul 15, 19:10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>200021701722</td>\n",
       "      <td>МИНУСИНСК</td>\n",
       "      <td>ПОДСИНИЙ</td>\n",
       "      <td>Jul 15, 19:25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>200021587740</td>\n",
       "      <td>ТЫНДА</td>\n",
       "      <td>КУВЫКТА</td>\n",
       "      <td>Jul 14, 23:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>210217812304</td>\n",
       "      <td>СМОЛЯНИНОВО</td>\n",
       "      <td>НОВОНЕЖИНО</td>\n",
       "      <td>Jul 15, 18:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>999928904022000</td>\n",
       "      <td>КИРЕНГА</td>\n",
       "      <td>КУНЕРМА</td>\n",
       "      <td>Jul 15, 19:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>200021517346</td>\n",
       "      <td>УРУША</td>\n",
       "      <td>ЕРОФЕЙ ПАВЛОВИЧ</td>\n",
       "      <td>Jul 15, 19:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>210219557487</td>\n",
       "      <td>МАГДАГАЧИ</td>\n",
       "      <td>УШУМУН</td>\n",
       "      <td>Jul 15, 18:25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>200022002016</td>\n",
       "      <td>КРАСНОЯРСК-ВОСТОЧНЫЙ</td>\n",
       "      <td>КРАСНОЯРСК-СЕВЕРНЫЙ</td>\n",
       "      <td>Jul 15, 16:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>200021958280</td>\n",
       "      <td>ХАБАРОВСК II</td>\n",
       "      <td>ХАБАРОВСК I</td>\n",
       "      <td>Jul 15, 16:55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109859</th>\n",
       "      <td>210209913533</td>\n",
       "      <td>СОЛЛУ</td>\n",
       "      <td>КУЗНЕЦОВСКИЙ</td>\n",
       "      <td>Jul 15, 15:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109867</th>\n",
       "      <td>200021920003</td>\n",
       "      <td>БЕСТУЖЕВО</td>\n",
       "      <td>ДИПКУН</td>\n",
       "      <td>Jul 15, 18:25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109905</th>\n",
       "      <td>200020087140</td>\n",
       "      <td>КАРЫМСКАЯ</td>\n",
       "      <td>ТАРСКАЯ</td>\n",
       "      <td>Jul 15, 15:10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110549</th>\n",
       "      <td>200208431772</td>\n",
       "      <td>КРУГЛИКОВО</td>\n",
       "      <td>ХАБАРОВСК II</td>\n",
       "      <td>Jul 15, 05:40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110975</th>\n",
       "      <td>210217919475</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>Jul 15, 15:41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111252</th>\n",
       "      <td>200021904779</td>\n",
       "      <td>ИЛАНСКАЯ</td>\n",
       "      <td>ЗАОЗЕРНАЯ</td>\n",
       "      <td>Jul 15, 17:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111391</th>\n",
       "      <td>200021371997</td>\n",
       "      <td>ИЛАНСКАЯ</td>\n",
       "      <td>РЕШОТЫ</td>\n",
       "      <td>Jul 15, 17:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111549</th>\n",
       "      <td>999912387032000</td>\n",
       "      <td>ТАЙШЕТ</td>\n",
       "      <td>ТОРЕЯ</td>\n",
       "      <td>Jul 15, 19:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111561</th>\n",
       "      <td>999912387032002</td>\n",
       "      <td>ТАЙШЕТ</td>\n",
       "      <td>ТОРЕЯ</td>\n",
       "      <td>Jul 15, 20:10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111571</th>\n",
       "      <td>200022013335</td>\n",
       "      <td>СИБИРЦЕВО</td>\n",
       "      <td>ДУБИНИНСКИЙ</td>\n",
       "      <td>Jul 15, 15:40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111573</th>\n",
       "      <td>999912387032004</td>\n",
       "      <td>ТАЙШЕТ</td>\n",
       "      <td>ТОРЕЯ</td>\n",
       "      <td>Jul 15, 20:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112003</th>\n",
       "      <td>200021893022</td>\n",
       "      <td>КРАСНОЯРСК-ВОСТОЧНЫЙ</td>\n",
       "      <td>ЗЫКОВО</td>\n",
       "      <td>Jul 15, 18:15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112727</th>\n",
       "      <td>999928877022015</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 17:55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112773</th>\n",
       "      <td>999928877022013</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 17:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112883</th>\n",
       "      <td>999928877022011</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 17:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112929</th>\n",
       "      <td>999928877022009</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 17:40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113039</th>\n",
       "      <td>999928877022007</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 17:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113085</th>\n",
       "      <td>999928877022005</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 17:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113195</th>\n",
       "      <td>999928877022003</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 17:25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113241</th>\n",
       "      <td>999928877022001</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 17:21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113438</th>\n",
       "      <td>9999331112001</td>\n",
       "      <td>КРАСНОЯРСК-ВОСТОЧНЫЙ</td>\n",
       "      <td>КРАСНОЯРСК-СЕВЕРНЫЙ</td>\n",
       "      <td>Jul 15, 19:55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113466</th>\n",
       "      <td>200021943970</td>\n",
       "      <td>АЧИНСК II</td>\n",
       "      <td>АЧИНСК I</td>\n",
       "      <td>Jul 15, 17:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113549</th>\n",
       "      <td>210218966139</td>\n",
       "      <td>РЕШОТЫ</td>\n",
       "      <td>ИЛАНСКАЯ</td>\n",
       "      <td>Jul 15, 16:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113571</th>\n",
       "      <td>999928877022017</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 18:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113668</th>\n",
       "      <td>999928877022019</td>\n",
       "      <td>НАХОДКА-ВОСТОЧНАЯ</td>\n",
       "      <td>ХМЫЛОВСКИЙ</td>\n",
       "      <td>Jul 15, 18:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train           st_from_name           st_to_name  \\\n",
       "7       999928799022001              ЗАОЗЕРНАЯ                  УЯР   \n",
       "21      999928799022003              ЗАОЗЕРНАЯ                  УЯР   \n",
       "29      999928799022005              ЗАОЗЕРНАЯ                  УЯР   \n",
       "87      999928799022007              ЗАОЗЕРНАЯ                  УЯР   \n",
       "321     999928814032001                  МЕГЕТ            СУХОВСКАЯ   \n",
       "329        200022114474          КРАСНОКАМЕНСК            УРУЛЮНГУЙ   \n",
       "463     999912393022000  ИРКУТСК-СОРТИРОВОЧНЫЙ            ГОНЧАРОВО   \n",
       "472     999912393022002  ИРКУТСК-СОРТИРОВОЧНЫЙ            ГОНЧАРОВО   \n",
       "536     999912508032001                 ВАНИНО                 ТОКИ   \n",
       "546        200021701871                СЕЛЬГОН                МЫЛКИ   \n",
       "806        200021923764  НЕРЮНГРИ-ПАССАЖИРСКАЯ    НЕРЮНГРИ-ГРУЗОВАЯ   \n",
       "807        200021923766           ВЫСОКОГОРНАЯ      БЛОКПОСТ 197 КМ   \n",
       "969        200022038309            ИЗВЕСТКОВАЯ              КУЛЬДУР   \n",
       "970     999928805012001              ЧЕРЕМХОВО               ЗАЛАРИ   \n",
       "976     999928813022000                  МЕГЕТ           БАТАРЕЙНАЯ   \n",
       "1043    999912377032001   КРАСНОЯРСК-ВОСТОЧНЫЙ  КРАСНОЯРСК-СЕВЕРНЫЙ   \n",
       "1055    999912377032003   КРАСНОЯРСК-ВОСТОЧНЫЙ  КРАСНОЯРСК-СЕВЕРНЫЙ   \n",
       "1139       200021701722              МИНУСИНСК             ПОДСИНИЙ   \n",
       "1189       200021587740                  ТЫНДА              КУВЫКТА   \n",
       "1307       210217812304            СМОЛЯНИНОВО           НОВОНЕЖИНО   \n",
       "1314    999928904022000                КИРЕНГА              КУНЕРМА   \n",
       "1528       200021517346                  УРУША      ЕРОФЕЙ ПАВЛОВИЧ   \n",
       "1674       210219557487              МАГДАГАЧИ               УШУМУН   \n",
       "1740       200022002016   КРАСНОЯРСК-ВОСТОЧНЫЙ  КРАСНОЯРСК-СЕВЕРНЫЙ   \n",
       "1861       200021958280           ХАБАРОВСК II          ХАБАРОВСК I   \n",
       "...                 ...                    ...                  ...   \n",
       "109859     210209913533                  СОЛЛУ         КУЗНЕЦОВСКИЙ   \n",
       "109867     200021920003              БЕСТУЖЕВО               ДИПКУН   \n",
       "109905     200020087140              КАРЫМСКАЯ              ТАРСКАЯ   \n",
       "110549     200208431772             КРУГЛИКОВО         ХАБАРОВСК II   \n",
       "110975     210217919475             ХМЫЛОВСКИЙ    НАХОДКА-ВОСТОЧНАЯ   \n",
       "111252     200021904779               ИЛАНСКАЯ            ЗАОЗЕРНАЯ   \n",
       "111391     200021371997               ИЛАНСКАЯ               РЕШОТЫ   \n",
       "111549  999912387032000                 ТАЙШЕТ                ТОРЕЯ   \n",
       "111561  999912387032002                 ТАЙШЕТ                ТОРЕЯ   \n",
       "111571     200022013335              СИБИРЦЕВО          ДУБИНИНСКИЙ   \n",
       "111573  999912387032004                 ТАЙШЕТ                ТОРЕЯ   \n",
       "112003     200021893022   КРАСНОЯРСК-ВОСТОЧНЫЙ               ЗЫКОВО   \n",
       "112727  999928877022015      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "112773  999928877022013      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "112883  999928877022011      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "112929  999928877022009      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "113039  999928877022007      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "113085  999928877022005      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "113195  999928877022003      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "113241  999928877022001      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "113438    9999331112001   КРАСНОЯРСК-ВОСТОЧНЫЙ  КРАСНОЯРСК-СЕВЕРНЫЙ   \n",
       "113466     200021943970              АЧИНСК II             АЧИНСК I   \n",
       "113549     210218966139                 РЕШОТЫ             ИЛАНСКАЯ   \n",
       "113571  999928877022017      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "113668  999928877022019      НАХОДКА-ВОСТОЧНАЯ           ХМЫЛОВСКИЙ   \n",
       "\n",
       "       time_start_norm loco  \n",
       "7        Jul 15, 18:35  NaN  \n",
       "21       Jul 15, 18:45  NaN  \n",
       "29       Jul 15, 18:50  NaN  \n",
       "87       Jul 15, 19:05  NaN  \n",
       "321      Jul 15, 18:30  NaN  \n",
       "329      Jul 15, 14:39  NaN  \n",
       "463      Jul 15, 20:15  NaN  \n",
       "472      Jul 15, 20:25  NaN  \n",
       "536      Jul 15, 19:55  NaN  \n",
       "546      Jul 15, 17:20  NaN  \n",
       "806      Jul 15, 16:40  NaN  \n",
       "807      Jul 15, 16:20  NaN  \n",
       "969      Jul 15, 13:23  NaN  \n",
       "970      Jul 15, 18:45  NaN  \n",
       "976      Jul 15, 18:30  NaN  \n",
       "1043     Jul 15, 18:50  NaN  \n",
       "1055     Jul 15, 19:10  NaN  \n",
       "1139     Jul 15, 19:25  NaN  \n",
       "1189     Jul 14, 23:35  NaN  \n",
       "1307     Jul 15, 18:05  NaN  \n",
       "1314     Jul 15, 19:20  NaN  \n",
       "1528     Jul 15, 19:50  NaN  \n",
       "1674     Jul 15, 18:25  NaN  \n",
       "1740     Jul 15, 16:45  NaN  \n",
       "1861     Jul 15, 16:55  NaN  \n",
       "...                ...  ...  \n",
       "109859   Jul 15, 15:45  NaN  \n",
       "109867   Jul 15, 18:25  NaN  \n",
       "109905   Jul 15, 15:10  NaN  \n",
       "110549   Jul 15, 05:40  NaN  \n",
       "110975   Jul 15, 15:41  NaN  \n",
       "111252   Jul 15, 17:50  NaN  \n",
       "111391   Jul 15, 17:20  NaN  \n",
       "111549   Jul 15, 19:50  NaN  \n",
       "111561   Jul 15, 20:10  NaN  \n",
       "111571   Jul 15, 15:40  NaN  \n",
       "111573   Jul 15, 20:30  NaN  \n",
       "112003   Jul 15, 18:15  NaN  \n",
       "112727   Jul 15, 17:55  NaN  \n",
       "112773   Jul 15, 17:50  NaN  \n",
       "112883   Jul 15, 17:45  NaN  \n",
       "112929   Jul 15, 17:40  NaN  \n",
       "113039   Jul 15, 17:35  NaN  \n",
       "113085   Jul 15, 17:30  NaN  \n",
       "113195   Jul 15, 17:25  NaN  \n",
       "113241   Jul 15, 17:21  NaN  \n",
       "113438   Jul 15, 19:55  NaN  \n",
       "113466   Jul 15, 17:35  NaN  \n",
       "113549   Jul 15, 16:00  NaN  \n",
       "113571   Jul 15, 18:00  NaN  \n",
       "113668   Jul 15, 18:05  NaN  \n",
       "\n",
       "[738 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['train', 'st_from_name', 'st_to_name', 'time_start_norm', 'loco']\n",
    "train_plan['train_type'] = train_plan.train.apply(lambda x: int(str(x)[0]))\n",
    "a = train_plan[(train_plan.time_start < current_time + 6 * 3600)\n",
    "           & (train_plan.loco.isnull())].drop_duplicates('train')\n",
    "a.train_type.value_counts()\n",
    "a[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Направления, на которые не удалось подвязать локомотив под поезд (первые 10 по количеству поездов):\n",
      "st_from_name           st_to_name         \n",
      "ХАБАРОВСК II           ХАБАРОВСК I            74\n",
      "КАРЫМСКАЯ              ТАРСКАЯ                70\n",
      "                       ЧИТА I                 59\n",
      "МАРИИНСК               БОГОТОЛ                51\n",
      "ХАБАРОВСК II           КРУГЛИКОВО             39\n",
      "КРАСНОЯРСК-ВОСТОЧНЫЙ   КРАСНОЯРСК-СЕВЕРНЫЙ    36\n",
      "ТАЙШЕТ                 ЮРТЫ                   32\n",
      "НАХОДКА-ВОСТОЧНАЯ      ХМЫЛОВСКИЙ             31\n",
      "ИРКУТСК-СОРТИРОВОЧНЫЙ  ГОНЧАРОВО              30\n",
      "ВЫСОКОГОРНАЯ           БЛОКПОСТ 197 КМ        27\n"
     ]
    }
   ],
   "source": [
    "a = train_plan[(train_plan.time_start < current_time + 24 * 3600) & (train_plan.loco.isnull())]\\\n",
    "    .drop_duplicates('train')\\\n",
    "    .groupby(['st_from_name', 'st_to_name']).train\\\n",
    "    .count().sort_values(ascending=False)\n",
    "add_header('Направления, на которые не удалось подвязать локомотив под поезд (первые 10 по количеству поездов):')\n",
    "add_line(a.head(10))\n",
    "a.to_csv('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поезда со станции КОМСОМОЛЬСК-НА-АМУРЕ-СОРТИРОВОЧНЫЙ, к которым не были подвязаны локомотивы\n",
      "        train  weight              st_from_name            st_to_name              st_dest_name time_start_norm loco ser_name  sections\n",
      " 210256220328      56  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                   ГУРСКОЕ   Jul 06, 05:20  NaN      NaN       NaN\n",
      " 210256388383      55  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН  СОВЕТСКАЯ ГАВАНЬ-СОРТ...   Jul 06, 05:31  NaN      NaN       NaN\n",
      " 210255960426    3583  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ                   КАМЫШТА   Jul 06, 07:35  NaN      NaN       NaN\n",
      " 210256428563    4525  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ              ХАБАРОВСК II   Jul 06, 07:35  NaN      NaN       NaN\n",
      " 210256382124    1395  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ                    ТАЙШЕТ   Jul 06, 07:35  NaN      NaN       NaN\n",
      " 210256436266    1870  КОМСОМОЛЬСК-НА-АМУРЕ-...  КОМСОМОЛЬСК-НА-АМУРЕ               НОВЫЙ УРГАЛ   Jul 06, 07:35  NaN      NaN       NaN\n",
      " 210256458309    1762  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ                    ТАЙШЕТ   Jul 06, 07:40  NaN      NaN       NaN\n",
      " 210256067719    1701  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ                       УЯР   Jul 06, 08:04  NaN      NaN       NaN\n",
      " 210256384216    4669  КОМСОМОЛЬСК-НА-АМУРЕ-...                 МЫЛКИ              ХАБАРОВСК II   Jul 06, 08:04  NaN      NaN       NaN\n",
      " 200200642585    5598  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 14:38  NaN      NaN       NaN\n",
      " 210252666540    5524  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 14:38  NaN      NaN       NaN\n",
      " 210253299383    5523  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 15:25  NaN      NaN       NaN\n",
      " 210250148719    6239  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 17:09  NaN      NaN       NaN\n",
      " 210255528673    6246  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 17:09  NaN      NaN       NaN\n",
      " 210255952264   11468  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 17:24  NaN      NaN       NaN\n",
      " 210253485165    6309  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 22:05  NaN      NaN       NaN\n",
      " 210253427872    6301  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 22:27  NaN      NaN       NaN\n",
      " 210252085037    5592  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 22:37  NaN      NaN       NaN\n",
      " 210254700107    5570  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 22:52  NaN      NaN       NaN\n",
      " 210255943332    5553  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 22:52  NaN      NaN       NaN\n",
      " 210250153384    5617  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 22:52  NaN      NaN       NaN\n",
      " 210256151970   11326  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 22:52  NaN      NaN       NaN\n",
      " 210251596402    5589  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 22:52  NaN      NaN       NaN\n",
      " 200259979839    5557  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 06, 23:37  NaN      NaN       NaN\n",
      " 210255696235    3934  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 07, 04:07  NaN      NaN       NaN\n",
      " 210252176649    5581  КОМСОМОЛЬСК-НА-АМУРЕ-...               СЕЛИХИН                    ВАНИНО   Jul 07, 07:21  NaN      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "(st_name, st2_name) = a.index[0]\n",
    "train_cols = ['train', 'weight', 'st_from_name', 'st_to_name', 'st_dest_name', 'time_start_norm', 'time_end_norm', 'loco', 'team']\n",
    "cols = ['train', 'weight', 'st_from_name', 'st_to_name', 'st_dest_name', 'time_start_norm', 'loco', 'ser_name', 'sections']\n",
    "routes = pd.read_csv(FOLDER + 'routes.csv', converters={'st_from':str, 'st_to':str, 'train':str})\n",
    "add_info(routes)\n",
    "routes['end'] = routes.train != routes.train.shift(-1)\n",
    "train_plan['st_dest_name'] = train_plan.train.map(routes[routes.end].set_index('train').st_to_name)\n",
    "loco_info['ser_name'] = loco_info.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "train_plan['ser_name'] = train_plan.loco.map(loco_info.set_index('loco').ser_name)\n",
    "train_plan['sections'] = train_plan.loco.map(loco_info.set_index('loco').sections)\n",
    "a = train_plan[(train_plan.time_start < current_time + 24 * 3600) \n",
    "               & (train_plan.loco.isnull())\n",
    "               & (train_plan.st_dest_name.isnull() == False)\n",
    "               & (train_plan.st_from_name == st_name)].drop_duplicates('train')\n",
    "add_header('Поезда со станции %s, к которым не были подвязаны локомотивы' % st_name)\n",
    "add_line(a.sort_values('time_start')[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='regions'></a>\n",
    "## Проверка наличия локомотивов только на своих тяговых плечах [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Проверка наличия локомотивов только на своих тяговых плечах', h=2, p=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='correct_reg_ser'></a>\n",
    "### Проверка назначения тяговых плеч локомотивам в соответствии с сериями [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка назначения тяговых плеч локомотивам в соответствии с сериями', h=3, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func(df, stations, st):    \n",
    "    a = links.loc[(links.st_from_name.isin(st))].st_from_name.value_counts()\n",
    "    b = links.loc[(links.st_from_name.isin(st)) & (links.st_to_name.isin(st))].st_from_name.value_counts()\n",
    "    c = a.to_frame().join(b, rsuffix='_reg')\n",
    "    c['delta'] = c.st_from_name - c.st_from_name_reg    \n",
    "    d = c.join(stations[['name', 'norm_time']].drop_duplicates().set_index('name'), how='right')\n",
    "    e = d.loc[((d.delta > 0) | (d.st_from_name == 1))]\n",
    "    return sorted(e.index.values)\n",
    "\n",
    "add_info(links)\n",
    "loco_info['regions_eval'] = loco_info.regions.apply(literal_eval)\n",
    "stations_regs = stations.groupby('station').loco_region.apply(lambda x: x.values)\n",
    "loco_info['ser_name'] = loco_info.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "reg_st = stations.groupby('loco_region')['name'].unique().to_frame()\n",
    "reg_st['short_name'] = reg_st['name'].apply(lambda x: func(links, stations, x))\n",
    "reg_st.columns = ['stations', 'reg_name']\n",
    "reg_borders = pd.read_csv(FOLDER + 'mandatory/loco_reg_borders.csv', encoding='utf-8-sig')\n",
    "bord = reg_borders.station.values\n",
    "reg_st['short_name'] = reg_st.reg_name.apply(lambda x: np.intersect1d(x, bord) if len(np.intersect1d(x, bord)) > 1 else [])\n",
    "big_borders = ['МАРИИНСК', 'БОРЗЯ', 'КАРЫМСКАЯ', 'ХАБАРОВСК II', 'МЕЖДУРЕЧЕНСК', 'ТАКСИМО', 'КОМСОМОЛЬСК-НА-АМУРЕ']\n",
    "reg_st['short_name'] = reg_st.short_name.apply(lambda x: np.intersect1d(x, big_borders) if len(x) > 2 else x)\n",
    "pd.set_option('display.max_colwidth', 60)\n",
    "#print(reg_st[['short_name']].to_string())\n",
    "#reg_st.ix[2002119307].reg_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           loco      series                       regions       depot  \\\n",
      "0  200200086862  2001889135                ['2002119299']  2000035162   \n",
      "1  200200138964  2001889412  ['2002119317', '2002119303']  2000036300   \n",
      "2  200200107482  2001889140                ['2002119299']  2000036604   \n",
      "3  200200029176  2001889231                ['2002119310']  2000039048   \n",
      "4  200200103583  2001889258                ['2002119303']  2000036208   \n",
      "\n",
      "   sections  ltype  number    oper   oper_time                 oper_location  \\\n",
      "0         2    NaN    1746  depart  1467765180  ['2000037674', '2000037726']   \n",
      "1         2    NaN      51  depart  1467772080  ['2000036300', '2000036316']   \n",
      "2         2    NaN     231  depart  1467767040  ['2000037792', '2000037776']   \n",
      "3         1    NaN    5707  depart  1467768300  ['2000039048', '2000039050']   \n",
      "4         3    NaN    2387  depart  1467770100  ['2000036228', '2000036274']   \n",
      "\n",
      "      ...         dts     tts  st_from_name   st_to_name  oper_location_name  \\\n",
      "0     ...         134  144000        КАДАЛА       ЛЕСНАЯ                   0   \n",
      "1     ...      999999  270000         ТЫНДА        ШТУРМ                   0   \n",
      "2     ...        2707  219600     ОЛОВЯННАЯ     МОГОЙТУЙ                   0   \n",
      "3     ...      999999   72000     УССУРИЙСК  БАРАНОВСКИЙ                   0   \n",
      "4     ...      999999  252000       ТАКСИМО       КУАНДА                   0   \n",
      "\n",
      "                  loc_name ser_name              regions_eval    ser_desc  \\\n",
      "0          КАДАЛА - ЛЕСНАЯ    ВЛ80Р              [2002119299]    Грузовое   \n",
      "1            ТЫНДА - ШТУРМ   2ТЭ25А  [2002119317, 2002119303]    Грузовое   \n",
      "2     ОЛОВЯННАЯ - МОГОЙТУЙ     ВЛ85              [2002119299]    Грузовое   \n",
      "3  УССУРИЙСК - БАРАНОВСКИЙ     ТЭМ2              [2002119310]  Маневровое   \n",
      "4         ТАКСИМО - КУАНДА  2ТЭ10МК              [2002119303]    Грузовое   \n",
      "\n",
      "     ser_type  \n",
      "0  Электровоз  \n",
      "1    Тепловоз  \n",
      "2  Электровоз  \n",
      "3    Тепловоз  \n",
      "4    Тепловоз  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Empty DataFrame\n",
      "Columns: [ser_name]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [ser_type]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [ser_name, ser_type]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot join with no level specified and no overlapping names",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2a4250f9e1be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloco_info_regs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloco_info_regs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mltype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'region'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reg_name_str'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m#print('Total locos:', loco_info.loco.drop_duplicates().count())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#print('Freight locos:', loco_info.loc[loco_info.ser_desc.isin(['Грузовое', 'Грузопассажирское'])].loco.drop_duplicates().count())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\oracle\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4276\u001b[0m         \u001b[1;31m# For SparseDataFrame's benefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4277\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[1;32m-> 4278\u001b[1;33m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[0;32m   4279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4280\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32mC:\\Users\\oracle\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4290\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[0;32m   4291\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4292\u001b[1;33m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[0;32m   4293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\oracle\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m     33\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                          copy=copy, indicator=indicator)\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m'\\nleft : DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\oracle\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\oracle\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_index\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                 \u001b[0mleft_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_ax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_index\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'left'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\oracle\\Anaconda3\\lib\\site-packages\\pandas\\core\\index.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, how, level, return_indexers)\u001b[0m\n\u001b[0;32m   2231\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2232\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2233\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_join_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_indexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2235\u001b[0m         \u001b[1;31m# join on the level\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\oracle\\Anaconda3\\lib\\site-packages\\pandas\\core\\index.py\u001b[0m in \u001b[0;36m_join_multi\u001b[1;34m(self, other, how, return_indexers)\u001b[0m\n\u001b[0;32m   2324\u001b[0m         \u001b[1;31m# need at least 1 in common, but not more than 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverlap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2326\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot join with no level specified and no overlapping names\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverlap\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2328\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"merging with more than one level overlap on a multi-index is not implemented\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot join with no level specified and no overlapping names"
     ]
    }
   ],
   "source": [
    "def save_to_excel(df, filename=FOLDER + 'reg_ser.xlsx'):    \n",
    "    df.to_excel(filename)\n",
    "    print('Excel file %s created' % filename)\n",
    "\n",
    "loco_info['ser_name'] = loco_info.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "loco_info['ser_desc'] = loco_info.series.map(loco_series.set_index('ser_id').ser_desc)\n",
    "loco_info['ser_type'] = loco_info.series.map(loco_series.set_index('ser_id').ser_type)\n",
    "loco_info_regs['number'] = loco_info.loco.map(loco_info.drop_duplicates('loco').set_index('loco').number)\n",
    "loco_info_regs['reg_name'] = loco_info_regs.region.map(reg_st.short_name)\n",
    "loco_info_regs['ser_name'] = loco_info_regs.loco.map(loco_info.set_index('loco').ser_name)\n",
    "loco_info_regs['ser_type'] = loco_info_regs.loco.map(loco_info.set_index('loco').ser_type)\n",
    "loco_info_regs['reg_name_str'] = loco_info_regs.reg_name.apply(str)\n",
    "loco_info_regs['ltype'] = loco_info_regs.loco.map(loco_info.set_index('loco').ltype)\n",
    "loco_info_regs.sort_values(['ser_name', 'reg_name_str'])[['loco', 'ser_name', 'reg_name']].set_index('loco')\\\n",
    "                .to_excel(FOLDER + 'ans.xlsx')\n",
    "a = loco_info_regs.groupby('reg_name_str').ser_name.unique()\n",
    "loco_info_regs['ser_desc'] = loco_info_regs.ser_name.map(loco_series.drop_duplicates('ser_name').set_index('ser_name').ser_desc)\n",
    "a = loco_info_regs.loc[(loco_info_regs.ltype == 1) & (loco_info_regs.ser_desc.isin(['Грузовое', 'Грузопассажирское']))]\\\n",
    "            .groupby(['region', 'reg_name_str']).ser_name.unique().to_frame()\n",
    "b = loco_info_regs.loc[(loco_info_regs.ltype == 1) & (loco_info_regs.ser_desc.isin(['Грузовое', 'Грузопассажирское']))]\\\n",
    "            .groupby(['region', 'reg_name_str']).ser_type.unique().to_frame()\n",
    "c = a.join(b)\n",
    "d = c.join(loco_info_regs.loc[loco_info_regs.ltype == 1].groupby(['region', 'reg_name_str']).loco.count())\n",
    "#print('Total locos:', loco_info.loco.drop_duplicates().count())\n",
    "#print('Freight locos:', loco_info.loc[loco_info.ser_desc.isin(['Грузовое', 'Грузопассажирское'])].loco.drop_duplicates().count())\n",
    "#print('Locos of type = 1:', loco_info[loco_info.ltype == 1].loco.drop_duplicates().count())\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "add_line(d.reset_index().sort_values('loco', ascending=False))\n",
    "#save_to_excel(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_ser = d.reset_index()[['region', 'ser_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='correct_reg_plan'></a>\n",
    "### Проверка выезда локомотивов за пределы своих тяговых плеч [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка выезда локомотивов за пределы своих тяговых плеч', h=3, p=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавляем тяговое плечо в таблицу линков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations['regions'] = stations.station.map(stations.groupby('station').loco_region.unique())\n",
    "stations_unique = stations.drop_duplicates('station').set_index('station')\n",
    "links['st_from_regs'] = links.st_from.map(stations_unique.regions)\n",
    "links['st_to_regs'] = links.st_to.map(stations_unique.regions)\n",
    "links['regs'] = links.st_from_regs.combine(links.st_to_regs, np.intersect1d)\n",
    "links['link'] = list(zip(links.st_from, links.st_to))\n",
    "regs = reg_st.reset_index()\n",
    "links['reg_name'] = links.regs.apply(lambda x: regs[regs.loco_region.isin(x)].short_name.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавляем текущее тяговое плечо в каждый участок планов по локомотивам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['curr_reg'] = loco_plan.link.map(links.drop_duplicates('link').set_index('link').regs)\n",
    "loco_plan['curr_reg_name'] = loco_plan.link.map(links.drop_duplicates('link').set_index('link').reg_name)\n",
    "loco_plan['regions'] = loco_plan.loco.map(loco_info.set_index('loco').regions_eval)\n",
    "loco_info['reg_names'] = loco_info.regions_eval.apply(lambda x: \\\n",
    "                                                regs[regs.loco_region.isin([int(i) for i in x if i != ''])].short_name.values)\n",
    "loco_plan['reg_names'] = loco_plan.loco.map(loco_info.set_index('loco').reg_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_info[loco_info.regions.apply(lambda x: len(x) < 5)][['loco', 'number', 'regions', 'regions_eval']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисляем, есть у локомотива текущее тяговое плечо в списке разрешенных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['ok_reg'] = loco_plan.curr_reg.combine(loco_plan.regions, np.intersect1d).apply(len) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисляем тяговое плечо на исходном местоположении локомотива"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_current_region(row):\n",
    "    if row.st_from == '-1':        \n",
    "        a = links[links.st_from == row.oper_location].regs.values\n",
    "    else:\n",
    "        a = links[(links.st_from == row.st_from) & (links.st_to == row.st_to)].regs.values\n",
    "    return list(np.concatenate(a) if len(a) > 0 else [])\n",
    "        \n",
    "loco_info['location'] = list(zip(loco_info.oper_location, loco_info.st_from, loco_info.st_to))\n",
    "loco_info['curr_reg'] = loco_info.apply(lambda row: get_current_region(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисляем, находится ли локомотив на своем тяговом плече на начало планирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loco_info['ok_reg'] = loco_info.curr_reg.combine(loco_info.regions_eval, np.intersect1d).apply(len) > 0\n",
    "loco_plan['info_ok_reg'] = loco_plan.loco.map(loco_info.drop_duplicates('loco').set_index('loco').ok_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Составляем список локомотивов, выезжающих за пределы своих ТП в процессе планирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_out_of_regs = loco_plan[(loco_plan.curr_reg_name.isnull() == False) \n",
    "                             & (loco_plan.ok_reg == False) & (loco_plan.info_ok_reg == True)]\n",
    "cols = ['loco', 'ser_name', 'reg_names', 'st_from_name', 'st_to_name', 'train', 'state', 'loc_name']\n",
    "add_line('Всего %d локомотивов, выезжающих за пределы своих тяговых плеч в процессе планирования:' \n",
    "           % loco_out_of_regs.loco.drop_duplicates().count())\n",
    "add_line('- %d следуют резервом;' % (loco_out_of_regs[loco_out_of_regs.state == 0].loco.drop_duplicates().count()))\n",
    "add_line('- %d с поездами.' % (loco_out_of_regs[loco_out_of_regs.state == 1].loco.drop_duplicates().count()))\n",
    "\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "states = sorted(loco_out_of_regs.state.unique())\n",
    "for s in states:\n",
    "    add_header('\\nПримеры локомотивов в состоянии %d за пределами своих тяговых плеч:' % s)\n",
    "    add_line(loco_out_of_regs[loco_out_of_regs.state == s].drop_duplicates('loco')[cols].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bad_regs_loco_info'></a>\n",
    "### Локомотивы на чужих тяговых плечах на начало планирования [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Локомотивы на чужих тяговых плечах на начало планирования', h=3, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['loco', 'ser_name', 'loc_name', 'reg_names']\n",
    "bad_regs_loco_info = loco_info[(loco_info.ltype == 1) & (loco_info.ok_reg == False)]\n",
    "add_header('Всего %d локомотивов на чужих тяговых плечах на начало планирования' % bad_regs_loco_info.loco.count())\n",
    "add_header('\\nРаспределение по сериям (показаны первые 5):')\n",
    "add_line(bad_regs_loco_info[cols].ser_name.value_counts().head())\n",
    "add_header('\\nРаспределение по тяговым плечам локомотивов (показаны первые 5):')\n",
    "add_line(bad_regs_loco_info[cols].reg_names.value_counts().head())\n",
    "add_header('\\nПримеры локомотивов:')\n",
    "add_line(bad_regs_loco_info[cols].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='st_to2'></a>\n",
    "## Проверка пунктов проведения ТО-2 [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка планирования ТО-2', h=2, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to2_type = 2001889869\n",
    "service = pd.read_csv(FOLDER + 'service.csv', converters={'station':str})\n",
    "service['st_name'] = service.station.map(st_names.name)\n",
    "service['dur_h'] = np.round((service.duration / 3600), 2)\n",
    "to2 = service[service.serv_type == to2_type].drop_duplicates()\n",
    "to2_dur_median = to2.dur_h.median()\n",
    "add_header('Пункты проведения ТО-2 во входных данных:')\n",
    "add_line(to2[['st_name', 'dur_h']].sort_values('st_name'))\n",
    "add_line('Медианное время проведения ТО-2: %.2f часа' % to2_dur_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['tt'] = loco_plan.time_end - loco_plan.time_start\n",
    "plan_to = loco_plan[loco_plan.state == 4][['loco', 'st_from_name', 'st_to_name', 'time_start_norm', 'time_end_norm', 'tt']]\n",
    "add_header('Проведение ТО запланировано на %d разных станциях (показаны первые 10):' \n",
    "           % plan_to.st_from_name.drop_duplicates().count())\n",
    "stats_plan_to = plan_to.st_from_name.value_counts().to_frame().join(plan_to.groupby('st_from_name').tt.median())\n",
    "stats_plan_to.columns = ['num', 'time']\n",
    "stats_plan_to['time_h'] = np.round((stats_plan_to.time / 3600), 2)\n",
    "add_line(stats_plan_to[['num', 'time_h']].reset_index().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='tonnage'></a>\n",
    "## Проверка подвязки на соответствие весовым нормам [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Проверка подвязки на соответствие весовым нормам', h=2, p=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Маска времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ниже надо раскомментировать соответствующую строчку для нужного анализа\n",
    "\n",
    "def time_mask(df):\n",
    "    # Маска для анализа поездов, которые запланировал планировщик (отправленных после начала планирования)\n",
    "    return df.time_start >= current_time\n",
    "    # Маска для анализа позедов, отправленных до начала планирования (следующих по факту)\n",
    "    #time_mask = overweight.time_start < current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка соответствия результатов планирования справочнику весовых норм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['ser_name'] = loco_plan.series.map(loco_series.set_index('ser_id').ser_name)\n",
    "loco_tonnage = pd.read_csv(FOLDER + 'loco_tonnage.csv', converters={'st_from':str, 'st_to':str})\n",
    "loco_tonnage['link'] = list(zip(loco_tonnage.st_from, loco_tonnage.st_to))\n",
    "loco_tonnage['ssl'] = list(zip(loco_tonnage.series, loco_tonnage.sections, loco_tonnage.link))\n",
    "loco_plan['link'] = list(zip(loco_plan.st_from, loco_plan.st_to))\n",
    "loco_plan['link_name'] = list(zip(loco_plan.st_from_name, loco_plan.st_to_name))\n",
    "loco_plan['ssl'] = list(zip(loco_plan.series, loco_plan.sections, loco_plan.link))\n",
    "loco_plan['max_weight'] = loco_plan.ssl.map(loco_tonnage.groupby('ssl').max_weight.max().to_frame().max_weight)\n",
    "loco_plan['train_weight'] = loco_plan.train.map(train_info.drop_duplicates('train').set_index('train').weight)\n",
    "loco_plan['overweight'] = loco_plan.train_weight - loco_plan.max_weight\n",
    "cols = ['loco', 'ser_name', 'st_from_name', 'st_to_name', 'time_start_norm', 'max_weight', 'train_weight', 'overweight', 'train']\n",
    "overweight = loco_plan[(loco_plan.overweight > 0)].dropna(subset=['max_weight']).drop_duplicates(subset=['loco', 'train'])\n",
    "overweight_plan = overweight[time_mask(overweight)] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<< TIME_MASK -----------------------\n",
    "overweight_n = len(overweight_plan.index)\n",
    "add_header('Всего %d подвязок локомотивов к поезду с нарушением весовых норм (показаны первые 10):' % overweight_n)\n",
    "pd.set_option('display.max_colwidth', 15)\n",
    "add_line(overweight_plan.sort_values('overweight', ascending=False).head(10)[cols])\n",
    "\n",
    "overweight_no_joint = overweight_plan[overweight_plan.train_weight < 10000]\n",
    "add_header('\\nВсего %d подвязок локомотивов к поездам (за исключением сдвоенных) с нарушением весовых норм (показаны первые 10):' \n",
    "      % len(overweight_no_joint.index))\n",
    "add_line(overweight_no_joint.sort_values('overweight', ascending=False).head(10)[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', context='talk')\n",
    "sns.set_color_codes('dark')\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
    "sns.distplot(overweight_plan.train_weight, hist=False, color='b', \n",
    "             kde_kws={'shade':True, 'label':'Вес поезда'}, ax=ax[0])\n",
    "sns.distplot(overweight_plan.overweight, hist=False, color='g', \n",
    "             kde_kws={'shade':True, 'label':'Превышение весовой нормы'}, ax=ax[0])\n",
    "sns.distplot(overweight_no_joint.train_weight, hist=False, color='b', \n",
    "             kde_kws={'shade':True, 'label':'Вес поезда'}, ax=ax[1])\n",
    "sns.distplot(overweight_no_joint.overweight, hist=False, color='g', \n",
    "             kde_kws={'shade':True, 'label':'Превышение весовой нормы'}, ax=ax[1])\n",
    "title = 'Для всех поездов'\n",
    "title_nj = 'Без сдвоенных поезов'\n",
    "ax[0].set(title=title, xlabel='Вес поезда')\n",
    "ax[1].set(title=title_nj, xlabel='Вес поезда')\n",
    "ax[0].legend(frameon=True)\n",
    "ax[1].legend(frameon=True)\n",
    "plt.suptitle('Распределение весов поездов, для которых наблюдается нарушение весовых норм', fontsize=20)\n",
    "sns.despine()\n",
    "filename = 'weight_error.png'\n",
    "fig.savefig(REPORT_FOLDER + filename, bbox_inches='tight')\n",
    "add_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Распределение нарушений весовых норм по участкам (первые 5):')\n",
    "a = overweight_no_joint.link_name.value_counts()\n",
    "b = overweight_no_joint.groupby('link_name').overweight.median()\n",
    "overweight_links = a.to_frame().join(b)\n",
    "overweight_links.columns = ['number', 'overw_median']\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "add_line(overweight_links.reset_index().head())\n",
    "\n",
    "add_header('\\nРаспределение нарушений весовых норм по сериям локомотивов:')\n",
    "a = overweight_no_joint.ser_name.value_counts()\n",
    "b = overweight_no_joint.groupby('ser_name').overweight.median()\n",
    "overweight_ser = a.to_frame().join(b)\n",
    "overweight_ser.columns = ['number', 'overw_median']\n",
    "add_line(overweight_ser.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='change'></a>\n",
    "## Проверка смены локомотивов на станциях обязательной смены [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка смены локомотивов на станциях обязательной смены', h=2, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hor = 24 * 3600\n",
    "cols = ['train', 'st_from_name', 'st_to_name', 'time_start_norm', 'loco', 'train_start', 'loco_start']\n",
    "train_plan['train_start'] = train_plan.train != train_plan.train.shift(1)\n",
    "train_plan['loco_start'] = (train_plan.loco != train_plan.loco.shift(1)) & (train_plan.loco.isnull() == False)\n",
    "loco_changes = train_plan.loc[(train_plan.train_start == False) & (train_plan.loco_start == True) &\n",
    "              (train_plan.time_start < current_time + hor)]\n",
    "add_header('Станции смены локомотивов (показаны первые 10):')\n",
    "add_line(loco_changes.st_from_name.value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Список станций (первый столбец), на которых локомотивы меняются всегда,\n",
    "# если в машруте поезда есть любая из проверочных станций (второй столбец)\n",
    "st_list = [['КАРЫМСКАЯ',['УРУЛЬГА']], ['БОРЗЯ',['ХАРАНОР','ЗУН-ТОРЕЙ']], ['ТАКСИМО', ['КУАНДА','КАЗАНКАН']], \n",
    "           ['СКОВОРОДИНО', ['ШТУРМ']], ['ИЗВЕСТКОВАЯ', ['КУЛЬДУР']], ['ВОЛОЧАЕВКА II', ['СЕЛЬГОН']], \n",
    "           ['УССУРИЙСК', ['ПРИМОРСКАЯ', 'ГРОДЕКОВО']]]\n",
    "df_list = pd.DataFrame(st_list, columns=['st', 'other_st'])\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "add_header('Станции обязательной смены локомотивов:')\n",
    "add_line(df_list)\n",
    "a = train_plan.groupby('train').st_from_name.unique().to_frame()\n",
    "a.columns = ['route']\n",
    "train_plan['route'] = train_plan.train.map(a.route)\n",
    "# Если проверочная станция находится в маршруте поезда, значит, поезд едет в том направлении, где НАДО менять локомотив\n",
    "train_plan['check_st'] = train_plan.st_from_name.map(df_list.set_index('st').other_st)\n",
    "train_plan['in_route'] = train_plan.route.combine(train_plan.check_st, \\\n",
    "                                                  lambda x, y: not False in [st in x for st in y] if type(y) == list else False)\n",
    "\n",
    "cols = ['train', 'st_from_name', 'st_to_name', 'time_start_norm', 'loco', 'in_route']\n",
    "change_fails = train_plan.loc[(train_plan.time_start < current_time + hor) \n",
    "                              & (train_plan.train_type.isin([2, 9]))\n",
    "                              & (train_plan.train_start == False)\n",
    "                              & (train_plan.loco_start == False)\n",
    "                              & (train_plan.st_from_name.isin(df_list.st))\n",
    "                              & (train_plan.in_route == True)][cols].drop_duplicates().dropna(subset=['loco'])\n",
    "add_header('\\nВсего %d поездов, у которых должна быть смена локомотивов на станциях обязательной смены, но она не запланирована:' \n",
    "      % len(change_fails))\n",
    "add_line(change_fails.sort_values(['st_to_name', 'time_start_norm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res'></a>\n",
    "## Анализ локомотивов резервом [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_header('Анализ локомотивов резервом', h=2, p=False)\n",
    "hor = 24 * 3600\n",
    "add_line('Анализируемый горизонт отправления: %.2f ч.' % (hor / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res_nums'></a>\n",
    "### Проверка диапазона номеров для локомотивов резервом [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_plan.columns\n",
    "train_plan['train_type'] = train_plan.train.apply(lambda x: int(str(x)[0]))\n",
    "train_plan['res_train_num'] = train_plan.train.apply(lambda x: int(str(x)[-4:]))\n",
    "res_train_nums = train_plan[train_plan.train_type == 8].res_train_num.drop_duplicates()\n",
    "add_line('Диапазон номеров поездов для локомотивов резервом: от %d до %d' % (res_train_nums.min(), res_train_nums.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res_amount'></a>\n",
    "### Анализ количества отправлений локомотивов резервом по направлениям [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_mask = loco_plan.time_start < current_time + hor\n",
    "loco_cols = ['loco', 'st_from_name', 'st_to_name', 'time_start', 'time_start_norm', 'time_end_norm',\n",
    "             'state', 'train', 'res_start', 'res_end']\n",
    "loco_plan['res_start'] = loco_plan.train != loco_plan.train.shift(1)\n",
    "loco_plan['res_end'] = loco_plan.train != loco_plan.train.shift(-1)\n",
    "loco_plan.loc[loco_plan.state == 0, loco_cols]\n",
    "loco_res_start = loco_plan.loc[(loco_plan.res_start == True) &\n",
    "                               (loco_plan.state == 0), loco_cols].sort_values(['loco', 'time_start'])\n",
    "loco_res_end = loco_plan.loc[(loco_plan.res_end == True) & (loco_plan.state == 0), loco_cols].sort_values(['loco', 'time_start'])\n",
    "cols = ['loco', 'st_from_name', 'st_to_name', 'st_to_name_end', 'time_start', 'time_start_norm', 'time_end_norm', 'train']\n",
    "loco_res_trips = loco_res_start[['loco', 'st_from_name', 'st_to_name', 'time_start', 'time_start_norm', 'train']].\\\n",
    "                set_index(['loco', 'train']).join(loco_res_end[['loco', 'st_to_name', 'time_end_norm', 'train']].\\\n",
    "                                                  set_index(['loco', 'train']), rsuffix='_end').reset_index()[cols]\n",
    "\n",
    "loco_res_trips_hor = loco_res_trips.loc[loco_res_trips.time_start < current_time + hor]\n",
    "add_line('Всего отправок локомотивов резервом: %d' % loco_res_trips_hor.loco.count())\n",
    "add_line('Всего локомотивов, для которых есть пересылка резервом: %d' % loco_res_trips_hor.loco.drop_duplicates().count())\n",
    "add_header('\\nСтанции, с которых было отправлено больше всего локомотивов резервом (первые 10):')\n",
    "add_line(loco_res_trips_hor.st_from_name.value_counts().head(10))\n",
    "add_header('\\nУчастки планирования, на которых было отправлено больше всего локомотивов резервом (первые 10):')\n",
    "add_line(loco_res_trips_hor.groupby('st_from_name').st_to_name.value_counts().sort_values(ascending=False).head(10))\n",
    "add_header('\\nСамые частые маршруты для локомотивов резервом (первые 10):')\n",
    "add_line(loco_res_trips_hor.groupby('st_from_name').st_to_name_end.value_counts().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res_before'></a>\n",
    "### Локомотивы резервом до начала планирования [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_info(links)\n",
    "add_line('Время начала планирования: %s (%d)' % (time.strftime(time_format, time.localtime(current_time)), current_time))\n",
    "loco_res_trips['link_name'] = list(zip(loco_res_trips.st_from_name, loco_res_trips.st_to_name))\n",
    "links['link_name'] = list(zip(links.st_from_name, links.st_to_name))\n",
    "loco_res_trips['dir'] = loco_res_trips.link_name.map(links.drop_duplicates('link_name').set_index('link_name')['dir'])\n",
    "loco_res_trips_hor = loco_res_trips.loc[loco_res_trips.time_start < current_time + hor]\n",
    "    \n",
    "cols = ['loco', 'st_from_name', 'st_to_name_end', 'time_start', 'time_start_norm', 'dir', 'train']\n",
    "res_before_ct = loco_res_trips.loc[loco_res_trips.time_start < current_time, cols]\n",
    "add_header('Всего %d локомотивов, отправленных резервом до начала планирования (показаны первые 10):' % len(res_before_ct.index))\n",
    "if not res_before_ct.empty:\n",
    "    add_line(res_before_ct.sort_values('time_start').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a =id='res_even'></a>\n",
    "### Локомотивы резервом в четном направлении [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['loco', 'st_from_name', 'st_to_name_end', 'time_start', 'time_start_norm', 'dir', 'train']\n",
    "even_res = loco_res_trips.loc[loco_res_trips.dir == 0, cols]\n",
    "even_res_hor = loco_res_trips_hor.loc[loco_res_trips_hor.dir == 0, cols]\n",
    "a = even_res_hor.groupby('st_from_name').st_to_name_end.value_counts().sort_values(ascending=False)\n",
    "add_header('Самые частые маршруты для локомотивов резервом в четном направлении (всего %d, показаны первые 10):' \n",
    "      % even_res_hor.loco.drop_duplicates().count())\n",
    "add_line(a.head(10))\n",
    "\n",
    "st_from = a.to_frame().reset_index().ix[0]['st_from_name']\n",
    "st_to = a.to_frame().reset_index().ix[0]['st_to_name_end']\n",
    "most_even_res = even_res_hor.loc[(even_res_hor.st_from_name == st_from) \n",
    "                                 & (even_res_hor.st_to_name_end == st_to)].sort_values('time_start')\n",
    "add_header('\\nЛокомотивы резервом на самом частном маршруте в четном направлении:')\n",
    "add_line(most_even_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Причины появления четных локомотивов резервом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Мариинск и Карымская не являются станциями прохождения ТО. Поэтому локомотивы пересылаются резервом из Мариинска в Боготол для прохождения ТО или из Читы на Карымскую после прохождения ТО в Чите для подвязки под поезда в Карымской. Необходимо обновить справочник ПТОЛ.\n",
    "2. У локомотивов среди разрешенных тяговых плеч указаны и Мариинск-Борзя, и Карымская-Хабаровск. Поэтому локомотивы едут резервом из Читы в Карымскую, чтобы везти локомотивы на Хабаровск, поскольку Чита совсем недалеко от Карымской. Если бы у локомотивов с плеча Мариинск-Борзя не было проставлено плечо Карымская-Хабаровск, то направления резервом из Читы не было бы. Необходимо загрузить новый справочник тяговых плеч, где такого не будет.\n",
    "3. Поезда своего формирования (ССП) из Карымской следуют только до Читы. Поэтому локомотивы и освобождаются в Чите. Но поскольку в Чите они не нужны, то следуют резервом \"куда-то, где нужны\". В новом справочнике от Войтенко поезда СФ из Карымской следуют до Иркутска, Челутая и Петровского Завода -- это дальше Читы. Поэтому отправлений резервом из Читы станет меньше. Аналогичная проблема: для поездов СФ из Красноярска-Восточного и Тайшета.\n",
    "4. Недостаточное количество поездов в четном направлении на главном ходу -- поэтому локомотивы, которые могли бы ехать в четную сторону с поездами, едут резервом. Будет исправлено с загрузкой новых маршрутов.\n",
    "5. Смена локомотивов происходит на станции Горелый (для маршрутов типа Карымская--Беркакит или Таксимо--Карымская, например). Хотя поезд правильнее заводить на Сковородино и менять локомотив там. Проблема в том, что тогда на маршруте поезда получится петля типа \"Бамовская -- Горелый -- Сковородино -- Горелый -- Штурм\". Текущий алгоритм построения маршрутов не сможет сгенерировать такой маршрут у поезда. Видимо, нужна более продвинутая проверка на приоритетные станции при смене локомотивов и корректировка маршрута поезда. Сложная проблема, надо думать. Пока отложено до 10.05.2016.\n",
    "6. Узел Комсомольска-на-Амуре сложный, надо разбираться. Возможно, надо будет вводить дополнительный участок планирования КнА II - КнА-Сорт. Тоже сложная проблема, тоже пока отложено до 10.05.2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='time_leaps'></a>\n",
    "## Проверка скачков по времени назад [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_header('Проверка скачков по времени назад', h=2, p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loco_plan['next_time_start'] = loco_plan.time_start.shift(-1)\n",
    "loco_plan['next_time_start_norm'] = loco_plan.time_start_norm.shift(-1)\n",
    "loco_plan['loco_end'] = loco_plan.loco != loco_plan.loco.shift(-1)\n",
    "cols = ['loco', 'st_from_name', 'st_to_name', 'time_start_norm', 'time_end_norm', 'next_time_start_norm']\n",
    "leaps = loco_plan[(loco_plan.loco_end == False) & (loco_plan.next_time_start < loco_plan.time_end)]\n",
    "if leaps.empty:\n",
    "    add_header('Не найдено локомотивов со скачками по времени назад в плане')\n",
    "else:\n",
    "    add_header('Всего %d локомотивов со скачками по времени назад в плане. Примеры:' % leaps.loco.count())\n",
    "    add_line(leaps.head(10)[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='report'></a>\n",
    "### Экспорт результатов в HTML [ToC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = REPORT_FOLDER + 'loco_report_' + time.strftime('%Y%m%d_%H%M%S', time.localtime(time.time())) + '.html'\n",
    "create_report(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
